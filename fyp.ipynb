{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda env update --file environment.yml --prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:dbg:cuda:0\n",
      "DEBUG:dbg:2.6.0+cu124\n",
      "DEBUG:dbg:NVIDIA RTX A4000\n",
      "DEBUG:dbg:['ffmpeg']\n"
     ]
    }
   ],
   "source": [
    "import os, random, glob, logging, ntpath, math, time, sys, datetime, json, traceback\n",
    "from IPython import display\n",
    "from IPython.display import Audio\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# pd.options.display.max_seq_items = 2000\n",
    "pd.set_option(\"display.max_colwidth\",None)\n",
    "\n",
    "logging.basicConfig()\n",
    "logger=logging.getLogger(\"dbg\")\n",
    "logging.disable(logging.NOTSET)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "perf_logger=logging.getLogger(\"perf\")\n",
    "perf_logger.setLevel(logging.DEBUG)\n",
    "# logging.disable(logging.DEBUG)\n",
    "\n",
    "import torch, torchaudio\n",
    "import torch.nn as nn\n",
    "import torchaudio.functional as audioF\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "logger.debug(device)\n",
    "logger.debug(torch.__version__)\n",
    "logger.debug(torch.cuda.get_device_name(device))\n",
    "logger.debug(torchaudio.list_audio_backends())\n",
    "\n",
    "from ignite.engine import Engine, Events, EventEnum\n",
    "from ignite.metrics import Loss, Metric, RunningAverage\n",
    "from ignite.metrics.metric import reinit__is_reduced, sync_all_reduce\n",
    "from ignite.exceptions import NotComputableError\n",
    "from ignite.handlers.tqdm_logger import ProgressBar\n",
    "from ignite.handlers import Checkpoint, DiskSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "SHUFFLE = True\n",
    "FRAME_SHIFT = 40\n",
    "MAXIMUM_SAMPLE_NUM_OF_FRAMES = 640000\n",
    "\n",
    "RUN_GAN = False\n",
    "RUN_CRN = True\n",
    "RUN_RNN = False\n",
    "RUN_CNN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "from IPython import get_ipython\n",
    "\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    return\n",
    "\n",
    "@register_cell_magic\n",
    "def skip_if(line, cell):\n",
    "    if eval(line):\n",
    "        return\n",
    "    get_ipython().run_cell(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystoi\n",
    "import pesq\n",
    "\n",
    "def combine_audio(speech: torch.Tensor, noise: torch.Tensor, snr: torch.Tensor | int) -> torch.Tensor:\n",
    "    if not (torch.is_floating_point(speech) or torch.is_complex(speech)):\n",
    "        # speech = torch.tensor(speech, dtype=torch.float64, device=speech.device)\n",
    "        speech = speech.to(torch.float64,non_blocking=True)\n",
    "    if not (torch.is_floating_point(noise) or torch.is_complex(noise)):\n",
    "        # noise = torch.tensor(noise, dtype=torch.float64, device=noise.device)\n",
    "        noise = noise.to(torch.float64,non_blocking=True)\n",
    "    if not(type(snr) is torch.Tensor):\n",
    "        snr = torch.tensor([snr])\n",
    "    logger.debug(f\"speech:{speech.ndim}, noise:{noise.ndim}, snr:{snr.ndim}\")\n",
    "    out = audioF.add_noise(speech, noise, snr).to(dtype=torch.float)\n",
    "    return out\n",
    "\n",
    "def calc_pesq(speech: np.ndarray, processed: np.ndarray) -> float:\n",
    "    return pesq.pesq(ref=speech, deg=processed, fs=16000)\n",
    "\n",
    "def calc_stoi(speech: np.ndarray, processed: np.ndarray) -> float:\n",
    "    return pystoi.stoi(x=speech, y=processed, fs_sig=16000)\n",
    "\n",
    "def ns_to_sec(ns: int):\n",
    "    return ns/1000000000.0\n",
    "\n",
    "def datetime_string():\n",
    "    return datetime.datetime.now().strftime(\"%d-%m-%Y--%H-%M-%S\")\n",
    "\n",
    "def plot_waveform(waveform, sample_rate=16000):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
    "        axes[c].grid(True)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
    "    figure.suptitle(\"waveform\")\n",
    "\n",
    "def write_fstring_file(model_name: str, format_string: str, **args):\n",
    "    with open(f\"saved_models/{model_name}_{datetime_string()}.txt\") as f:\n",
    "        f.write(format_string.format(**args))\n",
    "\n",
    "def standardize_batch(batch: torch.Tensor, coerce_func = lambda x: x):\n",
    "    b = batch.squeeze()\n",
    "    if len(b.shape) == 2:\n",
    "        return b\n",
    "    elif len(b.shape) == 1:\n",
    "        return b.unsqueeze(dim=0)\n",
    "    else:\n",
    "        return coerce_func(b)\n",
    "\n",
    "\n",
    "\n",
    "# def stitch_audio(frames_func, frame_size, frame_shift):\n",
    "#     *batches, at_end = frames_func()\n",
    "\n",
    "#     # audio[mix, clean]\n",
    "#     audio = [torch.zeros((b.shape[0],b.shape[1],640000),dtype=torch.float) for b in batches if len(b.shape)==3]\n",
    "#     pos=0\n",
    "#     end=frame_size\n",
    "#     for batch_i, batch in enumerate(batches):\n",
    "#         audio[batch_i][:,:,:end] = batch[:,:,:]\n",
    "\n",
    "#     frame_slice_start = frame_size - frame_shift\n",
    "#     while not at_end:\n",
    "#         pos = end\n",
    "#         end += frame_shift\n",
    "#         *batches, at_end = frames_func()\n",
    "#         for batch_i, batch in enumerate((batches)):\n",
    "#             audio[batch_i][:,0,pos:end] = batch[:,0,frame_slice_start:]\n",
    "\n",
    "#             if at_end:\n",
    "#                 print(audio[batch_i].shape)\n",
    "#                 audio[batch_i] = torch.tensor(audio[batch_i][:,:,:end]) \n",
    "        \n",
    "#     for i in range(BATCH_SIZE):\n",
    "#         print(audio[0][i][0])\n",
    "\n",
    "#     return audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ldrnd = random.Random(42)   #   Used for noise loading \n",
    "\n",
    "def get_sequential_wav_paths(dir):\n",
    "    count = len(glob.glob(\"*.wav\", root_dir=dir))\n",
    "    lst = []\n",
    "    for i in range(1,count+1):\n",
    "        lst.append(dir + \"/\" + str(i) + \".wav\")\n",
    "    \n",
    "    return lst\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, data: list, root_dir: str | None = None):\n",
    "        self.data = data\n",
    "        if root_dir==None:\n",
    "            root_dir = os.getcwd()+\"/data\"\n",
    "        self.root_dir = root_dir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        wave, _ = torchaudio.load(self.root_dir + \"/\" + self.data[idx], format=\"wav\")\n",
    "        return wave\n",
    "\n",
    "    def get(self,idx):\n",
    "        wave, _ = torchaudio.load(self.root_dir + \"/\" + self.data[idx], format=\"wav\")\n",
    "        return wave\n",
    "    \n",
    "class SortedBatchDataset(Dataset):\n",
    "    def __init__(self, mixed: list, clean: list, batch_size: int):\n",
    "        self.mixed = mixed\n",
    "        self.clean = clean\n",
    "        self.batch_size = batch_size\n",
    "        # if root_dir==None:\n",
    "        #     root_dir = os.getcwd()+\"/data\"\n",
    "        # self.root_dir = root_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.floor(len(self.mixed)/self.batch_size)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        mixeds = []\n",
    "        cleans = []\n",
    "        max_len = 0\n",
    "        for i in range(self.batch_size):\n",
    "            if idx + i > len(self.mixed): continue\n",
    "            mixed_wave, _ = torchaudio.load(self.mixed[idx*self.batch_size+i])\n",
    "            clean_wave, _ = torchaudio.load(self.clean[idx*self.batch_size+i])\n",
    "            mixed_wave = mixed_wave[0]\n",
    "            clean_wave = clean_wave[0]\n",
    "            assert(mixed_wave.shape[0]==clean_wave.shape[0])\n",
    "            if i==0:\n",
    "                max_len = mixed_wave.shape[0]\n",
    "            else:\n",
    "                mixed_wave = torch.nn.functional.pad(mixed_wave,(0,max_len-(mixed_wave.shape[0])),value=0.0)\n",
    "                clean_wave = torch.nn.functional.pad(clean_wave,(0,max_len-(clean_wave.shape[0])),value=0.0)\n",
    "            # logger.debug(mixed_wave)\n",
    "            mixeds.append(mixed_wave)\n",
    "            cleans.append(clean_wave)\n",
    "        mixeds = np.asarray(mixeds)\n",
    "        cleans = np.asarray(cleans)\n",
    "        return torch.tensor(mixeds), torch.tensor(cleans)\n",
    "\n",
    "    def split(self, val_pct, seed=None):\n",
    "        rnd = random.Random()\n",
    "        if seed is not None:\n",
    "            rnd.seed(seed)\n",
    "        this_len = len(self)\n",
    "        val_batches = math.floor(this_len*val_pct)\n",
    "        val_indices = sorted(rnd.sample(range(this_len), val_batches))\n",
    "        train_mixed = []\n",
    "        train_clean = []\n",
    "        val_mixed = []\n",
    "        val_clean = []\n",
    "        for i in range(this_len):\n",
    "            if i in val_indices:\n",
    "                for x in range(self.batch_size):\n",
    "                    val_mixed.append(self.mixed[i*self.batch_size+x])\n",
    "                    val_clean.append(self.clean[i*self.batch_size+x])\n",
    "            else:\n",
    "                for x in range(self.batch_size):\n",
    "                    train_mixed.append(self.mixed[i*self.batch_size+x])\n",
    "                    train_clean.append(self.clean[i*self.batch_size+x])\n",
    "        \n",
    "        return SortedBatchDataset(train_mixed,train_clean,self.batch_size), SortedBatchDataset(val_mixed,val_clean,self.batch_size)\n",
    "\n",
    "class FrameLoaderEvents(EventEnum):\n",
    "    END_OF_BATCH = \"end_of_batch\"\n",
    "\n",
    "class FrameLoader():\n",
    "    '''Takes a dataloader, frame size and frame shift. It can then be iterated over to produce frames.\\n\n",
    "    Provides padding when sample length would be exceeded.\\n\n",
    "    Returns (mix, clean, has_batch_ended)'''\n",
    "\n",
    "    def __init__(self, dl: DataLoader, frame_size: int, frame_shift: int, batch_size: int, engine: Engine | None = None, output_transform = lambda x: x):\n",
    "        self.dl = dl\n",
    "        self.dl_iter = iter(dl)\n",
    "        self.batch_count = len(dl)\n",
    "        self.frame_size = frame_size\n",
    "        self.frame_shift = frame_shift\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_mixed: torch.Tensor\n",
    "        self.batch_clean: torch.Tensor\n",
    "        self.frame_position = 0\n",
    "        self.at_end = True\n",
    "        self.engine = engine\n",
    "        self.output_transform = output_transform\n",
    "    def __iter__(self):\n",
    "        self.dl_iter = iter(self.dl)\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self.at_end:\n",
    "            batches: tuple[torch.Tensor,torch.Tensor] = next(self.dl_iter)\n",
    "            self.batch_mixed = batches[0].squeeze_()\n",
    "            if len(self.batch_mixed.shape) == 1:\n",
    "                self.batch_mixed.unsqueeze_(0)\n",
    "            self.batch_clean = batches[1].squeeze_()\n",
    "            if len(self.batch_clean.shape) == 1:\n",
    "                self.batch_clean.unsqueeze_(0)\n",
    "            self.frame_position = 0\n",
    "            self.at_end = False\n",
    "            # logger.debug(f\"mixed batch shape:{self.batch_mixed.shape} | clean batch shape:{self.batch_clean.shape}\")\n",
    "            # mix_maxes = [torch.max(s[0]) for s in self.batch_mixed]\n",
    "            # clean_maxes = [torch.max(s[0]) for s in self.batch_clean]\n",
    "            # logger.debug(f\"mix_maxes:{str(mix_maxes)} | clean_maxes:{str(clean_maxes)}\")\n",
    "        \n",
    "        frame_end = self.frame_position + self.frame_size\n",
    "        frames = []\n",
    "        for batch_i, batch in enumerate([self.batch_mixed, self.batch_clean]):\n",
    "            shp = batch.shape\n",
    "            frame: torch.Tensor\n",
    "            if frame_end >= shp[-1]:\n",
    "                if self.engine is not None and batch_i==0: \n",
    "                    self.engine.fire_event(FrameLoaderEvents.END_OF_BATCH)\n",
    "                self.at_end = True\n",
    "                if frame_end != shp[-1]:\n",
    "                    diff = frame_end - shp[-1]\n",
    "                    # Pad batch until aligned with frame_end\n",
    "                    frame = torch.zeros((self.batch_size, self.frame_size), dtype=torch.float32)\n",
    "                    frame[:, 0:self.frame_size - diff] = batch[:, self.frame_position:shp[-1]]\n",
    "                else:\n",
    "                    frame = torch.zeros((self.batch_size, self.frame_size), dtype=torch.float32)\n",
    "                    frame[:, 0:self.frame_size] = batch[:, self.frame_position:frame_end]\n",
    "            else:\n",
    "                frame = torch.zeros((self.batch_size, self.frame_size), dtype=torch.float32)\n",
    "                frame[:, 0:self.frame_size] = batch[:, self.frame_position:frame_end]\n",
    "            frames.append(self.output_transform(frame))\n",
    "\n",
    "        self.frame_position += self.frame_shift\n",
    "        # logger.debug(f\"FrameLoader: frame_position[{self.frame_position}] - frame_end[{frame_end}]\")\n",
    "        # perf_logger.debug(f\"Time to load frame at ({self.frame_position}): {time.perf_counter() - start}s\")\n",
    "\n",
    "        try:\n",
    "\n",
    "            if frames[0].shape[-1] != self.frame_size:\n",
    "                logger.debug(frames[0].shape[-1])\n",
    "                logger.debug(\"FrameLoader issue\")\n",
    "        except Exception as e:\n",
    "            print(frames[0].shape)\n",
    "            raise Exception(e.args)\n",
    "        \n",
    "        return frames[0], frames[1], self.at_end\n",
    "\n",
    "class FrameReconstructor():\n",
    "    '''Constructs a batch of audio samples by continuously adding (batches of) frames to the end of a buffer, excluding overlapping sections.\\n\n",
    "    Use `add_frame()` to return the constructed samples, up to the last batch of frames added.\n",
    "    '''\n",
    "    def __init__(self, frame_size: int, frame_shift: int, batch_size: int, output_transform = lambda x: x):\n",
    "        self.audio: torch.Tensor = torch.zeros((batch_size, MAXIMUM_SAMPLE_NUM_OF_FRAMES),dtype=torch.float)\n",
    "        self.frame_size = frame_size\n",
    "        self.frame_shift = frame_shift\n",
    "        self.pos: int = 0\n",
    "        self.end: int = frame_size\n",
    "        self.frame_slice_start: int = 0\n",
    "        self.at_end = False\n",
    "        self.output_transform = output_transform\n",
    "    \n",
    "    def add_frame(self, batch: torch.Tensor, _at_end = False):\n",
    "        batch = standardize_batch(batch)\n",
    "        batch = batch.reshape((self.audio.shape[0], batch.shape[-1]))\n",
    "        self.audio[:,self.pos:self.end] = batch[:,self.frame_slice_start:]\n",
    "\n",
    "        self.pos = self.end\n",
    "        self.end += self.frame_shift\n",
    "        self.frame_slice_start = self.frame_size - self.frame_shift\n",
    "\n",
    "        # if _at_end: \n",
    "        #     return True\n",
    "        # return False\n",
    "\n",
    "        #   Remove if _at_end ends up doing something\n",
    "        return _at_end\n",
    "    \n",
    "    def get_current_audio(self):\n",
    "        out = torch.tensor(self.audio[:,0:self.end - self.frame_shift])\n",
    "        out = self.output_transform(out)\n",
    "        return out\n",
    "\n",
    "    def reset(self):\n",
    "        self.audio = torch.zeros(self.audio.shape,dtype=torch.float)\n",
    "        self.pos = 0\n",
    "        self.end = self.frame_size\n",
    "        self.frame_slice_start = 0\n",
    "        self.at_end = False\n",
    "\n",
    "\n",
    "def get_reference_batch(ds: Dataset, frame_size: int, output_transform=lambda x: x):\n",
    "    while True:\n",
    "        idx = random.randint(0,len(ds)-1)\n",
    "        batches = ds.__getitem__(idx)\n",
    "        batch, batch2 = batches[0], batches[1]\n",
    "        print(batch.shape)\n",
    "        if batch.shape[-1] < frame_size:\n",
    "            continue\n",
    "        randpos = random.randint(0, batch.shape[-1]-frame_size)\n",
    "        batch = batch[:, randpos:randpos+frame_size]\n",
    "        batch2 = batch2[:, randpos:randpos+frame_size]\n",
    "        return output_transform(batch), output_transform(batch2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.MSELoss()\n",
    "\n",
    "pf_train_totals = [0,0]                                                     ###\n",
    "pf_train_num_loops = 0                                                      ###\n",
    "pf_eval_total = 0\n",
    "pf_eval_num_loops = 0\n",
    "\n",
    "class PESQMetric(Metric):\n",
    "    def __init__(self, stitch_keys=(\"stitch_proc\",\"stitch_clean\"), output_transform = lambda x: x, device=device):\n",
    "        self.stitch_keys=stitch_keys\n",
    "        self.running_total=0.0\n",
    "        self.num=0\n",
    "        super().__init__(output_transform, device)\n",
    "    @reinit__is_reduced\n",
    "    def reset(self):\n",
    "        self.running_total=0.0\n",
    "        self.num=0\n",
    "        super().reset()\n",
    "    @reinit__is_reduced\n",
    "    def update(self, output):\n",
    "        if len(output)<=2 or \"stitch_proc\" not in output[2]: return\n",
    "        y_pred: np.ndarray = standardize_batch(output[2][self.stitch_keys[0]]).cpu().numpy()\n",
    "        y: np.ndarray = standardize_batch(output[2][self.stitch_keys[1]]).cpu().numpy()\n",
    "        for i in range(y.shape[0]):\n",
    "            self.running_total += calc_pesq(y[i], y_pred[i])\n",
    "            self.num += 1\n",
    "        \n",
    "    @sync_all_reduce(\"num\",\"running_total:SUM\")\n",
    "    def compute(self):\n",
    "        if self.num == 0:\n",
    "            raise NotComputableError(\"PESQ Metric must have one complete sample before computing\")\n",
    "        return self.running_total / self.num\n",
    "\n",
    "class STOIMetric(Metric):\n",
    "    def __init__(self, stitch_keys=(\"stitch_proc\",\"stitch_clean\"), output_transform = lambda x: x, device=device):\n",
    "        self.stitch_keys=stitch_keys\n",
    "        self.running_total=0.0\n",
    "        self.num=0\n",
    "        super().__init__(output_transform, device)\n",
    "    @reinit__is_reduced\n",
    "    def reset(self):\n",
    "        self.running_total=0.0\n",
    "        self.num=0\n",
    "        super().reset()\n",
    "    @reinit__is_reduced\n",
    "    def update(self, output):\n",
    "        if len(output)<=2 or \"stitch_proc\" not in output[2]: return\n",
    "        y_pred: np.ndarray = standardize_batch(output[2][self.stitch_keys[0]]).cpu().numpy()\n",
    "        y: np.ndarray = standardize_batch(output[2][self.stitch_keys[1]]).cpu().numpy()\n",
    "        for i in range(y.shape[0]):\n",
    "            self.running_total += calc_stoi(y[i], y_pred[i])\n",
    "            self.num += 1\n",
    "    @sync_all_reduce(\"num\",\"running_total:SUM\")\n",
    "    def compute(self):\n",
    "        if self.num == 0:\n",
    "            raise NotComputableError(\"STOI Metric must have one complete sample before computing\")\n",
    "        return self.running_total / self.num\n",
    "\n",
    "\n",
    "class ValidationEvents(EventEnum):\n",
    "    VALIDATION_COMPLETED = \"validation_completed\"\n",
    "\n",
    "def register_custom_events(eng: Engine):\n",
    "    eng.register_events(*FrameLoaderEvents)\n",
    "    eng.register_events(*ValidationEvents)\n",
    "\n",
    "def log_trainer_loss(eng: Engine):\n",
    "    iterations = eng.state.iteration % eng.state.iteration_ceiling\n",
    "    print(f\"Epoch[{eng.state.epoch}], Iter[{iterations}] Loss: {eng.state.output}\")\n",
    "\n",
    "def log_custom(eng: Engine, **kwargs):\n",
    "    full_dict = {**eng.state_dict(), \"epoch\": eng.state.epoch, **kwargs}\n",
    "    fmt_string: str = kwargs[\"template\"]\n",
    "    print(fmt_string.format(**full_dict))\n",
    "\n",
    "def run_eval(eng: Engine, **kwargs):\n",
    "    validator: Engine = kwargs.get(\"validator\",None)\n",
    "    val_frame_loader: FrameLoader = kwargs.get(\"val_frame_loader\",None)\n",
    "    if validator is None:\n",
    "        raise TypeError(\"log_eval_results must be passed the argument `validator` of type `Engine`\")\n",
    "    if val_frame_loader is None:\n",
    "        raise TypeError(\"log_eval_results must be passed the argument `val_frame_loader` of type `FrameLoader`\")\n",
    "    \n",
    "    validator.run(val_frame_loader)\n",
    "    eng.fire_event(ValidationEvents.VALIDATION_COMPLETED)\n",
    "\n",
    "def log_eval_results(eng: Engine, **kwargs):\n",
    "    prefix = kwargs.get(\"prefix\",\"\")\n",
    "    validator: Engine = kwargs.get(\"validator\",None)\n",
    "    if validator is None:\n",
    "        raise TypeError(\"log_eval_results must be passed the argument `validator` of type `Engine`\")\n",
    "    \n",
    "    metrics = validator.state.metrics\n",
    "    metrics_out = kwargs.get(\"metrics_out\",None)\n",
    "    if metrics_out != None:\n",
    "        metrics_out.append(metrics.copy())\n",
    "    print(f\"{prefix}Epoch[{eng.state.epoch}] | PESQ:[{metrics['pesq']:.2f}] | STOI:[{metrics['stoi']:.2f}] | Loss:[{metrics['loss']}]\")\n",
    "\n",
    "def set_engine_custom_keys(eng: Engine):\n",
    "    eng.state_dict_user_keys.append(\"iteration_ceiling\")\n",
    "    eng.state.iteration_ceiling = sys.maxsize\n",
    "\n",
    "def set_iteration_ceiling(eng: Engine, *args):\n",
    "    if len(args)==1:\n",
    "        eng.state.iteration_ceiling = args[0]\n",
    "    else:\n",
    "        eng.state.iteration_ceiling = eng.state.iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_hp = {\n",
    "    \"frame_size\":16384,\n",
    "    \"frame_shift\":8192,\n",
    "    \"g_lr\":1.0e-4,\n",
    "    \"d_lr\":1.0e-4,\n",
    "    \"batch_size\":128,\n",
    "    \"epochs\":80,\n",
    "    \"save\":True,\n",
    "    \"load\":None,\n",
    "}\n",
    "\n",
    "GAN_RUN_ON_LOAD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan(hp: dict = gan_hp):\n",
    "    global pf_train_totals, pf_train_num_loops, pf_eval_total, pf_eval_num_loops\n",
    "    pf_train_totals = [0,0]\n",
    "    pf_train_num_loops = 0\n",
    "    pf_eval_total = 0\n",
    "    pf_eval_num_loops = 0\n",
    "    try:\n",
    "        datestring_at_start = datetime_string()\n",
    "        os.mkdir(f\"saved_models/gan_{datestring_at_start}\")\n",
    "\n",
    "        from models.segan import Discriminator, Generator\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        out = {\"hp\": hp}\n",
    "        gen = Generator().to(device=device)\n",
    "        dcrim = Discriminator().to(device=device)\n",
    "\n",
    "        if hp[\"load\"] != None:\n",
    "            gen.load_state_dict(torch.load(hp[\"load\"][0], weights_only=True))\n",
    "            dcrim.load_state_dict(torch.load(hp[\"load\"][1], weights_only=True))\n",
    "        \n",
    "        g_optimizer = torch.optim.RMSprop(gen.parameters(), lr=hp[\"g_lr\"])\n",
    "        d_optimizer = torch.optim.RMSprop(dcrim.parameters(), lr=hp[\"d_lr\"])\n",
    "        criterion = nn.L1Loss()\n",
    "        out[\"optimizer\"] = \"RMSprop\"\n",
    "        out[\"criterion\"] = \"L1loss\"\n",
    "\n",
    "\n",
    "        _dataset = SortedBatchDataset(get_sequential_wav_paths(\"data/mixed/train\"),\n",
    "                                    get_sequential_wav_paths(\"data/speech_ordered/train\"), \n",
    "                                    batch_size=hp[\"batch_size\"])\n",
    "        train_dataset, val_dataset = _dataset.split(0.2)\n",
    "        del _dataset\n",
    "        base_train_dataloader = DataLoader(train_dataset, shuffle=SHUFFLE)\n",
    "        base_val_dataloader = DataLoader(val_dataset)\n",
    "        r = get_reference_batch(train_dataset, hp[\"frame_size\"], lambda x: x.view(hp[\"batch_size\"],1,-1))\n",
    "        ref_batch = torch.cat((r[0],r[1]),dim=1).to(device=device)\n",
    "        z = torch.zeros((hp[\"batch_size\"],1024,8)).to(device=device)\n",
    "        print(ref_batch.shape)\n",
    "\n",
    "        def train_step(engine, batch):\n",
    "            # global pf_train_totals, pf_train_num_loops\n",
    "            # pf_train_forward = time.perf_counter_ns()                               ###\n",
    "            dcrim.train()\n",
    "            dcrim.zero_grad()\n",
    "            x, y = batch[0].to(device=device), batch[1].to(device=device)\n",
    "            nn.init.normal_(z)\n",
    "            combined_batch = torch.cat((x.clone().detach(),y.clone().detach()),dim=1)\n",
    "            output = dcrim(combined_batch, ref_batch)\n",
    "            clean_loss = torch.mean((output - 1.0) ** 2)\n",
    "            clean_loss.backward()\n",
    "\n",
    "            gen_out = gen(x, z)\n",
    "            output = dcrim(torch.cat((gen_out, x), dim=1),ref_batch)\n",
    "            noisy_loss = torch.mean(output ** 2)\n",
    "            noisy_loss.backward()\n",
    "\n",
    "            d_optimizer.step()\n",
    "\n",
    "            gen.train()\n",
    "            gen.zero_grad()\n",
    "            gen_out = gen(x, z)\n",
    "            gen_noise_pair = torch.cat((gen_out, x), dim=1)\n",
    "            output = dcrim(gen_noise_pair, ref_batch)\n",
    "\n",
    "            g_loss_ = 0.5 * torch.mean((output - 1.0) ** 2)\n",
    "            l1_dist = torch.abs(torch.add(gen_out, torch.neg(y)))\n",
    "            g_cond_loss = 100 * torch.mean(l1_dist)\n",
    "            g_loss = g_loss_ + g_cond_loss\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            return g_loss.item()\n",
    "            \n",
    "        trainer = Engine(train_step)\n",
    "        register_custom_events(trainer)\n",
    "        RunningAverage(output_transform=lambda x: x).attach(trainer,'loss')\n",
    "        pbar = ProgressBar(desc=\"Training Epoch\")\n",
    "        pbar.attach(trainer,['loss'])\n",
    "\n",
    "        trainer.add_event_handler(Events.STARTED, set_engine_custom_keys)\n",
    "        trainer.add_event_handler(Events.EPOCH_COMPLETED(once=1),set_iteration_ceiling)\n",
    "\n",
    "        train_dataloader = FrameLoader(base_train_dataloader, hp[\"frame_size\"], hp[\"frame_shift\"],\n",
    "                                        hp[\"batch_size\"], engine=trainer, \n",
    "                                        output_transform=lambda x: x.view((hp[\"batch_size\"],1,-1)))\n",
    "\n",
    "        proc_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"],\n",
    "                                                    output_transform=lambda x: x.view((hp[\"batch_size\"],1,-1)))\n",
    "        clean_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"],\n",
    "                                                     output_transform=lambda x: x.view((hp[\"batch_size\"],1,-1)))\n",
    "        \n",
    "        def val_step(engine, batch):\n",
    "            with torch.no_grad():\n",
    "                # global pf_eval_total, pf_eval_num_loops\n",
    "                x, y = batch[0].to(device=device), batch[1].to(device=device)\n",
    "                nn.init.normal_(z)\n",
    "                y_pred = gen(x, z)\n",
    "                proc_frame_constructor.add_frame(y_pred)\n",
    "                clean_frame_constructor.add_frame(y)\n",
    "                if batch[2]:    #   Frame fully constructed\n",
    "                    y_pred_stitch = proc_frame_constructor.get_current_audio()\n",
    "                    y_stitch = clean_frame_constructor.get_current_audio()\n",
    "                    proc_frame_constructor.reset()\n",
    "                    clean_frame_constructor.reset()\n",
    "                    return y_pred, y, {\"stitch_proc\": y_pred_stitch, \"stitch_clean\": y_stitch}\n",
    "\n",
    "                return y_pred, y\n",
    "        \n",
    "        validator = Engine(val_step)\n",
    "        pbar = ProgressBar(desc=\"Validation\")\n",
    "        pbar.attach(validator,['loss'])\n",
    "        val_metrics: dict[str, Metric] = {\n",
    "            \"loss\": Loss(criterion, output_transform=lambda x: (x[0],x[1])),\n",
    "            \"pesq\": PESQMetric(),\n",
    "            \"stoi\": STOIMetric()\n",
    "        }\n",
    "        for name, metric in val_metrics.items():\n",
    "            metric.attach(validator, name)\n",
    "\n",
    "        checkpoint_to_save = {\"gen\": gen, \"dcrim\": dcrim}\n",
    "        checkpoint_handler = Checkpoint(\n",
    "            checkpoint_to_save, f\"saved_models/gan_{datestring_at_start}\",\n",
    "            filename_prefix=\"best\", score_function=lambda eng: eng.state.metrics['pesq'],n_saved=2\n",
    "        )\n",
    "\n",
    "        metrics_out = []\n",
    "        out[\"metrics\"] = metrics_out\n",
    "        val_dataloader = FrameLoader(base_val_dataloader, hp[\"frame_size\"], hp[\"frame_shift\"],\n",
    "                                     hp[\"batch_size\"], output_transform=lambda x: x.view((hp[\"batch_size\"],1,-1)))\n",
    "        trainer.add_event_handler(Events.EPOCH_COMPLETED,run_eval,validator=validator,val_frame_loader=val_dataloader)\n",
    "        trainer.add_event_handler(ValidationEvents.VALIDATION_COMPLETED,log_eval_results,validator=validator,metrics_out=metrics_out)\n",
    "        validator.add_event_handler(Events.COMPLETED, checkpoint_handler)\n",
    "            \n",
    "        time_train = time.perf_counter_ns()\n",
    "        trainer.run(train_dataloader, max_epochs=hp[\"epochs\"])\n",
    "        out[\"total_time\"] = time.perf_counter_ns() - time_train\n",
    "        # out[\"fwd\"]=pf_train_totals[0] / float(pf_train_num_loops)                        ###\n",
    "        # out[\"bck\"]=pf_train_totals[1] / float(pf_train_num_loops)                        ###\n",
    "        # out[\"eval\"]=pf_eval_total / float(pf_eval_num_loops)                          ###\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"failed\")\n",
    "        print(traceback.format_exc())\n",
    "        print(e)\n",
    "    \n",
    "    finally:\n",
    "        if \"dcrim\" in locals():\n",
    "            if hp[\"save\"]:\n",
    "                torch.save(gen.state_dict(),f\"saved_models/gan_{datestring_at_start}/gen_final.pt\")\n",
    "                torch.save(dcrim.state_dict(),f\"saved_models/gan_{datestring_at_start}/dcrim_final.pt\")\n",
    "                with open(f\"saved_models/gan_{datestring_at_start}/out.json\",\"w\") as f:\n",
    "                    json.dump({k: out[k] for k in out.keys() - {'gen', 'dcrim'}},f)\n",
    "            return out\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "if GAN_RUN_ON_LOAD:\n",
    "    gan()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WaveCRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "crn_hp = {\n",
    "    \"frame_size\":96,\n",
    "    \"frame_shift\":40,\n",
    "    \"lr\":5.0e-7,\n",
    "    \"batch_size\":128,\n",
    "    \"epochs\":80,\n",
    "    \"save\":True,\n",
    "    \"load\":None,\n",
    "}\n",
    "\n",
    "CRN_RUN_ON_LOAD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/research/FYP_Leo/fyp/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "/vol/research/FYP_Leo/fyp/lib/python3.12/site-packages/sru/modules.py:538: UserWarning: rnn_dropout > 0 is deprecated and will be removed innext major version of SRU. Please use dropout instead.\n",
      "  warnings.warn(\"rnn_dropout > 0 is deprecated and will be removed in\"\n",
      "/vol/research/FYP_Leo/fyp/lib/python3.12/site-packages/ignite/handlers/tqdm_logger.py:127: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df15d6deee3b420b8e3b8dc1d223638f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6568a59315ba456687359a2b90f4fa22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/research/FYP_Leo/fyp/lib/python3.12/site-packages/ignite/handlers/base_logger.py:128: UserWarning: Provided metric name 'loss' is missing in engine's state metrics: []\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1729098/226662389.py:197: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  out = torch.tensor(self.audio[:,0:self.end - self.frame_shift])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] | PESQ:[1.26] | STOI:[0.80] | Loss:[0.017353107467738445]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886226d6d2274bcc95989c5f4bc8bcb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14955de5ff94553ada2ace42996c1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[2] | PESQ:[1.33] | STOI:[0.82] | Loss:[0.015892756131358026]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba78065f1ff41ca93f68331e25d95fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb0909aa7d44db19a782aea9ccc352d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[3] | PESQ:[1.36] | STOI:[0.83] | Loss:[0.015625199853163883]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739b3c8281e2450fa1026c3a35e9e4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128dd1f636fb4ea9a6af48a23ff5ea94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[4] | PESQ:[1.31] | STOI:[0.81] | Loss:[0.014960630982347506]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9b60f2a99f4ff19ffc95a51e541328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b068327df7b84459b8b285cc55fd4213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[5] | PESQ:[1.38] | STOI:[0.83] | Loss:[0.014529285043692698]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148adfea3a6c48108d1bf94de9f1cc27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15fb898acb594e52a0485e745f7624df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[6] | PESQ:[1.42] | STOI:[0.83] | Loss:[0.014353434244791666]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6379fb0f4a9e48a0be89688bb2b5befa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d72afb8351f49819dbcdf6bcdaeabf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[7] | PESQ:[1.41] | STOI:[0.84] | Loss:[0.014134841991748965]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3b325f141c4995ad7918e237fd172b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e772458c24a34564adc54c2454560dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[8] | PESQ:[1.43] | STOI:[0.84] | Loss:[0.013870264953219285]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ab474f2f7f492fa89b90af950f4351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1139cc6f5a6e426fb9b699908a9e48e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[9] | PESQ:[1.46] | STOI:[0.84] | Loss:[0.013761930263168473]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909416499a7a4e4b9ee23277f8a1c10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6849471d30ad4d29b3b4c1c35acbcc66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10] | PESQ:[1.45] | STOI:[0.84] | Loss:[0.01347442150160577]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c63bd8adec41a8bba252a69179b17b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e7b9ecc1b743e783d40ee89bf5977f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[11] | PESQ:[1.44] | STOI:[0.84] | Loss:[0.013398528690143635]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df4d5d907384ca7ac6907c8e5e3d9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794fb53bd4074ba4ab1e4dbbfe30b63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[12] | PESQ:[1.48] | STOI:[0.84] | Loss:[0.01344897591127561]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71975c432a07444287fb1acfbf2ce62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331e3aa9a704499aaa159aa517f012d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[13] | PESQ:[1.48] | STOI:[0.84] | Loss:[0.01333168779948282]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a1784b058543f791e6e38c23b7a547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90c63770b4d47fa992a6cc01703613e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[14] | PESQ:[1.49] | STOI:[0.85] | Loss:[0.013202272883210105]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fb510432704facba3da8c4e9640904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3e3f953dfa4556bd7740b8997940b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[15] | PESQ:[1.52] | STOI:[0.85] | Loss:[0.013310089382557419]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8017da4dbba46a496ae9653ac0cf86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c079de7a33247a7bd97811a39588e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[16] | PESQ:[1.48] | STOI:[0.84] | Loss:[0.013047203958307753]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ddca77c0707463c8b0016eebec180f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f6ab452870432bb3f95792222d2c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[17] | PESQ:[1.49] | STOI:[0.85] | Loss:[0.013050251719056974]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82a53ac0f8842779abc5dad0dec3579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa01dc1d9054121a7a68391771e33ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[18] | PESQ:[1.50] | STOI:[0.85] | Loss:[0.013048447330491627]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f57c387193449948f39b4edc54dc358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841733e966a84c1cbe75ca7d9db46e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[19] | PESQ:[1.49] | STOI:[0.85] | Loss:[0.012912628547839046]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfac67a74c54453afbc5e142a8f1b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136f104f4dd649c4bee25bb3496ed39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[20] | PESQ:[1.51] | STOI:[0.85] | Loss:[0.012932790877029686]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06cbd1d71c2473289e518a46c70a149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536dd589f724447f9e0b4f05260a8cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[21] | PESQ:[1.53] | STOI:[0.85] | Loss:[0.012861280559946996]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d9c320e59e4105b0dddbe9b234fcb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83126c5f60740579387c120ff78bd0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[22] | PESQ:[1.52] | STOI:[0.85] | Loss:[0.012784434163388618]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61c27925af240c9ac4755af6851900d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab455ce124ca40bc9713c6cbf89e17dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[23] | PESQ:[1.56] | STOI:[0.85] | Loss:[0.012901880730189915]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb810bc3db3d4644a8a1cf1420946137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b97703257b54f2d95b4981f2e74ee23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[24] | PESQ:[1.54] | STOI:[0.85] | Loss:[0.01280889476312535]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5327236c73e643e19ea2911a1a39b03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d15342dc52a4867a5a6e1410c0a59ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[25] | PESQ:[1.57] | STOI:[0.85] | Loss:[0.01285472252112642]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595fde7449b44eb7a65a76b52ee50a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0cb0a41f91f44f3942a4bd23a5902e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[26] | PESQ:[1.56] | STOI:[0.85] | Loss:[0.012842171742434542]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9727bfcb9a234b95a85c0f5b766aee70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ce2dfe1c0d4852a9af345b275c907f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[27] | PESQ:[1.57] | STOI:[0.86] | Loss:[0.012803904144118661]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b030d8f9454a998f51b12d00986b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fde26811d1b4c91b8c1290cc97d4ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[28] | PESQ:[1.55] | STOI:[0.85] | Loss:[0.01266105766771038]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069fb5a5ef7e4cc3b55febddb7733270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90006c7b17248439b03655fc41a2ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[29] | PESQ:[1.57] | STOI:[0.86] | Loss:[0.012729655838690769]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e36bf304d04fdfb4a5e5a6112eb22b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f87255bcb3450dbb70457ae3b6a231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[30] | PESQ:[1.53] | STOI:[0.85] | Loss:[0.012664519410013361]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da172584c23446d9a6da5c8c4f502f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a27f728408497486341a020d662b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[31] | PESQ:[1.53] | STOI:[0.85] | Loss:[0.012567417895295398]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80df371757f4bd3812b76c28fbca5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012c5994525c49c98745ea948697a580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[32] | PESQ:[1.53] | STOI:[0.85] | Loss:[0.012515421812143325]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e110587ecb4898b6d4ee115fedbd72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb46520d94b474a831e53b1b8d79344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[33] | PESQ:[1.55] | STOI:[0.85] | Loss:[0.012560797045480458]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a079106a4af148fea4238fab97eb1840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ff869c9fa7486984407bdeee27ee4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[34] | PESQ:[1.55] | STOI:[0.85] | Loss:[0.01253682751351784]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0cbcb1c95ea4e14b826bef0afc8b1c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4d85166b714d6db46acf0240185275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[35] | PESQ:[1.56] | STOI:[0.86] | Loss:[0.012487062648188265]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676b161303c1455080330a26cc1abf30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848fcf322aa643628a77cbda27229aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[36] | PESQ:[1.56] | STOI:[0.85] | Loss:[0.012439349132833696]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f713f466fd24422c93d22ec3898f7eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178de0c1b7374100a4149d0c21fdd5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[37] | PESQ:[1.54] | STOI:[0.85] | Loss:[0.012426367242316869]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fbd144e6df64750ada70c306bbe855b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227c0cdbfd1942b08a846297b96c0f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[38] | PESQ:[1.59] | STOI:[0.86] | Loss:[0.012530198098567306]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2f3211f0694f9db338492e354c7a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d4db9647a04832beafa97411f85875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[39] | PESQ:[1.54] | STOI:[0.85] | Loss:[0.012380702221892102]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69f302e10df46878644e060ff2d351c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c96f7dd786b42709aae169865ddb3d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[40] | PESQ:[1.55] | STOI:[0.85] | Loss:[0.012383120445175092]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ca2e1488514b6a942a19939bcd5efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0634507e31405ea2a0db39e1ab2a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[41] | PESQ:[1.59] | STOI:[0.86] | Loss:[0.012466801819938284]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc51b6fc10940eca1e7ca376f5b48a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4936d4712c34b68a89dcc8b845fd189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[42] | PESQ:[1.55] | STOI:[0.85] | Loss:[0.01239269198420251]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c716b875e6e04aa7a12502c8e12be45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b0ebb9f98a4cfe805349f3130cf949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[43] | PESQ:[1.56] | STOI:[0.86] | Loss:[0.01234490852024058]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5876548318864ab39592684ba2a4975f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdcafa3a26844cde882bc3dec46dade3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[44] | PESQ:[1.55] | STOI:[0.85] | Loss:[0.01235281128534957]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfcbfb311f7421e8f6ea8d8a0ed0eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d59cfd4d9349c68207a592ae4c0241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[45] | PESQ:[1.59] | STOI:[0.86] | Loss:[0.012336417615820734]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4130cd1ea2a44059998df0e862939826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dab83e9c9d043a8a007c37021e0764e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[46] | PESQ:[1.56] | STOI:[0.85] | Loss:[0.012342872873014167]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48cd268e5f34a328cbb747b3b83318d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25b5fe578dd48bebfd078ed89e09726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[47] | PESQ:[1.60] | STOI:[0.86] | Loss:[0.012402083655382432]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17051d4117c4fd8bd622427a4d609cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c55f5dc98d4bcf93182a97f3cc2496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[48] | PESQ:[1.57] | STOI:[0.86] | Loss:[0.012291440661288766]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc294ef31e8148648096c7d44f70fa32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1695cf9f5b648f5b1498b84a2a573aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[49] | PESQ:[1.57] | STOI:[0.86] | Loss:[0.012329195778991544]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e2473b2a044c979e16f7c6067e6f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26782f344b4b4569a65e57ae1efca66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[50] | PESQ:[1.55] | STOI:[0.85] | Loss:[0.012268401874060805]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e549e9e1e554b9080d07a4115ddec9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4f45c1de95483ebcba19729c50a108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[51] | PESQ:[1.54] | STOI:[0.85] | Loss:[0.012269396857312424]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4d35a3014f4086ba85808606462dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd350174859243048c75ac06b4b6a4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[52] | PESQ:[1.55] | STOI:[0.85] | Loss:[0.012221165151254355]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662c844e42bf4e59827b13edd80251b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9eaa4b41e3f415aa2ed4161c7c33c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[53] | PESQ:[1.57] | STOI:[0.86] | Loss:[0.012239050581899323]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317affae13ae49748c034cebc5026c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44030f87ff124be0b6b7732a0073cbb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[54] | PESQ:[1.57] | STOI:[0.85] | Loss:[0.012215446495722091]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5803e7ef644b9aa4a14ac971fc0a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc70409999e4d0f8ff19c4ce45b9a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[55] | PESQ:[1.54] | STOI:[0.85] | Loss:[0.012233958608788094]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098575bb309045f5bb115fcabcc1e153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73999b53227142d0b91677d0d9bc41b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[56] | PESQ:[1.57] | STOI:[0.86] | Loss:[0.012247782737638432]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76d47e218364763a3905814d02e5ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac02362234e42b1b524b1a910804687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[57] | PESQ:[1.58] | STOI:[0.86] | Loss:[0.01240974945173996]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c838b2ef545543a5a9ad265bcfebbedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc2f3cda778486eb72f04ddacc2981c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[58] | PESQ:[1.57] | STOI:[0.85] | Loss:[0.012183210180387694]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4792183129534234810f9d10ed6d7445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9420a1c229d41d5a85993a267d41a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[59] | PESQ:[1.57] | STOI:[0.86] | Loss:[0.012193512610985885]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05188b270e44c0b99694b1b1a20685d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0e3f0b9f1944b8b688d7f2f041b5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[60] | PESQ:[1.58] | STOI:[0.86] | Loss:[0.012201416803617474]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab305915ea6340b9af87465aedec786a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef99e313e6c14302be2055edfd12cde4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[61] | PESQ:[1.55] | STOI:[0.85] | Loss:[0.012141842002986424]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4be9b63a2ef4ad69fd4597b9b02f1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3a728f32f34bc8a941d390563af3a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[62] | PESQ:[1.58] | STOI:[0.86] | Loss:[0.012149686239668847]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49bfd9632bbd415e86f824025470ba56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbcb1bebe62455eb8dbf90399d7b0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[63] | PESQ:[1.58] | STOI:[0.86] | Loss:[0.012154008778099126]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b7e8158a604c029c0bfdda47566bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbacf47a6f914e35b5a0664ea5bb406d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[64] | PESQ:[1.60] | STOI:[0.86] | Loss:[0.012238409624252298]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0c85ca833b4b968c39b4615be5e972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6612a36cd93c4958ae4c3917f5e78f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[65] | PESQ:[1.59] | STOI:[0.86] | Loss:[0.012173721437671028]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ef1d60558e4533bd3724b044caacce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa06f8bac713456f8f4bb630d32a1318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[66] | PESQ:[1.55] | STOI:[0.85] | Loss:[0.012122166459002099]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3695d5522e6e45b49d1ca1d7f5f8f6e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84391e4a999649b7ba3b421f3d66de57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[67] | PESQ:[1.55] | STOI:[0.85] | Loss:[0.012126685995551063]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e893706923b44de92c1f33e99c24ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e67be7cd8c4c0b8ec558116e219bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[68] | PESQ:[1.61] | STOI:[0.86] | Loss:[0.01211211812742656]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b1b658b00c4c9f9a415d0a5836bb62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce15b4f939344279e6709dc3e65b382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[69] | PESQ:[1.57] | STOI:[0.86] | Loss:[0.012096188402742451]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef32f9845d4f48d287265172c7f44eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0120ff0a519c4e33aab5fdeeb09078bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[70] | PESQ:[1.56] | STOI:[0.85] | Loss:[0.01209876222598875]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc3bd8b083845e293dd9cdc031310c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f732dc452d450f8e1d866d2b67cb38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[71] | PESQ:[1.59] | STOI:[0.86] | Loss:[0.012121321365623392]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acfd4484447d43a0b70ae6959579ace8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c814e90e86754dd3a587cd09da1ca355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[72] | PESQ:[1.58] | STOI:[0.86] | Loss:[0.012086108665669731]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8e95a58ad04eddb38dd5ec595e862f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24d699b43384ef9a92f489673e769b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[73] | PESQ:[1.59] | STOI:[0.86] | Loss:[0.01207609744968177]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950f8de2808c4a35900e539fcdefadaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490ccd904e744d4aac62d41f1735e0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[74] | PESQ:[1.58] | STOI:[0.85] | Loss:[0.01206534534946484]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b53f12247f48679337d8240d016292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d533142e8f44b4688154856a89c6887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[75] | PESQ:[1.56] | STOI:[0.86] | Loss:[0.012063608054461654]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddcbd3cd236b47f6a39a7cc9793e8d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfdd43e6247452084d14a1474dd0696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[76] | PESQ:[1.59] | STOI:[0.86] | Loss:[0.012033708593622095]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77a431d030647b1a6fa0bc2e27f47e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f91d729e0a4b6da32e4ab3436651aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[77] | PESQ:[1.59] | STOI:[0.86] | Loss:[0.012048293592017787]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa45c4e0636847d5a7205390cbb999be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a124e122244922be5dc343f2ba2592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[78] | PESQ:[1.56] | STOI:[0.86] | Loss:[0.012072423006511512]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def940b2057a40ffadae26413a3fd03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474c4c4c9f6c4b39a0da4adb90fed624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[79] | PESQ:[1.58] | STOI:[0.86] | Loss:[0.012033027665342292]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8e3da558d8428c9a1632033e736076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch[1/195756]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ed9252b0d14fc2ac40b6a2e798336e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation[1/?]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[80] | PESQ:[1.58] | STOI:[0.86] | Loss:[0.012054206390623538]\n"
     ]
    }
   ],
   "source": [
    "def crn(hp: dict = crn_hp):\n",
    "    global pf_train_totals, pf_train_num_loops, pf_eval_total, pf_eval_num_loops\n",
    "    pf_train_totals = [0,0]                                                     ###\n",
    "    pf_train_num_loops = 0                                                      ###\n",
    "    pf_eval_total = 0\n",
    "    pf_eval_num_loops = 0\n",
    "    try:\n",
    "        datestring_at_start = datetime_string()\n",
    "        os.mkdir(f\"saved_models/crn_{datestring_at_start}\")\n",
    "\n",
    "        from models.wavecrn import ConvBSRU\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        out = {\"hp\": hp}\n",
    "        model = ConvBSRU(frame_size=hp[\"frame_size\"], conv_channels=256, stride=48, num_layers=6, dropout=0.0).to(device=device)\n",
    "        if hp[\"load\"] != None:\n",
    "            model.load_state_dict(torch.load(hp[\"load\"], weights_only=True))\n",
    "        out[\"model\"] = model\n",
    "        \n",
    "        # optimizer = torch.optim.Adam(model.parameters(),lr=hp[\"lr\"])\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=hp[\"lr\"])\n",
    "        criterion = nn.L1Loss()\n",
    "        out[\"optimizer\"] = \"Adam\"\n",
    "        out[\"criterion\"] = \"L1Loss\"\n",
    "\n",
    "        _dataset = SortedBatchDataset(get_sequential_wav_paths(\"data/mixed/train\"), \n",
    "                                      get_sequential_wav_paths(\"data/speech_ordered/train\"), \n",
    "                                      batch_size=hp[\"batch_size\"])\n",
    "        train_dataset, val_dataset = _dataset.split(0.2)\n",
    "        del _dataset\n",
    "        base_train_dataloader = DataLoader(train_dataset, shuffle=SHUFFLE)\n",
    "        base_val_dataloader = DataLoader(val_dataset)\n",
    "\n",
    "        def train_step(engine, batch):\n",
    "            global pf_train_totals, pf_train_num_loops\n",
    "            pf_train_forward = time.perf_counter_ns()                               ###\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            x, y = batch[0].to(device), batch[1].to(device)\n",
    "            y_pred = model(x)\n",
    "            pf_train_totals[0] += (time.perf_counter_ns() - pf_train_forward)       ###\n",
    "            pf_train_back = time.perf_counter_ns()                                  ###\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pf_train_totals[1] += (time.perf_counter_ns() - pf_train_back)          ###\n",
    "            pf_train_num_loops += 1                                                 ###\n",
    "            return loss.item()\n",
    "\n",
    "        trainer = Engine(train_step)\n",
    "        register_custom_events(trainer)\n",
    "        RunningAverage(output_transform=lambda x: x).attach(trainer,'loss')\n",
    "        pbar = ProgressBar(desc=\"Training Epoch\")\n",
    "        pbar.attach(trainer,['loss'])\n",
    "\n",
    "        trainer.add_event_handler(Events.STARTED, set_engine_custom_keys)\n",
    "        trainer.add_event_handler(Events.EPOCH_COMPLETED(once=1),set_iteration_ceiling)\n",
    "\n",
    "        train_dataloader = FrameLoader(base_train_dataloader, hp[\"frame_size\"], hp[\"frame_shift\"], batch_size=hp[\"batch_size\"], engine=trainer, output_transform=lambda x: x.view((hp[\"batch_size\"],1,-1)))\n",
    "\n",
    "        \n",
    "        proc_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"], output_transform=lambda x: x.view((hp[\"batch_size\"],1,-1)))\n",
    "        clean_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"], output_transform=lambda x: x.view((hp[\"batch_size\"],1,-1)))\n",
    "        def val_step(engine, batch):\n",
    "            global pf_eval_total, pf_eval_num_loops\n",
    "            pf_eval_forward = time.perf_counter_ns()                                ###\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                x, y = batch[0].to(device), batch[1].to(device)\n",
    "                y_pred = model(x)\n",
    "                pf_eval_total += (time.perf_counter_ns() - pf_eval_forward)         ###\n",
    "                pf_eval_num_loops += 1                                              ###\n",
    "                proc_frame_constructor.add_frame(y_pred)\n",
    "                clean_frame_constructor.add_frame(y)\n",
    "                if batch[2]:    #   Frame fully constructed\n",
    "                    y_pred_stitch = proc_frame_constructor.get_current_audio()\n",
    "                    y_stitch = clean_frame_constructor.get_current_audio()\n",
    "                    proc_frame_constructor.reset()\n",
    "                    clean_frame_constructor.reset()\n",
    "                    return y_pred, y, {\"stitch_proc\": y_pred_stitch, \"stitch_clean\": y_stitch}\n",
    "\n",
    "                return y_pred, y\n",
    "\n",
    "        validator = Engine(val_step)\n",
    "        pbar = ProgressBar(desc=\"Validation\")\n",
    "        pbar.attach(validator,['loss'])\n",
    "        val_metrics: dict[str, Metric] = {\n",
    "            \"loss\": Loss(criterion, output_transform=lambda x: (x[0],x[1])),\n",
    "            \"pesq\": PESQMetric(),\n",
    "            \"stoi\": STOIMetric()\n",
    "        }\n",
    "        for name, metric in val_metrics.items():\n",
    "            metric.attach(validator, name)\n",
    "\n",
    "        checkpoint_to_save = {\"model\":model}\n",
    "        checkpoint_handler = Checkpoint(\n",
    "            checkpoint_to_save, f\"saved_models/crn_{datestring_at_start}\",\n",
    "            filename_prefix=\"best\", score_function=lambda eng: eng.state.metrics['pesq'],n_saved=2\n",
    "        )\n",
    "\n",
    "        metrics_out = []\n",
    "        out[\"metrics\"] = metrics_out\n",
    "        val_dataloader = FrameLoader(base_val_dataloader, hp[\"frame_size\"], hp[\"frame_shift\"],\n",
    "                                     hp[\"batch_size\"],output_transform=lambda x: x.view((hp[\"batch_size\"],1,-1)))\n",
    "        trainer.add_event_handler(Events.EPOCH_COMPLETED,run_eval,validator=validator,val_frame_loader=val_dataloader)\n",
    "        trainer.add_event_handler(ValidationEvents.VALIDATION_COMPLETED,log_eval_results,validator=validator,metrics_out=metrics_out)\n",
    "        validator.add_event_handler(Events.COMPLETED, checkpoint_handler)\n",
    "\n",
    "\n",
    "        time_train = time.perf_counter_ns()\n",
    "        trainer.run(train_dataloader, max_epochs=hp[\"epochs\"])\n",
    "        out[\"total_time\"] = time.perf_counter_ns() - time_train\n",
    "        out[\"fwd\"]=pf_train_totals[0] / float(pf_train_num_loops)                        ###\n",
    "        out[\"bck\"]=pf_train_totals[1] / float(pf_train_num_loops)                        ###\n",
    "        out[\"eval\"]=pf_eval_total / float(pf_eval_num_loops)                          ###\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(traceback.print_exc())\n",
    "        print(e)    \n",
    "    finally:\n",
    "        if \"model\" in locals():\n",
    "            if hp[\"save\"]:\n",
    "                torch.save(model.state_dict(),f\"saved_models/crn_{datestring_at_start}/final.pt\")\n",
    "                json_dict = {k: out[k] for k in out.keys() - {'model'}}\n",
    "                with open(f\"saved_models/crn_{datestring_at_start}/out.json\",\"w\") as f:\n",
    "                    json.dump(json_dict,f)\n",
    "            return out\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "if CRN_RUN_ON_LOAD:\n",
    "    crn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'crn_model' in locals(): torch.save(crn_model.state_dict(),f\"saved_models/crn_{datetime_string()}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RHR-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_hp = {\n",
    "    \"frame_size\":1024,\n",
    "    \"frame_shift\":256,\n",
    "    \"lr\":1.0e-4,\n",
    "    \"batch_size\":128,\n",
    "    \"epochs\":30,\n",
    "    \"save\":True,\n",
    "    \"load\":None,\n",
    "}\n",
    "\n",
    "RNN_RUN_ON_LOAD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(hp: dict = rnn_hp):\n",
    "    global pf_train_totals, pf_train_num_loops, pf_eval_total, pf_eval_num_loops\n",
    "    pf_train_totals = [0,0]                                                     ###\n",
    "    pf_train_num_loops = 0                                                      ###\n",
    "    pf_eval_total = 0\n",
    "    pf_eval_num_loops = 0\n",
    "    try:\n",
    "        datestring_at_start = datetime_string()\n",
    "        os.mkdir(f\"saved_models/rnn_{datestring_at_start}\")\n",
    "        \n",
    "        import yaml\n",
    "        from models.rhrnetdir.Arg_Parser import Recursive_Parse\n",
    "        from models.rhrnet import RHRNet\n",
    "        rnn_hp = Recursive_Parse(yaml.load(\n",
    "            open('models/rhrnetdir/rhrnet_hyperparameters.yaml', encoding='utf-8'),\n",
    "            Loader=yaml.Loader\n",
    "            ))  \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        out = {\"hp\": hp, \"datetime_str\": datestring_at_start}\n",
    "        model = RHRNet(rnn_hp).to(device=device)\n",
    "        if hp[\"load\"] != None:\n",
    "            model.load_state_dict(torch.load(hp[\"load\"], weights_only=True))\n",
    "        out[\"model\"] = model\n",
    "        \n",
    "        optimizer = torch.optim.RMSprop(model.parameters(),lr=hp[\"lr\"])\n",
    "        out[\"model\"] = \"RMSProp\"\n",
    "\n",
    "        _dataset = SortedBatchDataset(get_sequential_wav_paths(\"data/mixed/train\"), get_sequential_wav_paths(\"data/speech_ordered/train\"), batch_size=hp[\"batch_size\"])\n",
    "        train_dataset, val_dataset = _dataset.split(0.2)\n",
    "        del _dataset\n",
    "        base_train_dataloader = DataLoader(train_dataset, shuffle=SHUFFLE)\n",
    "        base_val_dataloader = DataLoader(val_dataset)\n",
    "        print(f\"val dataset:{len(val_dataset)}\")\n",
    "\n",
    "        def train_step(engine, batch):\n",
    "            global pf_train_totals, pf_train_num_loops\n",
    "            pf_train_forward = time.perf_counter_ns()                               ###\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            x, y = batch[0].to(device), batch[1].to(device)\n",
    "            y_pred = model(x)\n",
    "            pf_train_totals[0] += (time.perf_counter_ns() - pf_train_forward)       ###\n",
    "            pf_train_back = time.perf_counter_ns()                                  ###\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pf_train_totals[1] += (time.perf_counter_ns() - pf_train_back)          ###\n",
    "            pf_train_num_loops += 1                                                 ###\n",
    "            return loss.item()\n",
    "\n",
    "        trainer = Engine(train_step)\n",
    "        register_custom_events(trainer)\n",
    "        RunningAverage(output_transform=lambda x: x).attach(trainer,'loss')\n",
    "        pbar = ProgressBar(desc=\"Training Epoch\")\n",
    "        pbar.attach(trainer,['loss'])\n",
    "\n",
    "        trainer.add_event_handler(Events.STARTED, set_engine_custom_keys)\n",
    "        trainer.add_event_handler(Events.EPOCH_COMPLETED(once=1),set_iteration_ceiling)\n",
    "\n",
    "        train_dataloader = FrameLoader(base_train_dataloader, hp[\"frame_size\"], hp[\"frame_shift\"], batch_size=hp[\"batch_size\"], engine=trainer, output_transform=lambda x: x.view((hp[\"batch_size\"],-1)))\n",
    "\n",
    "        proc_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"], output_transform=lambda x: x.view((hp[\"batch_size\"],-1)))\n",
    "        clean_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"], output_transform=lambda x: x.view((hp[\"batch_size\"],-1)))\n",
    "        def val_step(engine, batch):\n",
    "            global pf_eval_total, pf_eval_num_loops\n",
    "            pf_eval_forward = time.perf_counter_ns()                                ###\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                x, y = batch[0].to(device), batch[1].to(device)\n",
    "                y_pred = model(x)\n",
    "                pf_eval_total += (time.perf_counter_ns() - pf_eval_forward)         ###\n",
    "                pf_eval_num_loops += 1                                              ###\n",
    "                proc_frame_constructor.add_frame(y_pred)\n",
    "                clean_frame_constructor.add_frame(y)\n",
    "                if batch[2]:    #   Frame fully constructed\n",
    "                    y_pred_stitch = proc_frame_constructor.get_current_audio()\n",
    "                    y_stitch = clean_frame_constructor.get_current_audio()\n",
    "                    proc_frame_constructor.reset()\n",
    "                    clean_frame_constructor.reset()\n",
    "                    return y_pred, y, {\"stitch_proc\": y_pred_stitch, \"stitch_clean\": y_stitch}\n",
    "\n",
    "                return y_pred, y\n",
    "\n",
    "        validator = Engine(val_step)\n",
    "        pbar = ProgressBar(desc=\"Validation\")\n",
    "        pbar.attach(validator,['loss'])\n",
    "        val_metrics: dict[str, Metric] = {\n",
    "            \"loss\": Loss(criterion, output_transform=lambda x: (x[0],x[1])),\n",
    "            \"pesq\": PESQMetric(),\n",
    "            \"stoi\": STOIMetric()\n",
    "        }\n",
    "\n",
    "        for name, metric in val_metrics.items():\n",
    "            metric.attach(validator, name)\n",
    "\n",
    "        checkpoint_to_save = {\"model\":model}\n",
    "        checkpoint_handler = Checkpoint(\n",
    "            checkpoint_to_save, f\"saved_models/rnn_{datestring_at_start}\",\n",
    "            filename_prefix=\"best\", score_function=lambda eng: eng.state.metrics['pesq'],n_saved=2\n",
    "        )\n",
    "\n",
    "        metrics_out = []\n",
    "        out[\"metrics\"] = metrics_out\n",
    "        val_dataloader = FrameLoader(base_val_dataloader, hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"])\n",
    "        trainer.add_event_handler(Events.EPOCH_COMPLETED,run_eval,validator=validator,val_frame_loader=val_dataloader)\n",
    "        trainer.add_event_handler(ValidationEvents.VALIDATION_COMPLETED,log_eval_results,validator=validator,metrics_out=metrics_out)\n",
    "        validator.add_event_handler(Events.COMPLETED, checkpoint_handler)\n",
    "\n",
    "        time_train = time.perf_counter_ns()\n",
    "        trainer.run(train_dataloader, max_epochs=hp[\"epochs\"])\n",
    "        out[\"total_time\"] = time.perf_counter_ns() - time_train\n",
    "        out[\"fwd\"]=pf_train_totals[0] / float(pf_train_num_loops)                        ###\n",
    "        out[\"bck\"]=pf_train_totals[1] / float(pf_train_num_loops)                        ###\n",
    "        out[\"eval\"]=pf_eval_total / float(pf_eval_num_loops)                          ###\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "    finally:\n",
    "        if \"model\" in locals():\n",
    "            if hp[\"save\"]:\n",
    "                torch.save(model.state_dict(),f\"saved_models/rnn_{datestring_at_start}/final.pt\")\n",
    "                with open(f\"saved_models/rnn_{datestring_at_start}/out.json\",\"w\") as f:\n",
    "                    json.dump({k: out[k] for k in out.keys() - {'model'}},f)\n",
    "            return out\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "if RNN_RUN_ON_LOAD:\n",
    "    rnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=ns_to_sec(pf_train_totals[0] / float(pf_train_num_loops))                         ###\n",
    "b=ns_to_sec(pf_train_totals[1] / float(pf_train_num_loops))                         ###\n",
    "c=ns_to_sec(pf_eval_total / float(pf_train_num_loops/4))                            ###\n",
    "print(f\"train forward:{a:.20f} | backprop:{b:.20f} | eval forward:{c:.20f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'rnn_model' in locals(): torch.save(rnn_model.state_dict(),f\"saved_models/rnn_{datetime.datetime.now().strftime(\"%d-%m-%Y--%H-%M-%S\")}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wave-U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_FRAME_SIZE = 16153\n",
    "CNN_OUT_FRAME_SIZE = 16009\n",
    "CNN_FRAME_SHIFT = CNN_FRAME_SIZE / 4\n",
    "CNN_LR = 1.0e-4\n",
    "\n",
    "CNN_PREP = True\n",
    "CNN_TRAIN = False\n",
    "CNN_LOAD= False\n",
    "CNN_SAVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'cnn_model' in locals(): torch.save(cnn_model.state_dict(),f\"saved_models/cnn_{datetime.datetime.now().strftime(\"%d-%m-%Y--%H-%M-%S\")}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Running Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeDataset(Dataset):\n",
    "    def __init__(self, l_waveforms: list, r_waveforms:list):\n",
    "        self.l_waveforms = l_waveforms\n",
    "        self.r_waveforms = r_waveforms\n",
    "        super().__init__()\n",
    "    def __len__(self):\n",
    "        return len(self.l_waveforms)\n",
    "    def __getitem__(self,idx):\n",
    "        # return self.l_waveforms[idx], self.r_waveforms[idx]\n",
    "        # print(torch.tensor(self.l_waveforms[idx]).unsqueeze_(0))\n",
    "        # print(torch.tensor(self.l_waveforms[idx]).unsqueeze_(0).shape,flush=True)\n",
    "\n",
    "        return torch.tensor(self.l_waveforms[idx]).unsqueeze_(0), torch.tensor(self.r_waveforms[idx]).unsqueeze_(0)\n",
    "\n",
    "def evaluate_e2e_one_sample(model_dict: dict):\n",
    "    chosen_sample = ntpath.basename(random.choice(glob.glob(\"data/speech_ordered/train/*.wav\")))\n",
    "    clean_sample,_ = torchaudio.load(\"data/speech_ordered/train/\" + chosen_sample)\n",
    "    mixed_sample,_ = torchaudio.load(\"data/mixed/train/\" + chosen_sample)\n",
    "    ds = FakeDataset([mixed_sample],[clean_sample])\n",
    "    dl = DataLoader(ds)\n",
    "    out = {}\n",
    "    for name in model_dict.keys():\n",
    "        out[name] = {}\n",
    "        out[name][\"model\"] = model_dict[name]\n",
    "        match name:\n",
    "            case \"cnn\":\n",
    "                out[name][\"loader\"] = FrameLoader(dl,CNN_FRAME_SIZE,CNN_FRAME_SHIFT, batch_size=1)\n",
    "                out[name][\"processed_constructor\"] = FrameReconstructor(CNN_OUT_FRAME_SIZE,CNN_FRAME_SHIFT, batch_size=1)\n",
    "                out[name][\"clean_constructor\"] = FrameReconstructor(CNN_OUT_FRAME_SIZE,CNN_FRAME_SHIFT, batch_size=1)\n",
    "            case \"rnn\":\n",
    "                out[name][\"loader\"] = FrameLoader(dl,RNN_FRAME_SIZE,RNN_FRAME_SHIFT, batch_size=1)\n",
    "                out[name][\"processed_constructor\"] = FrameReconstructor(RNN_FRAME_SIZE,RNN_FRAME_SHIFT, batch_size=1)\n",
    "                out[name][\"clean_constructor\"] = FrameReconstructor(RNN_FRAME_SIZE,RNN_FRAME_SHIFT, batch_size=1)\n",
    "            case \"crn\":\n",
    "                out[name][\"loader\"] = FrameLoader(dl,CRN_FRAME_SIZE,CRN_FRAME_SHIFT, batch_size=1, output_transform=lambda x: x.reshape(1,1,-1))\n",
    "                out[name][\"processed_constructor\"] = FrameReconstructor(CRN_FRAME_SIZE,CRN_FRAME_SHIFT, batch_size=1)\n",
    "                out[name][\"clean_constructor\"] = FrameReconstructor(CRN_FRAME_SIZE,CRN_FRAME_SHIFT, batch_size=1)\n",
    "            # case \"gan\":\n",
    "            #     out[name][\"loader\"] = FrameLoader(dl,GAN_FRAME_SIZE,GAN_FRAME_SHIFT)\n",
    "            case _:\n",
    "                pass\n",
    "        out[name][\"perf\"] = {\"e2e_time\":0, \"avg_forward\":0}\n",
    "    # print(\"shape__:\" + str(clean_sample.shape))\n",
    "    out[\"num_frames\"] = clean_sample.shape[1]\n",
    "    \n",
    "    for name in model_dict.keys():\n",
    "        # print(name)\n",
    "        # print(out[name],flush=True)\n",
    "        at_end = False\n",
    "        model = out[name][\"model\"]\n",
    "        data = iter(out[name][\"loader\"])\n",
    "        pf_eval_total = 0\n",
    "        n_loops = 0\n",
    "        pf_eval_e2e = time.perf_counter_ns()\n",
    "        while not at_end:\n",
    "            pf_eval_forward = time.perf_counter_ns()\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                x, y, at_end = next(data)\n",
    "                x = x.to(device=device)\n",
    "                y = y.to(device=device)\n",
    "                y_pred = model(x)\n",
    "                pf_eval_total += (time.perf_counter_ns() - pf_eval_forward)\n",
    "                n_loops += 1\n",
    "                try:\n",
    "                    out[name][\"processed_constructor\"].add_frame(y_pred)\n",
    "                    out[name][\"clean_constructor\"].add_frame(y)\n",
    "                except RuntimeError as e:\n",
    "                    print(out[name][\"processed_constructor\"].audio.shape)\n",
    "                    raise RuntimeError(e.args)\n",
    "                \n",
    "\n",
    "                if at_end:    #   Frame fully constructed\n",
    "                    y_pred_stitch = out[name][\"processed_constructor\"].get_current_audio()\n",
    "                    y_stitch = out[name][\"clean_constructor\"].get_current_audio()\n",
    "                    print(y_pred_stitch.shape)\n",
    "                    print(y_stitch.shape)\n",
    "                    display.display(Audio(y_pred_stitch[0][0],rate=16000))\n",
    "                    display.display(Audio(y_stitch[0][0],rate=16000))\n",
    "                    \n",
    "        \n",
    "        pf_eval_e2e = time.perf_counter_ns() - pf_eval_e2e\n",
    "        out[name][\"perf\"][\"e2e_time\"] = pf_eval_e2e\n",
    "        out[name][\"perf\"][\"avg_forward\"] = pf_eval_total / float(n_loops)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crn_model = ConvBSRU(frame_size=CRN_FRAME_SIZE, conv_channels=256, stride=48, num_layers=6, dropout=0.0).to(device=device)\n",
    "crn_model.load_state_dict(torch.load(\"saved_models/crn.pt\", weights_only=True))\n",
    "models = {  \"crn\": crn_model }#, \"rnn\": rnn_model}#, \"cnn\": cnn_model,}\n",
    "out = evaluate_e2e_one_sample(models)\n",
    "\n",
    "print(\"Duration of audio: \" + str(out[\"num_frames\"] / 16000.0))\n",
    "for name in models.keys():\n",
    "    model_dict = out[name]\n",
    "    print(f\"{name.upper()} -- e2e:{ns_to_sec(model_dict[\"perf\"][\"e2e_time\"])}, average forward:{ns_to_sec(model_dict[\"perf\"][\"avg_forward\"])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
