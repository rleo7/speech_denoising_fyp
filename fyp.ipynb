{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda env update --file environment.yml --prune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:dbg:cuda:0\n",
      "DEBUG:dbg:2.6.0+cu124\n",
      "DEBUG:dbg:NVIDIA GeForce GTX 1060 6GB\n",
      "DEBUG:dbg:['ffmpeg', 'soundfile']\n"
     ]
    }
   ],
   "source": [
    "import os, random, glob, logging, ntpath, math, time, sys, datetime, json, traceback\n",
    "from typing import Callable\n",
    "from IPython import display\n",
    "from IPython.display import Audio\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# pd.options.display.max_seq_items = 2000\n",
    "pd.set_option(\"display.max_colwidth\",None)\n",
    "\n",
    "logging.basicConfig()\n",
    "logger=logging.getLogger(\"dbg\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.disable(logging.NOTSET)\n",
    "perf_logger=logging.getLogger(\"perf\")\n",
    "perf_logger.setLevel(logging.DEBUG)\n",
    "# logging.disable(logging.DEBUG)\n",
    "\n",
    "import torch, torchaudio\n",
    "import torch.nn as nn\n",
    "import torchaudio.functional as audioF\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "logger.debug(device)\n",
    "logger.debug(torch.__version__)\n",
    "logger.debug(torch.cuda.get_device_name(device))\n",
    "logger.debug(torchaudio.list_audio_backends())\n",
    "\n",
    "from ignite.engine import Engine, Events, EventEnum\n",
    "from ignite.metrics import Loss, Metric, RunningAverage\n",
    "from ignite.metrics.metric import reinit__is_reduced, sync_all_reduce\n",
    "from ignite.exceptions import NotComputableError\n",
    "from ignite.handlers.tqdm_logger import ProgressBar\n",
    "from ignite.handlers import Checkpoint, DiskSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE = True\n",
    "SAMPLE_RATE = 16000\n",
    "MAXIMUM_SAMPLE_NUM_OF_FRAMES = 640000   #   SAMPLE_RATE*40, i.e. 40 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic\n",
    "from IPython import get_ipython\n",
    "\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    return\n",
    "\n",
    "@register_cell_magic\n",
    "def skip_if(line, cell):\n",
    "    if eval(line):\n",
    "        return\n",
    "    get_ipython().run_cell(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystoi\n",
    "import pesq\n",
    "\n",
    "def combine_audio(speech: torch.Tensor, noise: torch.Tensor, snr: torch.Tensor | int) -> torch.Tensor:\n",
    "    if not (torch.is_floating_point(speech) or torch.is_complex(speech)):\n",
    "        # speech = torch.tensor(speech, dtype=torch.float64, device=speech.device)\n",
    "        speech = speech.to(torch.float64,non_blocking=True)\n",
    "    if not (torch.is_floating_point(noise) or torch.is_complex(noise)):\n",
    "        # noise = torch.tensor(noise, dtype=torch.float64, device=noise.device)\n",
    "        noise = noise.to(torch.float64,non_blocking=True)\n",
    "    if not(type(snr) is torch.Tensor):\n",
    "        snr = torch.tensor([snr])\n",
    "    logger.debug(f\"speech:{speech.ndim}, noise:{noise.ndim}, snr:{snr.ndim}\")\n",
    "    out = audioF.add_noise(speech, noise, snr).to(dtype=torch.float)\n",
    "    return out\n",
    "\n",
    "def calc_pesq(speech: np.ndarray, processed: np.ndarray) -> float:\n",
    "    return pesq.pesq(ref=speech, deg=processed, fs=SAMPLE_RATE)\n",
    "\n",
    "def calc_stoi(speech: np.ndarray, processed: np.ndarray) -> float:\n",
    "    return pystoi.stoi(x=speech, y=processed, fs_sig=SAMPLE_RATE)\n",
    "\n",
    "def ns_to_sec(ns: int) -> float:\n",
    "    return ns/1000000000.0\n",
    "\n",
    "def datetime_string() -> str:\n",
    "    return datetime.datetime.now().strftime(\"%d-%m-%Y--%H-%M-%S\")\n",
    "\n",
    "def plot_waveform(waveform, sample_rate=SAMPLE_RATE):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
    "        axes[c].grid(True)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
    "    figure.suptitle(\"waveform\")\n",
    "\n",
    "def write_fstring_file(model_name: str, format_string: str, **args):\n",
    "    with open(f\"saved_models/{model_name}_{datetime_string()}.txt\") as f:\n",
    "        f.write(format_string.format(**args))\n",
    "\n",
    "def standardize_batch(batch: torch.Tensor, coerce_func = lambda x: x) -> torch.Tensor:\n",
    "    b = batch.squeeze()\n",
    "    if len(b.shape) == 2:\n",
    "        return b\n",
    "    elif len(b.shape) == 1:\n",
    "        return b.unsqueeze(dim=0)\n",
    "    else:\n",
    "        return coerce_func(b)\n",
    "    \n",
    "def calc_windowing(data_len: int, frame_size: int, frame_shift: int):\n",
    "    num_frames = 0\n",
    "    spare = 0\n",
    "    c = data_len - frame_size\n",
    "    if c < 1:\n",
    "        return 0, 0, 0\n",
    "    num_frames += 1\n",
    "    num_frames += c // frame_shift\n",
    "    spare = c % frame_shift\n",
    "    to_pad = frame_shift - spare\n",
    "    return num_frames, spare, to_pad\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def get_sequential_wav_paths(dir):\n",
    "    count = len(glob.glob(\"*.wav\", root_dir=dir))\n",
    "    lst = []\n",
    "    for i in range(1,count+1):\n",
    "        lst.append(dir + \"/\" + str(i) + \".wav\")\n",
    "    \n",
    "    return lst\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, data: list, root_dir: str | None = None):\n",
    "        self.data = data\n",
    "        if root_dir==None:\n",
    "            root_dir = os.getcwd()+\"/data\"\n",
    "        self.root_dir = root_dir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        wave, _ = torchaudio.load(self.root_dir + \"/\" + self.data[idx], format=\"wav\")\n",
    "        return wave\n",
    "    \n",
    "class SortedBatchDataset(Dataset):\n",
    "    def __init__(self, mixed: list, clean: list, batch_size: int):\n",
    "        self.mixed = mixed\n",
    "        self.clean = clean\n",
    "        self.batch_size = batch_size\n",
    "        # if root_dir==None:\n",
    "        #     root_dir = os.getcwd()+\"/data\"\n",
    "        # self.root_dir = root_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.floor(len(self.mixed)/self.batch_size)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        mixeds = []\n",
    "        cleans = []\n",
    "        max_len = 0\n",
    "        for i in range(self.batch_size):\n",
    "            if idx + i > len(self.mixed): continue\n",
    "            mixed_wave, _ = torchaudio.load(self.mixed[idx*self.batch_size+i])\n",
    "            clean_wave, _ = torchaudio.load(self.clean[idx*self.batch_size+i])\n",
    "            mixed_wave = mixed_wave[0]\n",
    "            clean_wave = clean_wave[0]\n",
    "            assert(mixed_wave.shape[0]==clean_wave.shape[0])\n",
    "            if i==0:\n",
    "                max_len = mixed_wave.shape[0]\n",
    "            else:\n",
    "                mixed_wave = torch.nn.functional.pad(mixed_wave,(0,max_len-(mixed_wave.shape[0])),value=0.0)\n",
    "                clean_wave = torch.nn.functional.pad(clean_wave,(0,max_len-(clean_wave.shape[0])),value=0.0)\n",
    "            # logger.debug(mixed_wave)\n",
    "            mixeds.append(mixed_wave)\n",
    "            cleans.append(clean_wave)\n",
    "        mixeds = np.asarray(mixeds)\n",
    "        cleans = np.asarray(cleans)\n",
    "        return torch.tensor(mixeds), torch.tensor(cleans)\n",
    "\n",
    "    def split(self, val_pct, seed=None):\n",
    "        rnd = random.Random(seed)\n",
    "        this_len = len(self)\n",
    "        val_batches = math.floor(this_len*val_pct)\n",
    "        val_indices = sorted(rnd.sample(range(this_len), val_batches))\n",
    "        train_mixed = []\n",
    "        train_clean = []\n",
    "        val_mixed = []\n",
    "        val_clean = []\n",
    "        for i in range(this_len):\n",
    "            if i in val_indices:\n",
    "                for x in range(self.batch_size):\n",
    "                    val_mixed.append(self.mixed[i*self.batch_size+x])\n",
    "                    val_clean.append(self.clean[i*self.batch_size+x])\n",
    "            else:\n",
    "                for x in range(self.batch_size):\n",
    "                    train_mixed.append(self.mixed[i*self.batch_size+x])\n",
    "                    train_clean.append(self.clean[i*self.batch_size+x])\n",
    "        \n",
    "        return SortedBatchDataset(train_mixed,train_clean,self.batch_size), SortedBatchDataset(val_mixed,val_clean,self.batch_size)\n",
    "\n",
    "class FrameLoaderEvents(EventEnum):\n",
    "    END_OF_BATCH = \"end_of_batch\"\n",
    "\n",
    "class FrameLoader():\n",
    "    '''Takes a dataloader, frame size and frame shift. It can then be iterated over to produce frames.\\n\n",
    "    Provides padding when sample length would be exceeded.\\n\n",
    "    Returns (mix, clean, has_batch_ended)'''\n",
    "\n",
    "    def __init__(self, dl: DataLoader, frame_size: int, frame_shift: int, batch_size: int, engine: Engine | None = None, output_transform = lambda x: x):\n",
    "        self.dl = dl\n",
    "        self.dl_iter = iter(dl)\n",
    "        self.batch_count = len(dl)\n",
    "        self.frame_size = frame_size\n",
    "        self.frame_shift = frame_shift\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_mixed: torch.Tensor\n",
    "        self.batch_clean: torch.Tensor\n",
    "        self.frame_position = 0\n",
    "        self.at_end = True\n",
    "        self.engine = engine\n",
    "        self.output_transform = output_transform\n",
    "    def __iter__(self):\n",
    "        self.dl_iter = iter(self.dl)\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self.at_end:\n",
    "            batches: tuple[torch.Tensor,torch.Tensor] = next(self.dl_iter)\n",
    "            self.batch_mixed = batches[0].squeeze_()\n",
    "            if len(self.batch_mixed.shape) == 1:\n",
    "                self.batch_mixed.unsqueeze_(0)\n",
    "            self.batch_clean = batches[1].squeeze_()\n",
    "            if len(self.batch_clean.shape) == 1:\n",
    "                self.batch_clean.unsqueeze_(0)\n",
    "            self.frame_position = 0\n",
    "            self.at_end = False\n",
    "            # logger.debug(f\"mixed batch shape:{self.batch_mixed.shape} | clean batch shape:{self.batch_clean.shape}\")\n",
    "            # mix_maxes = [torch.max(s[0]) for s in self.batch_mixed]\n",
    "            # clean_maxes = [torch.max(s[0]) for s in self.batch_clean]\n",
    "            # logger.debug(f\"mix_maxes:{str(mix_maxes)} | clean_maxes:{str(clean_maxes)}\")\n",
    "        \n",
    "        frame_end = self.frame_position + self.frame_size\n",
    "        frames = []\n",
    "        for batch_i, batch in enumerate([self.batch_mixed, self.batch_clean]):\n",
    "            shp = batch.shape\n",
    "            frame: torch.Tensor\n",
    "            if frame_end >= shp[-1]:\n",
    "                if self.engine is not None and batch_i==0: \n",
    "                    self.engine.fire_event(FrameLoaderEvents.END_OF_BATCH)\n",
    "                self.at_end = True\n",
    "                if frame_end != shp[-1]:\n",
    "                    diff = frame_end - shp[-1]\n",
    "                    # Pad batch until aligned with frame_end\n",
    "                    frame = torch.zeros((self.batch_size, self.frame_size), dtype=torch.float32)\n",
    "                    frame[:, 0:self.frame_size - diff] = batch[:, self.frame_position:shp[-1]]\n",
    "                else:\n",
    "                    frame = torch.zeros((self.batch_size, self.frame_size), dtype=torch.float32)\n",
    "                    frame[:, 0:self.frame_size] = batch[:, self.frame_position:frame_end]\n",
    "            else:\n",
    "                frame = torch.zeros((self.batch_size, self.frame_size), dtype=torch.float32)\n",
    "                frame[:, 0:self.frame_size] = batch[:, self.frame_position:frame_end]\n",
    "            frames.append(self.output_transform(frame))\n",
    "\n",
    "        self.frame_position += self.frame_shift\n",
    "        # logger.debug(f\"FrameLoader: frame_position[{self.frame_position}] - frame_end[{frame_end}]\")\n",
    "        # perf_logger.debug(f\"Time to load frame at ({self.frame_position}): {time.perf_counter() - start}s\")\n",
    "\n",
    "        try:\n",
    "\n",
    "            if frames[0].shape[-1] != self.frame_size:\n",
    "                logger.debug(frames[0].shape[-1])\n",
    "                logger.debug(\"FrameLoader issue\")\n",
    "        except Exception as e:\n",
    "            print(frames[0].shape)\n",
    "            raise Exception(e.args)\n",
    "        \n",
    "        return frames[0], frames[1], self.at_end\n",
    "\n",
    "class FrameReconstructor():\n",
    "    '''Constructs a batch of audio samples by continuously adding (batches of) frames to the end of a buffer, excluding overlapping sections.\\n\n",
    "    Use `add_frame()` to return the constructed samples, up to the last batch of frames added.\n",
    "    Use `add_presliced()` when audio data to add should not be treated as an overlapping frame as defined at the constructor's start.\n",
    "    '''\n",
    "    def __init__(self, frame_size: int, frame_shift: int, batch_size: int, output_transform = lambda x: x):\n",
    "        self.audio: torch.Tensor = torch.zeros((batch_size, MAXIMUM_SAMPLE_NUM_OF_FRAMES),dtype=torch.float)\n",
    "        self.frame_size = frame_size\n",
    "        self.frame_shift = frame_shift\n",
    "        self.pos: int = 0\n",
    "        self.end: int = frame_size\n",
    "        self.frame_slice_start: int = 0\n",
    "        self.at_end = False\n",
    "        self.output_transform = output_transform\n",
    "    \n",
    "    def add_frame(self, batch: torch.Tensor, _at_end = False):\n",
    "        '''Adds a frame to the end of currently stored audio. Slices the frame to remove overlap.'''\n",
    "        batch = standardize_batch(batch)\n",
    "        batch = batch.reshape((self.audio.shape[0], batch.shape[-1]))\n",
    "        self.audio[:,self.pos:self.end] = batch[:,self.frame_slice_start:]\n",
    "\n",
    "        self.pos = self.end\n",
    "        self.end += self.frame_shift\n",
    "        self.frame_slice_start = self.frame_size - self.frame_shift\n",
    "\n",
    "        # if _at_end: \n",
    "        #     return True\n",
    "        # return False\n",
    "\n",
    "        #   Remove if _at_end ends up doing something\n",
    "        return _at_end\n",
    "    \n",
    "    def add_presliced(self, batch: torch.Tensor):\n",
    "        '''Appends an arbitrary amount of audio data to the end of currently stored audio.'''\n",
    "        batch = standardize_batch(batch)\n",
    "        batch = batch.reshape((self.audio.shape[0], batch.shape[1]))\n",
    "        self.audio[:,self.pos:self.pos+batch.shape[1]] = batch[:,0:]\n",
    "\n",
    "        self.pos += batch.shape[1]\n",
    "    \n",
    "    def get_current_audio(self) -> torch.Tensor:\n",
    "        out = self.audio[:,0:self.end - self.frame_shift].clone().detach()\n",
    "        # out = torch.tensor(self.audio[:,0:self.end - self.frame_shift])\n",
    "        out = self.output_transform(out)\n",
    "        return out\n",
    "\n",
    "    def reset(self):\n",
    "        self.audio = torch.zeros(self.audio.shape,dtype=torch.float)\n",
    "        self.pos = 0\n",
    "        self.end = self.frame_size\n",
    "        self.frame_slice_start = 0\n",
    "        self.at_end = False\n",
    "\n",
    "\n",
    "def get_reference_batch(ds: Dataset, frame_size: int, output_transform=lambda x: x, seed=None) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    rnd = random.Random(seed)\n",
    "    while True:\n",
    "        idx = rnd.randint(0,len(ds)-1)\n",
    "        batches = ds.__getitem__(idx)\n",
    "        batch, batch2 = batches[0], batches[1]\n",
    "        print(batch.shape)\n",
    "        if batch.shape[-1] < frame_size:\n",
    "            continue\n",
    "        randpos = rnd.randint(0, batch.shape[-1]-frame_size)\n",
    "        batch = batch[:, randpos:randpos+frame_size]\n",
    "        batch2 = batch2[:, randpos:randpos+frame_size]\n",
    "        return output_transform(batch), output_transform(batch2)\n",
    "\n",
    "def get_all_frames(batch: torch.Tensor, frame_size: int, frame_shift: int, output_transform=lambda x: x) -> torch.Tensor:\n",
    "    logger.debug(f\"before standard: {batch.shape}\")\n",
    "    batch = standardize_batch(batch)\n",
    "    logger.debug(f\"after standard: {batch.shape}\")\n",
    "    out = batch.unfold(batch.ndim-1, frame_size, frame_shift)\n",
    "    out = output_transform(out)\n",
    "    return out\n",
    "\n",
    "class MultiFrameLoader():\n",
    "    '''Gets a 2D tensor of several overlapped frames. For TCNN.'''\n",
    "    def __init__(self,dl: DataLoader, frame_size: int, frame_shift: int, batch_size: int, num_frames: int, engine: Engine | None = None, output_transform = lambda x: x):\n",
    "        self.dl = dl\n",
    "        self.dl_iter = iter(dl)\n",
    "        self.batch_count = len(dl)\n",
    "        self.frame_size = frame_size\n",
    "        self.frame_shift = frame_shift\n",
    "        self.batch_size = batch_size\n",
    "        self.start_frame = 0\n",
    "        self.num_frames = num_frames\n",
    "        self.batch_mixed: torch.Tensor\n",
    "        self.batch_clean: torch.Tensor\n",
    "        self.at_end = True\n",
    "        self.engine = engine\n",
    "        self.output_transform = output_transform\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.dl_iter = iter(self.dl)\n",
    "        return self\n",
    "\n",
    "    def __next__(self) -> tuple[torch.Tensor, torch.Tensor, bool]:\n",
    "        if self.at_end:\n",
    "            self.batch_mixed, self.batch_clean = next(self.dl_iter)\n",
    "            self.batch_mixed = get_all_frames(self.batch_mixed, self.frame_size, self.frame_shift)\n",
    "            self.batch_clean = get_all_frames(self.batch_clean, self.frame_size, self.frame_shift)\n",
    "            self.start_frame = 0\n",
    "            self.at_end = False\n",
    "        spare = self.batch_mixed.shape[1] - (self.start_frame + self.num_frames)\n",
    "        if spare <= 0:\n",
    "            self.at_end = True\n",
    "            if spare == 0:\n",
    "                _num_frames = self.num_frames\n",
    "            else:\n",
    "                _num_frames = self.num_frames + spare   #   i.e. self.num_frames - abs(spare)\n",
    "        else:\n",
    "            _num_frames = self.num_frames\n",
    "        out = (self.output_transform(self.batch_mixed.narrow(1, self.start_frame, _num_frames)),\n",
    "                self.output_transform(self.batch_clean.narrow(1, self.start_frame, _num_frames)),\n",
    "                self.at_end)\n",
    "        self.start_frame += _num_frames\n",
    "        return out\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.MSELoss()\n",
    "\n",
    "pf_train_totals = [0,0]                                                     ###\n",
    "pf_train_num_loops = 0                                                      ###\n",
    "pf_eval_total = 0\n",
    "pf_eval_num_loops = 0\n",
    "\n",
    "class PESQMetric(Metric):\n",
    "    def __init__(self, stitch_keys=(\"stitch_proc\",\"stitch_clean\"), output_transform = lambda x: x, device=device):\n",
    "        self.stitch_keys=stitch_keys\n",
    "        self.running_total=0.0\n",
    "        self.num=0\n",
    "        super().__init__(output_transform, device)\n",
    "    @reinit__is_reduced\n",
    "    def reset(self):\n",
    "        self.running_total=0.0\n",
    "        self.num=0\n",
    "        super().reset()\n",
    "    @reinit__is_reduced\n",
    "    def update(self, output):\n",
    "        if len(output)<=2 or \"stitch_proc\" not in output[2]: return\n",
    "        y_pred: np.ndarray = standardize_batch(output[2][self.stitch_keys[0]]).cpu().numpy()\n",
    "        y: np.ndarray = standardize_batch(output[2][self.stitch_keys[1]]).cpu().numpy()\n",
    "        for i in range(y.shape[0]):\n",
    "            self.running_total += calc_pesq(y[i], y_pred[i])\n",
    "            self.num += 1\n",
    "        \n",
    "    @sync_all_reduce(\"num\",\"running_total:SUM\")\n",
    "    def compute(self):\n",
    "        if self.num == 0:\n",
    "            raise NotComputableError(\"PESQ Metric must have one complete sample before computing\")\n",
    "        return self.running_total / self.num\n",
    "\n",
    "class STOIMetric(Metric):\n",
    "    def __init__(self, stitch_keys=(\"stitch_proc\",\"stitch_clean\"), output_transform = lambda x: x, device=device):\n",
    "        self.stitch_keys=stitch_keys\n",
    "        self.running_total=0.0\n",
    "        self.num=0\n",
    "        super().__init__(output_transform, device)\n",
    "    @reinit__is_reduced\n",
    "    def reset(self):\n",
    "        self.running_total=0.0\n",
    "        self.num=0\n",
    "        super().reset()\n",
    "    @reinit__is_reduced\n",
    "    def update(self, output):\n",
    "        if len(output)<=2 or \"stitch_proc\" not in output[2]: return\n",
    "        y_pred: np.ndarray = standardize_batch(output[2][self.stitch_keys[0]]).cpu().numpy()\n",
    "        y: np.ndarray = standardize_batch(output[2][self.stitch_keys[1]]).cpu().numpy()\n",
    "        for i in range(y.shape[0]):\n",
    "            self.running_total += calc_stoi(y[i], y_pred[i])\n",
    "            self.num += 1\n",
    "    @sync_all_reduce(\"num\",\"running_total:SUM\")\n",
    "    def compute(self):\n",
    "        if self.num == 0:\n",
    "            raise NotComputableError(\"STOI Metric must have one complete sample before computing\")\n",
    "        return self.running_total / self.num\n",
    "\n",
    "\n",
    "class ValidationEvents(EventEnum):\n",
    "    VALIDATION_COMPLETED = \"validation_completed\"\n",
    "\n",
    "def register_custom_events(eng: Engine):\n",
    "    eng.register_events(*FrameLoaderEvents)\n",
    "    eng.register_events(*ValidationEvents)\n",
    "\n",
    "def log_trainer_loss(eng: Engine):\n",
    "    iterations = eng.state.iteration % eng.state.iteration_ceiling\n",
    "    print(f\"Epoch[{eng.state.epoch}], Iter[{iterations}] Loss: {eng.state.output}\")\n",
    "\n",
    "def log_custom(eng: Engine, **kwargs):\n",
    "    full_dict = {**eng.state_dict(), \"epoch\": eng.state.epoch, **kwargs}\n",
    "    fmt_string: str = kwargs[\"template\"]\n",
    "    print(fmt_string.format(**full_dict))\n",
    "\n",
    "def run_eval(eng: Engine, **kwargs):\n",
    "    validator: Engine = kwargs.get(\"validator\",None)\n",
    "    val_frame_loader: FrameLoader = kwargs.get(\"val_frame_loader\",None)\n",
    "    if validator is None:\n",
    "        raise TypeError(\"log_eval_results must be passed the argument `validator` of type `Engine`\")\n",
    "    if val_frame_loader is None:\n",
    "        raise TypeError(\"log_eval_results must be passed the argument `val_frame_loader` of type `FrameLoader`\")\n",
    "    \n",
    "    validator.run(val_frame_loader)\n",
    "    eng.fire_event(ValidationEvents.VALIDATION_COMPLETED)\n",
    "\n",
    "def log_eval_results(eng: Engine, **kwargs):\n",
    "    prefix = kwargs.get(\"prefix\",\"\")\n",
    "    validator: Engine = kwargs.get(\"validator\",None)\n",
    "    if validator is None:\n",
    "        raise TypeError(\"log_eval_results must be passed the argument `validator` of type `Engine`\")\n",
    "    \n",
    "    metrics = validator.state.metrics\n",
    "    metrics_out = kwargs.get(\"metrics_out\",None)\n",
    "    if metrics_out != None:\n",
    "        metrics_out.append(metrics.copy())\n",
    "    print(f\"{prefix}Epoch[{eng.state.epoch}] | PESQ:[{metrics['pesq']:.2f}] | STOI:[{metrics['stoi']:.2f}] | Loss:[{metrics['loss']}]\")\n",
    "\n",
    "def set_engine_custom_keys(eng: Engine):\n",
    "    eng.state_dict_user_keys.append(\"iteration_ceiling\")\n",
    "    eng.state.iteration_ceiling = sys.maxsize\n",
    "\n",
    "def set_iteration_ceiling(eng: Engine, *args):\n",
    "    if len(args)==1:\n",
    "        eng.state.iteration_ceiling = args[0]\n",
    "    else:\n",
    "        eng.state.iteration_ceiling = eng.state.iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_hp = {\n",
    "    \"frame_size\":16384,\n",
    "    \"frame_shift\":8192,\n",
    "    \"g_lr\":1.0e-4,\n",
    "    \"d_lr\":1.0e-4,\n",
    "    \"batch_size\":128,\n",
    "    \"epochs\":80,\n",
    "    \"save\":True,\n",
    "    \"load\":None,\n",
    "    \"model_type\":\"gan\",\n",
    "}\n",
    "\n",
    "GAN_RUN_ON_LOAD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan(hp: dict = gan_hp):\n",
    "    global pf_train_totals, pf_train_num_loops, pf_eval_total, pf_eval_num_loops\n",
    "    pf_train_totals = [0,0]\n",
    "    pf_train_num_loops = 0\n",
    "    pf_eval_total = 0\n",
    "    pf_eval_num_loops = 0\n",
    "    try:\n",
    "        datestring_at_start = datetime_string()\n",
    "        os.mkdir(f\"saved_models/gan_{datestring_at_start}\")\n",
    "\n",
    "        from models.segan import Discriminator, Generator\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        out = {\"hp\": hp}\n",
    "        gen = Generator().to(device=device)\n",
    "        dcrim = Discriminator().to(device=device)\n",
    "\n",
    "        if hp[\"load\"] != None:\n",
    "            gen.load_state_dict(torch.load(hp[\"load\"][0], weights_only=True))\n",
    "            dcrim.load_state_dict(torch.load(hp[\"load\"][1], weights_only=True))\n",
    "        \n",
    "        g_optimizer = torch.optim.RMSprop(gen.parameters(), lr=hp[\"g_lr\"])\n",
    "        d_optimizer = torch.optim.RMSprop(dcrim.parameters(), lr=hp[\"d_lr\"])\n",
    "        criterion = nn.L1Loss()\n",
    "        out[\"optimizer\"] = str(g_optimizer).split(\"(\")[0]\n",
    "        out[\"criterion\"] = str(criterion).split(\"(\")[0]\n",
    "\n",
    "\n",
    "        _dataset = SortedBatchDataset(get_sequential_wav_paths(\"data/mixed/train\"),\n",
    "                                    get_sequential_wav_paths(\"data/speech_ordered/train\"), \n",
    "                                    batch_size=hp[\"batch_size\"])\n",
    "        train_dataset, val_dataset = _dataset.split(0.2)\n",
    "        del _dataset\n",
    "        base_train_dataloader = DataLoader(train_dataset, shuffle=SHUFFLE)\n",
    "        base_val_dataloader = DataLoader(val_dataset)\n",
    "        r = get_reference_batch(train_dataset, hp[\"frame_size\"], lambda x: x.view(hp[\"batch_size\"],1,-1))\n",
    "        ref_batch = torch.cat((r[0],r[1]),dim=1).to(device=device)\n",
    "        z = torch.zeros((hp[\"batch_size\"],1024,8)).to(device=device)\n",
    "        print(ref_batch.shape)\n",
    "\n",
    "        def train_step(engine, batch):\n",
    "            # global pf_train_totals, pf_train_num_loops\n",
    "            # pf_train_forward = time.perf_counter_ns()                               ###\n",
    "            dcrim.train()\n",
    "            dcrim.zero_grad()\n",
    "            x, y = batch[0].to(device=device), batch[1].to(device=device)\n",
    "            nn.init.normal_(z)\n",
    "            combined_batch = torch.cat((x.clone().detach(),y.clone().detach()),dim=1)\n",
    "            output = dcrim(combined_batch, ref_batch)\n",
    "            clean_loss = torch.mean((output - 1.0) ** 2)\n",
    "            clean_loss.backward()\n",
    "\n",
    "            gen_out = gen(x, z)\n",
    "            output = dcrim(torch.cat((gen_out, x), dim=1),ref_batch)\n",
    "            noisy_loss = torch.mean(output ** 2)\n",
    "            noisy_loss.backward()\n",
    "\n",
    "            d_optimizer.step()\n",
    "\n",
    "            gen.train()\n",
    "            gen.zero_grad()\n",
    "            gen_out = gen(x, z)\n",
    "            gen_noise_pair = torch.cat((gen_out, x), dim=1)\n",
    "            output = dcrim(gen_noise_pair, ref_batch)\n",
    "\n",
    "            g_loss_ = 0.5 * torch.mean((output - 1.0) ** 2)\n",
    "            l1_dist = torch.abs(torch.add(gen_out, torch.neg(y)))\n",
    "            g_cond_loss = 100 * torch.mean(l1_dist)\n",
    "            g_loss = g_loss_ + g_cond_loss\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            return g_loss.item()\n",
    "            \n",
    "        trainer = Engine(train_step)\n",
    "        register_custom_events(trainer)\n",
    "        RunningAverage(output_transform=lambda x: x).attach(trainer,'loss')\n",
    "        pbar = ProgressBar(desc=\"Training Epoch\")\n",
    "        pbar.attach(trainer,['loss'])\n",
    "\n",
    "        trainer.add_event_handler(Events.STARTED, set_engine_custom_keys)\n",
    "        trainer.add_event_handler(Events.EPOCH_COMPLETED(once=1),set_iteration_ceiling)\n",
    "\n",
    "        train_dataloader = FrameLoader(base_train_dataloader, hp[\"frame_size\"], hp[\"frame_shift\"],\n",
    "                                        hp[\"batch_size\"], engine=trainer, \n",
    "                                        output_transform=lambda x: x.view((hp[\"batch_size\"],1,-1)))\n",
    "\n",
    "        proc_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"],\n",
    "                                                    output_transform=lambda x: x.view((hp[\"batch_size\"],1,-1)))\n",
    "        clean_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"],\n",
    "                                                     output_transform=lambda x: x.view((hp[\"batch_size\"],1,-1)))\n",
    "        \n",
    "        def val_step(engine, batch):\n",
    "            with torch.no_grad():\n",
    "                # global pf_eval_total, pf_eval_num_loops\n",
    "                x, y = batch[0].to(device=device), batch[1].to(device=device)\n",
    "                nn.init.normal_(z)\n",
    "                y_pred = gen(x, z)\n",
    "                proc_frame_constructor.add_frame(y_pred)\n",
    "                clean_frame_constructor.add_frame(y)\n",
    "                if batch[2]:    #   Frame fully constructed\n",
    "                    y_pred_stitch = proc_frame_constructor.get_current_audio()\n",
    "                    y_stitch = clean_frame_constructor.get_current_audio()\n",
    "                    proc_frame_constructor.reset()\n",
    "                    clean_frame_constructor.reset()\n",
    "                    return y_pred, y, {\"stitch_proc\": y_pred_stitch, \"stitch_clean\": y_stitch}\n",
    "\n",
    "                return y_pred, y\n",
    "        \n",
    "        validator = Engine(val_step)\n",
    "        pbar = ProgressBar(desc=\"Validation\")\n",
    "        pbar.attach(validator,['loss'])\n",
    "        val_metrics: dict[str, Metric] = {\n",
    "            \"loss\": Loss(criterion, output_transform=lambda x: (x[0],x[1])),\n",
    "            \"pesq\": PESQMetric(),\n",
    "            \"stoi\": STOIMetric()\n",
    "        }\n",
    "        for name, metric in val_metrics.items():\n",
    "            metric.attach(validator, name)\n",
    "\n",
    "        checkpoint_to_save = {\"gen\": gen, \"dcrim\": dcrim}\n",
    "        checkpoint_handler = Checkpoint(\n",
    "            checkpoint_to_save, f\"saved_models/gan_{datestring_at_start}\",\n",
    "            filename_prefix=\"best\", score_function=lambda eng: eng.state.metrics['pesq'],n_saved=2\n",
    "        )\n",
    "\n",
    "        metrics_out = []\n",
    "        out[\"metrics\"] = metrics_out\n",
    "        val_dataloader = FrameLoader(base_val_dataloader, hp[\"frame_size\"], hp[\"frame_shift\"],\n",
    "                                     hp[\"batch_size\"], output_transform=lambda x: x.view((hp[\"batch_size\"],1,-1)))\n",
    "        trainer.add_event_handler(Events.EPOCH_COMPLETED,run_eval,validator=validator,val_frame_loader=val_dataloader)\n",
    "        trainer.add_event_handler(ValidationEvents.VALIDATION_COMPLETED,log_eval_results,validator=validator,metrics_out=metrics_out)\n",
    "        validator.add_event_handler(Events.COMPLETED, checkpoint_handler)\n",
    "            \n",
    "        time_train = time.perf_counter_ns()\n",
    "        trainer.run(train_dataloader, max_epochs=hp[\"epochs\"])\n",
    "        out[\"total_time\"] = time.perf_counter_ns() - time_train\n",
    "        # out[\"fwd\"]=pf_train_totals[0] / float(pf_train_num_loops)                        ###\n",
    "        # out[\"bck\"]=pf_train_totals[1] / float(pf_train_num_loops)                        ###\n",
    "        # out[\"eval\"]=pf_eval_total / float(pf_eval_num_loops)                          ###\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"failed\")\n",
    "        print(traceback.format_exc())\n",
    "        print(e)\n",
    "    \n",
    "    finally:\n",
    "        if \"dcrim\" in locals():\n",
    "            if hp[\"save\"]:\n",
    "                torch.save(gen.state_dict(),f\"saved_models/gan_{datestring_at_start}/gen_final.pt\")\n",
    "                torch.save(dcrim.state_dict(),f\"saved_models/gan_{datestring_at_start}/dcrim_final.pt\")\n",
    "                with open(f\"saved_models/gan_{datestring_at_start}/out.json\",\"w\") as f:\n",
    "                    json.dump({k: out[k] for k in out.keys() - {'gen', 'dcrim'}},f)\n",
    "            return out\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "if GAN_RUN_ON_LOAD:\n",
    "    gan()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WaveCRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crn_hp = {\n",
    "    \"frame_size\":96,\n",
    "    \"frame_shift\":40,\n",
    "    \"lr\":2.0e-5,\n",
    "    \"batch_size\":128,\n",
    "    \"epochs\":80,\n",
    "    \"save\":True,\n",
    "    \"load\":None,\n",
    "    \"model_type\":\"crn\",\n",
    "}\n",
    "\n",
    "CRN_RUN_ON_LOAD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crn(hp: dict = crn_hp):\n",
    "    global pf_train_totals, pf_train_num_loops, pf_eval_total, pf_eval_num_loops\n",
    "    pf_train_totals = [0,0]                                                     ###\n",
    "    pf_train_num_loops = 0                                                      ###\n",
    "    pf_eval_total = 0\n",
    "    pf_eval_num_loops = 0\n",
    "    try:\n",
    "        datestring_at_start = datetime_string()\n",
    "        os.mkdir(f\"saved_models/crn_{datestring_at_start}\")\n",
    "\n",
    "        from models.wavecrn import ConvBSRU\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        out = {\"hp\": hp}\n",
    "        model = ConvBSRU(frame_size=hp[\"frame_size\"], conv_channels=256, stride=48, num_layers=6, dropout=0.0).to(device=device)\n",
    "        if hp[\"load\"] != None:\n",
    "            model.load_state_dict(torch.load(hp[\"load\"], weights_only=True))\n",
    "        out[\"model\"] = model\n",
    "        \n",
    "        # optimizer = torch.optim.Adam(model.parameters(),lr=hp[\"lr\"])\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=hp[\"lr\"])\n",
    "        criterion = nn.L1Loss()\n",
    "        out[\"optimizer\"] = str(optimizer).split(\"(\")[0]\n",
    "        out[\"criterion\"] = str(criterion).split(\"(\")[0]\n",
    "\n",
    "        _dataset = SortedBatchDataset(get_sequential_wav_paths(\"data/mixed/train\"), \n",
    "                                      get_sequential_wav_paths(\"data/speech_ordered/train\"), \n",
    "                                      batch_size=hp[\"batch_size\"])\n",
    "        train_dataset, val_dataset = _dataset.split(0.2)\n",
    "        del _dataset\n",
    "        base_train_dataloader = DataLoader(train_dataset, shuffle=SHUFFLE)\n",
    "        base_val_dataloader = DataLoader(val_dataset)\n",
    "\n",
    "        def train_step(engine, batch):\n",
    "            global pf_train_totals, pf_train_num_loops\n",
    "            pf_train_forward = time.perf_counter_ns()                               ###\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            x, y = batch[0].to(device), batch[1].to(device)\n",
    "            y_pred = model(x)\n",
    "            pf_train_totals[0] += (time.perf_counter_ns() - pf_train_forward)       ###\n",
    "            pf_train_back = time.perf_counter_ns()                                  ###\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pf_train_totals[1] += (time.perf_counter_ns() - pf_train_back)          ###\n",
    "            pf_train_num_loops += 1                                                 ###\n",
    "            return loss.item()\n",
    "\n",
    "        trainer = Engine(train_step)\n",
    "        register_custom_events(trainer)\n",
    "        RunningAverage(output_transform=lambda x: x).attach(trainer,'loss')\n",
    "        pbar = ProgressBar(desc=\"Training Epoch\")\n",
    "        pbar.attach(trainer,['loss'])\n",
    "\n",
    "        trainer.add_event_handler(Events.STARTED, set_engine_custom_keys)\n",
    "        trainer.add_event_handler(Events.EPOCH_COMPLETED(once=1),set_iteration_ceiling)\n",
    "\n",
    "        train_dataloader = FrameLoader(base_train_dataloader, hp[\"frame_size\"], hp[\"frame_shift\"], batch_size=hp[\"batch_size\"], engine=trainer, output_transform=lambda x: x.view((hp[\"batch_size\"],1,-1)))\n",
    "\n",
    "        \n",
    "        proc_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"], output_transform=lambda x: x.view((hp[\"batch_size\"],1,-1)))\n",
    "        clean_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"], output_transform=lambda x: x.view((hp[\"batch_size\"],1,-1)))\n",
    "        def val_step(engine, batch):\n",
    "            global pf_eval_total, pf_eval_num_loops\n",
    "            pf_eval_forward = time.perf_counter_ns()                                ###\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                x, y = batch[0].to(device), batch[1].to(device)\n",
    "                y_pred = model(x)\n",
    "                pf_eval_total += (time.perf_counter_ns() - pf_eval_forward)         ###\n",
    "                pf_eval_num_loops += 1                                              ###\n",
    "                proc_frame_constructor.add_frame(y_pred)\n",
    "                clean_frame_constructor.add_frame(y)\n",
    "                if batch[2]:    #   Frame fully constructed\n",
    "                    y_pred_stitch = proc_frame_constructor.get_current_audio()\n",
    "                    y_stitch = clean_frame_constructor.get_current_audio()\n",
    "                    proc_frame_constructor.reset()\n",
    "                    clean_frame_constructor.reset()\n",
    "                    return y_pred, y, {\"stitch_proc\": y_pred_stitch, \"stitch_clean\": y_stitch}\n",
    "\n",
    "                return y_pred, y\n",
    "\n",
    "        validator = Engine(val_step)\n",
    "        pbar = ProgressBar(desc=\"Validation\")\n",
    "        pbar.attach(validator,['loss'])\n",
    "        val_metrics: dict[str, Metric] = {\n",
    "            \"loss\": Loss(criterion, output_transform=lambda x: (x[0],x[1])),\n",
    "            \"pesq\": PESQMetric(),\n",
    "            \"stoi\": STOIMetric()\n",
    "        }\n",
    "        for name, metric in val_metrics.items():\n",
    "            metric.attach(validator, name)\n",
    "\n",
    "        checkpoint_to_save = {\"model\":model}\n",
    "        checkpoint_handler = Checkpoint(\n",
    "            checkpoint_to_save, f\"saved_models/crn_{datestring_at_start}\",\n",
    "            filename_prefix=\"best\", score_function=lambda eng: eng.state.metrics['pesq'],n_saved=2\n",
    "        )\n",
    "\n",
    "        metrics_out = []\n",
    "        out[\"metrics\"] = metrics_out\n",
    "        val_dataloader = FrameLoader(base_val_dataloader, hp[\"frame_size\"], hp[\"frame_shift\"],\n",
    "                                     hp[\"batch_size\"],output_transform=lambda x: x.view((hp[\"batch_size\"],1,-1)))\n",
    "        trainer.add_event_handler(Events.EPOCH_COMPLETED,run_eval,validator=validator,val_frame_loader=val_dataloader)\n",
    "        trainer.add_event_handler(ValidationEvents.VALIDATION_COMPLETED,log_eval_results,validator=validator,metrics_out=metrics_out)\n",
    "        validator.add_event_handler(Events.COMPLETED, checkpoint_handler)\n",
    "\n",
    "\n",
    "        time_train = time.perf_counter_ns()\n",
    "        trainer.run(train_dataloader, max_epochs=hp[\"epochs\"])\n",
    "        out[\"total_time\"] = time.perf_counter_ns() - time_train\n",
    "        out[\"fwd\"]=pf_train_totals[0] / float(pf_train_num_loops)                        ###\n",
    "        out[\"bck\"]=pf_train_totals[1] / float(pf_train_num_loops)                        ###\n",
    "        out[\"eval\"]=pf_eval_total / float(pf_eval_num_loops)                          ###\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(traceback.print_exc())\n",
    "        print(e)    \n",
    "    finally:\n",
    "        if \"model\" in locals():\n",
    "            if hp[\"save\"]:\n",
    "                torch.save(model.state_dict(),f\"saved_models/crn_{datestring_at_start}/final.pt\")\n",
    "                json_dict = {k: out[k] for k in out.keys() - {'model'}}\n",
    "                with open(f\"saved_models/crn_{datestring_at_start}/out.json\",\"w\") as f:\n",
    "                    json.dump(json_dict,f)\n",
    "            return out\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "if CRN_RUN_ON_LOAD:\n",
    "    crn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'crn_model' in locals(): torch.save(crn_model.state_dict(),f\"saved_models/crn_{datetime_string()}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RHR-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_hp = {\n",
    "    \"frame_size\":1024,\n",
    "    \"frame_shift\":256,\n",
    "    \"lr\":1.0e-4,\n",
    "    \"batch_size\":128,\n",
    "    \"epochs\":30,\n",
    "    \"save\":True,\n",
    "    \"load\":None,\n",
    "    \"model_type\":\"rnn\",\n",
    "}\n",
    "\n",
    "RNN_RUN_ON_LOAD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(hp: dict = rnn_hp):\n",
    "    global pf_train_totals, pf_train_num_loops, pf_eval_total, pf_eval_num_loops\n",
    "    pf_train_totals = [0,0]                                                     ###\n",
    "    pf_train_num_loops = 0                                                      ###\n",
    "    pf_eval_total = 0\n",
    "    pf_eval_num_loops = 0\n",
    "    try:\n",
    "        datestring_at_start = datetime_string()\n",
    "        os.mkdir(f\"saved_models/rnn_{datestring_at_start}\")\n",
    "        \n",
    "        import yaml\n",
    "        from models.rhrnetdir.Arg_Parser import Recursive_Parse\n",
    "        from models.rhrnet import RHRNet\n",
    "        rnn_hp = Recursive_Parse(yaml.load(\n",
    "            open('models/rhrnetdir/rhrnet_hyperparameters.yaml', encoding='utf-8'),\n",
    "            Loader=yaml.Loader\n",
    "            ))  \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        out = {\"hp\": hp, \"datetime_str\": datestring_at_start}\n",
    "        model = RHRNet(rnn_hp).to(device=device)\n",
    "        if hp[\"load\"] != None:\n",
    "            model.load_state_dict(torch.load(hp[\"load\"], weights_only=True))\n",
    "        out[\"model\"] = model\n",
    "        \n",
    "        optimizer = torch.optim.RMSprop(model.parameters(),lr=hp[\"lr\"])\n",
    "        criterion = nn.L1Loss()\n",
    "        out[\"optimizer\"] = str(optimizer).split(\"(\")[0]\n",
    "        out[\"criterion\"] = str(criterion).split(\"(\")[0]\n",
    "\n",
    "        _dataset = SortedBatchDataset(get_sequential_wav_paths(\"data/mixed/train\"), get_sequential_wav_paths(\"data/speech_ordered/train\"), batch_size=hp[\"batch_size\"])\n",
    "        train_dataset, val_dataset = _dataset.split(0.2)\n",
    "        del _dataset\n",
    "        base_train_dataloader = DataLoader(train_dataset, shuffle=SHUFFLE)\n",
    "        base_val_dataloader = DataLoader(val_dataset)\n",
    "        print(f\"val dataset:{len(val_dataset)}\")\n",
    "\n",
    "        def train_step(engine, batch):\n",
    "            global pf_train_totals, pf_train_num_loops\n",
    "            pf_train_forward = time.perf_counter_ns()                               ###\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            x, y = batch[0].to(device), batch[1].to(device)\n",
    "            y_pred = model(x)\n",
    "            pf_train_totals[0] += (time.perf_counter_ns() - pf_train_forward)       ###\n",
    "            pf_train_back = time.perf_counter_ns()                                  ###\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pf_train_totals[1] += (time.perf_counter_ns() - pf_train_back)          ###\n",
    "            pf_train_num_loops += 1                                                 ###\n",
    "            return loss.item()\n",
    "\n",
    "        trainer = Engine(train_step)\n",
    "        register_custom_events(trainer)\n",
    "        RunningAverage(output_transform=lambda x: x).attach(trainer,'loss')\n",
    "        pbar = ProgressBar(desc=\"Training Epoch\")\n",
    "        pbar.attach(trainer,['loss'])\n",
    "\n",
    "        trainer.add_event_handler(Events.STARTED, set_engine_custom_keys)\n",
    "        trainer.add_event_handler(Events.EPOCH_COMPLETED(once=1),set_iteration_ceiling)\n",
    "\n",
    "        train_dataloader = FrameLoader(base_train_dataloader, hp[\"frame_size\"], hp[\"frame_shift\"], batch_size=hp[\"batch_size\"], engine=trainer, output_transform=lambda x: x.view((hp[\"batch_size\"],-1)))\n",
    "\n",
    "        proc_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"], output_transform=lambda x: x.view((hp[\"batch_size\"],-1)))\n",
    "        clean_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"], output_transform=lambda x: x.view((hp[\"batch_size\"],-1)))\n",
    "        def val_step(engine, batch):\n",
    "            global pf_eval_total, pf_eval_num_loops\n",
    "            pf_eval_forward = time.perf_counter_ns()                                ###\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                x, y = batch[0].to(device), batch[1].to(device)\n",
    "                y_pred = model(x)\n",
    "                pf_eval_total += (time.perf_counter_ns() - pf_eval_forward)         ###\n",
    "                pf_eval_num_loops += 1                                              ###\n",
    "                proc_frame_constructor.add_frame(y_pred)\n",
    "                clean_frame_constructor.add_frame(y)\n",
    "                if batch[2]:    #   Frame fully constructed\n",
    "                    y_pred_stitch = proc_frame_constructor.get_current_audio()\n",
    "                    y_stitch = clean_frame_constructor.get_current_audio()\n",
    "                    proc_frame_constructor.reset()\n",
    "                    clean_frame_constructor.reset()\n",
    "                    return y_pred, y, {\"stitch_proc\": y_pred_stitch, \"stitch_clean\": y_stitch}\n",
    "\n",
    "                return y_pred, y\n",
    "\n",
    "        validator = Engine(val_step)\n",
    "        pbar = ProgressBar(desc=\"Validation\")\n",
    "        pbar.attach(validator,['loss'])\n",
    "        val_metrics: dict[str, Metric] = {\n",
    "            \"loss\": Loss(criterion, output_transform=lambda x: (x[0],x[1])),\n",
    "            \"pesq\": PESQMetric(),\n",
    "            \"stoi\": STOIMetric()\n",
    "        }\n",
    "\n",
    "        for name, metric in val_metrics.items():\n",
    "            metric.attach(validator, name)\n",
    "\n",
    "        checkpoint_to_save = {\"model\":model}\n",
    "        checkpoint_handler = Checkpoint(\n",
    "            checkpoint_to_save, f\"saved_models/rnn_{datestring_at_start}\",\n",
    "            filename_prefix=\"best\", score_function=lambda eng: eng.state.metrics['pesq'],n_saved=2\n",
    "        )\n",
    "\n",
    "        metrics_out = []\n",
    "        out[\"metrics\"] = metrics_out\n",
    "        val_dataloader = FrameLoader(base_val_dataloader, hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"])\n",
    "        trainer.add_event_handler(Events.EPOCH_COMPLETED,run_eval,validator=validator,val_frame_loader=val_dataloader)\n",
    "        trainer.add_event_handler(ValidationEvents.VALIDATION_COMPLETED,log_eval_results,validator=validator,metrics_out=metrics_out)\n",
    "        validator.add_event_handler(Events.COMPLETED, checkpoint_handler)\n",
    "\n",
    "        time_train = time.perf_counter_ns()\n",
    "        trainer.run(train_dataloader, max_epochs=hp[\"epochs\"])\n",
    "        out[\"total_time\"] = time.perf_counter_ns() - time_train\n",
    "        out[\"fwd\"]=pf_train_totals[0] / float(pf_train_num_loops)                        ###\n",
    "        out[\"bck\"]=pf_train_totals[1] / float(pf_train_num_loops)                        ###\n",
    "        out[\"eval\"]=pf_eval_total / float(pf_eval_num_loops)                          ###\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "    finally:\n",
    "        if \"model\" in locals():\n",
    "            if hp[\"save\"]:\n",
    "                torch.save(model.state_dict(),f\"saved_models/rnn_{datestring_at_start}/final.pt\")\n",
    "                with open(f\"saved_models/rnn_{datestring_at_start}/out.json\",\"w\") as f:\n",
    "                    json.dump({k: out[k] for k in out.keys() - {'model'}},f)\n",
    "            return out\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "if RNN_RUN_ON_LOAD:\n",
    "    rnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=ns_to_sec(pf_train_totals[0] / float(pf_train_num_loops))                         ###\n",
    "b=ns_to_sec(pf_train_totals[1] / float(pf_train_num_loops))                         ###\n",
    "c=ns_to_sec(pf_eval_total / float(pf_train_num_loops/4))                            ###\n",
    "print(f\"train forward:{a:.20f} | backprop:{b:.20f} | eval forward:{c:.20f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'rnn_model' in locals(): torch.save(rnn_model.state_dict(),f\"saved_models/rnn_{datetime.datetime.now().strftime(\"%d-%m-%Y--%H-%M-%S\")}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wave-U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_FRAME_SIZE = 16153\n",
    "CNN_OUT_FRAME_SIZE = 16009\n",
    "CNN_FRAME_SHIFT = CNN_FRAME_SIZE / 4\n",
    "CNN_LR = 1.0e-4\n",
    "\n",
    "CNN_PREP = True\n",
    "CNN_TRAIN = False\n",
    "CNN_LOAD= False\n",
    "CNN_SAVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'cnn_model' in locals(): torch.save(cnn_model.state_dict(),f\"saved_models/cnn_{datetime.datetime.now().strftime(\"%d-%m-%Y--%H-%M-%S\")}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_hp = {\n",
    "    \"frame_size\":320,\n",
    "    \"frame_shift\":160,\n",
    "    \"num_frames\": 300,\n",
    "    \"lr\":1.0e-3,\n",
    "    \"batch_size\":16,\n",
    "    \"epochs\":30,\n",
    "    \"save\":False,\n",
    "    \"load\":None,\n",
    "    \"model_type\":\"cnn\",\n",
    "}\n",
    "\n",
    "CNN_RUN_ON_LOAD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(hp: dict = cnn_hp):\n",
    "    global pf_train_totals, pf_train_num_loops, pf_eval_total, pf_eval_num_loops\n",
    "    pf_train_totals = [0,0]                                                     ###\n",
    "    pf_train_num_loops = 0                                                      ###\n",
    "    pf_eval_total = 0\n",
    "    pf_eval_num_loops = 0\n",
    "    logging.disable(logging.DEBUG)\n",
    "    try:\n",
    "        datestring_at_start = datetime_string()\n",
    "        os.mkdir(f\"saved_models/cnn_{datestring_at_start}\")\n",
    "\n",
    "        from models.tcnn import TCNN\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        out = {\"hp\": hp}\n",
    "        model = TCNN().to(device=device)\n",
    "        if hp[\"load\"] != None:\n",
    "            model.load_state_dict(torch.load(hp[\"load\"], weights_only=True))\n",
    "        out[\"model\"] = model\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=hp[\"lr\"])\n",
    "        criterion = nn.L1Loss()\n",
    "        out[\"optimizer\"] = str(optimizer).split(\"(\")[0]\n",
    "        out[\"criterion\"] = str(criterion).split(\"(\")[0]\n",
    "\n",
    "        _dataset = SortedBatchDataset(get_sequential_wav_paths(\"data/mixed/train\"), \n",
    "                                      get_sequential_wav_paths(\"data/speech_ordered/train\"), \n",
    "                                      batch_size=hp[\"batch_size\"])\n",
    "        train_dataset, val_dataset = _dataset.split(0.2)\n",
    "        del _dataset\n",
    "        base_train_dataloader = DataLoader(train_dataset, shuffle=SHUFFLE)\n",
    "        base_val_dataloader = DataLoader(val_dataset)\n",
    "\n",
    "        def train_step(engine, batch):\n",
    "            global pf_train_totals, pf_train_num_loops\n",
    "            pf_train_forward = time.perf_counter_ns()                               ###\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            x, y = batch[0].to(device), batch[1].to(device)\n",
    "            y_pred = model(x)\n",
    "            pf_train_totals[0] += (time.perf_counter_ns() - pf_train_forward)       ###\n",
    "            pf_train_back = time.perf_counter_ns()                                  ###\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pf_train_totals[1] += (time.perf_counter_ns() - pf_train_back)          ###\n",
    "            pf_train_num_loops += 1                                                 ###\n",
    "            return loss.item()\n",
    "        \n",
    "        trainer = Engine(train_step)\n",
    "        register_custom_events(trainer)\n",
    "        RunningAverage(output_transform=lambda x: x).attach(trainer,'loss')\n",
    "        pbar = ProgressBar(desc=\"Training Epoch\")\n",
    "        pbar.attach(trainer,['loss'])\n",
    "\n",
    "        trainer.add_event_handler(Events.STARTED, set_engine_custom_keys)\n",
    "        trainer.add_event_handler(Events.EPOCH_COMPLETED(once=1),set_iteration_ceiling)\n",
    "\n",
    "        train_dataloader = MultiFrameLoader(base_train_dataloader, hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"],\n",
    "                                              hp[\"num_frames\"], engine=trainer, output_transform=lambda x: x.unsqueeze(1))\n",
    "        proc_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"])\n",
    "        clean_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"])\n",
    "        def val_step(engine, batch):\n",
    "            global pf_eval_total, pf_eval_num_loops\n",
    "            pf_eval_forward = time.perf_counter_ns()                                ###\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                x, y = batch[0].to(device), batch[1].to(device)\n",
    "                y_pred = model(x)\n",
    "                pf_eval_total += (time.perf_counter_ns() - pf_eval_forward)         ###\n",
    "                pf_eval_num_loops += 1                                              ###\n",
    "                for i in range(y_pred.shape[2]):\n",
    "                    proc_frame_constructor.add_frame(y_pred[:,:,i,:])\n",
    "                    clean_frame_constructor.add_frame(y[:,:,i,:])\n",
    "                if batch[2]:    #   Frame fully constructed\n",
    "                    y_pred_stitch = proc_frame_constructor.get_current_audio()\n",
    "                    y_stitch = clean_frame_constructor.get_current_audio()\n",
    "                    proc_frame_constructor.reset()\n",
    "                    clean_frame_constructor.reset()\n",
    "                    return y_pred, y, {\"stitch_proc\": y_pred_stitch, \"stitch_clean\": y_stitch}\n",
    "\n",
    "                return y_pred, y\n",
    "        \n",
    "        validator = Engine(val_step)\n",
    "        val_metrics: dict[str, Metric] = {\n",
    "            \"loss\": Loss(criterion, output_transform=lambda x: (x[0],x[1])),\n",
    "            \"pesq\": PESQMetric(),\n",
    "            \"stoi\": STOIMetric()\n",
    "        }\n",
    "        for name, metric in val_metrics.items():\n",
    "            metric.attach(validator, name)\n",
    "        RunningAverage(output_transform=lambda x: criterion(x[0],x[1]).item()).attach(validator,'running_loss')\n",
    "        pbar = ProgressBar(desc=\"Validation\")\n",
    "        pbar.attach(validator,['running_loss'])\n",
    "        \n",
    "        checkpoint_to_save = {\"model\":model}\n",
    "        checkpoint_handler = Checkpoint(\n",
    "            checkpoint_to_save, f\"saved_models/cnn_{datestring_at_start}\",\n",
    "            filename_prefix=\"best\", score_function=lambda eng: eng.state.metrics['pesq'],n_saved=2\n",
    "        )\n",
    "        metrics_out = []\n",
    "        out[\"metrics\"] = metrics_out\n",
    "        val_dataloader = MultiFrameLoader(base_val_dataloader, hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"],\n",
    "                                              hp[\"num_frames\"], engine=trainer, output_transform=lambda x: x.unsqueeze(1))\n",
    "        trainer.add_event_handler(Events.EPOCH_COMPLETED,run_eval,validator=validator,val_frame_loader=val_dataloader)\n",
    "        trainer.add_event_handler(ValidationEvents.VALIDATION_COMPLETED,log_eval_results,validator=validator,metrics_out=metrics_out)\n",
    "        validator.add_event_handler(Events.COMPLETED, checkpoint_handler)\n",
    "\n",
    "\n",
    "        time_train = time.perf_counter_ns()\n",
    "        trainer.run(train_dataloader, max_epochs=hp[\"epochs\"])\n",
    "        out[\"total_time\"] = time.perf_counter_ns() - time_train\n",
    "        out[\"fwd\"]=pf_train_totals[0] / float(pf_train_num_loops)                        ###\n",
    "        out[\"bck\"]=pf_train_totals[1] / float(pf_train_num_loops)                        ###\n",
    "        out[\"eval\"]=pf_eval_total / float(pf_eval_num_loops)                          ###\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(traceback.print_exc())\n",
    "        print(e) \n",
    "    finally:\n",
    "        logging.disable(logging.NOTSET)\n",
    "        if \"model\" in locals():\n",
    "            if hp[\"save\"]:\n",
    "                torch.save(model.state_dict(),f\"saved_models/cnn_{datestring_at_start}/final.pt\")\n",
    "                json_dict = {k: out[k] for k in out.keys() - {'model'}}\n",
    "                with open(f\"saved_models/cnn_{datestring_at_start}/out.json\",\"w\") as f:\n",
    "                    json.dump(json_dict,f)\n",
    "            return out\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "if CNN_RUN_ON_LOAD:\n",
    "    cnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.segan import Generator\n",
    "from models.tcnn import TCNN\n",
    "from models.rhrnet import RHRNet\n",
    "# from models.wavecrn import ConvBSRU\n",
    "from pesq.cypesq import NoUtterancesError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_test(model: Generator, dl: FrameLoader, hp: dict = gan_hp):\n",
    "    try:\n",
    "        proc_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"], output_transform=lambda x: x.view((hp[\"batch_size\"],-1)))\n",
    "        clean_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"], output_transform=lambda x: x.view((hp[\"batch_size\"],-1)))\n",
    "        results = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dl):\n",
    "                x, y = batch[0].to(device), batch[1].to(device)\n",
    "                y_pred = model(x)\n",
    "                proc_frame_constructor.add_frame(y_pred)\n",
    "                clean_frame_constructor.add_frame(y)\n",
    "                if batch[2]:    #   Frame fully constructed\n",
    "                    y_pred_stitch = proc_frame_constructor.get_current_audio()\n",
    "                    y_stitch = clean_frame_constructor.get_current_audio()\n",
    "                    proc_frame_constructor.reset()\n",
    "                    clean_frame_constructor.reset()\n",
    "                    try:\n",
    "                        sq = calc_pesq(y_stitch, y_pred_stitch)\n",
    "                        si = calc_stoi(y_stitch, y_pred_stitch)\n",
    "                        results.append({\"pesq\":sq, \"stoi\":si})\n",
    "                    except NoUtterancesError as e:\n",
    "                        continue\n",
    "\n",
    "    finally:\n",
    "        return results\n",
    "\n",
    "# def crn_test(model: ConvBSRU, dl: FrameLoader, hp: dict = crn_hp):\n",
    "#     try:\n",
    "#         proc_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"], output_transform=lambda x: x.view((hp[\"batch_size\"],1,-1)))\n",
    "#         clean_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"], output_transform=lambda x: x.view((hp[\"batch_size\"],1,-1)))\n",
    "#         results = []\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             for batch in tqdm(dl):\n",
    "#                 x, y = batch[0].to(device), batch[1].to(device)\n",
    "#                 y_pred = model(x)\n",
    "#                 proc_frame_constructor.add_frame(y_pred)\n",
    "#                 clean_frame_constructor.add_frame(y)\n",
    "#                 if batch[2]:    #   Frame fully constructed\n",
    "#                     y_pred_stitch = proc_frame_constructor.get_current_audio()\n",
    "#                     y_stitch = clean_frame_constructor.get_current_audio()\n",
    "#                     proc_frame_constructor.reset()\n",
    "#                     clean_frame_constructor.reset()\n",
    "#                     try:\n",
    "#                         sq = calc_pesq(y_stitch, y_pred_stitch)\n",
    "#                         si = calc_stoi(y_stitch, y_pred_stitch)\n",
    "#                         results.append({\"pesq\":sq, \"stoi\":si})\n",
    "#                     except NoUtterancesError as e:\n",
    "#                         continue\n",
    "#     finally:\n",
    "#         return results\n",
    "    \n",
    "def rnn_test(model: RHRNet, dl: FrameLoader, hp: dict = rnn_hp):\n",
    "    try:\n",
    "        proc_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"], output_transform=lambda x: x.view((hp[\"batch_size\"],-1)))\n",
    "        clean_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"], output_transform=lambda x: x.view((hp[\"batch_size\"],-1)))\n",
    "        results = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dl):\n",
    "                x, y = batch[0].to(device), batch[1].to(device)\n",
    "                y_pred = model(x)\n",
    "                proc_frame_constructor.add_frame(y_pred)\n",
    "                clean_frame_constructor.add_frame(y)\n",
    "                if batch[2]:    #   Frame fully constructed\n",
    "                    y_pred_stitch = proc_frame_constructor.get_current_audio()\n",
    "                    y_stitch = clean_frame_constructor.get_current_audio()\n",
    "                    proc_frame_constructor.reset()\n",
    "                    clean_frame_constructor.reset()\n",
    "                    try:\n",
    "                        sq = calc_pesq(y_stitch, y_pred_stitch)\n",
    "                        si = calc_stoi(y_stitch, y_pred_stitch)\n",
    "                        results.append({\"pesq\":sq, \"stoi\":si})\n",
    "                    except NoUtterancesError as e:\n",
    "                        continue\n",
    "    finally:\n",
    "        return results\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Speed Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 56/2620 [01:32<1:10:14,  1.64s/it]d:\\Anaconda\\Miniconda3\\envs\\fyp\\Lib\\site-packages\\pystoi\\stoi.py:66: RuntimeWarning: Not enough STFT frames to compute intermediate intelligibility measure after removing silent frames. Returning 1e-5. Please check you wav files\n",
      "  warnings.warn('Not enough STFT frames to compute intermediate '\n",
      " 42%|████▏     | 1096/2620 [30:45<42:46,  1.68s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\leoro\\AppData\\Local\\Temp\\ipykernel_22480\\2515190839.py\", line 127, in rnn_one_sec_test\n",
      "    y_pred: torch.Tensor = model(x)\n",
      "                           ^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Miniconda3\\envs\\fyp\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Miniconda3\\envs\\fyp\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\fyp\\speech_denoising_fyp\\models\\rhrnet.py\", line 45, in forward\n",
      "    x = self.layer_Dict['GRU_{}'.format(index)](x)[0]\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Miniconda3\\envs\\fyp\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Miniconda3\\envs\\fyp\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Miniconda3\\envs\\fyp\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py\", line 1393, in forward\n",
      "    result = _VF.gru(\n",
      "             ^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rnn': [{'pesq': 1.534623384475708,\n",
       "   'stoi': np.float64(0.8955591640289069),\n",
       "   'time': 1799518600},\n",
       "  {'pesq': 1.063320279121399,\n",
       "   'stoi': np.float64(0.647757180253734),\n",
       "   'time': 1596311100},\n",
       "  {'pesq': 1.4195754528045654,\n",
       "   'stoi': np.float64(0.9523593556354406),\n",
       "   'time': 1588517100},\n",
       "  {'pesq': 1.277953863143921,\n",
       "   'stoi': np.float64(0.8421710781092258),\n",
       "   'time': 1586592300},\n",
       "  {'pesq': 1.0233240127563477,\n",
       "   'stoi': np.float64(0.3679675267102117),\n",
       "   'time': 1577612500},\n",
       "  {'pesq': 1.089699387550354,\n",
       "   'stoi': np.float64(0.6149097733497789),\n",
       "   'time': 1580725200},\n",
       "  {'pesq': 1.0704900026321411,\n",
       "   'stoi': np.float64(0.29026373547579404),\n",
       "   'time': 1591999100},\n",
       "  {'pesq': 1.523060917854309,\n",
       "   'stoi': np.float64(0.856078598051337),\n",
       "   'time': 1576531000},\n",
       "  {'pesq': 1.5213298797607422,\n",
       "   'stoi': np.float64(0.9239089859741995),\n",
       "   'time': 1584364500},\n",
       "  {'pesq': 1.85567045211792,\n",
       "   'stoi': np.float64(0.9149691025706439),\n",
       "   'time': 1590620300},\n",
       "  {'pesq': 1.727832555770874,\n",
       "   'stoi': np.float64(0.9348384436803565),\n",
       "   'time': 1667022900},\n",
       "  {'pesq': 1.3132400512695312,\n",
       "   'stoi': np.float64(0.8682730376070772),\n",
       "   'time': 1664271000},\n",
       "  {'pesq': 1.5142509937286377,\n",
       "   'stoi': np.float64(0.8762017238321116),\n",
       "   'time': 1620766400},\n",
       "  {'pesq': 1.06367027759552,\n",
       "   'stoi': np.float64(0.6461072893759985),\n",
       "   'time': 1637214900},\n",
       "  {'pesq': 1.7706983089447021,\n",
       "   'stoi': np.float64(0.9655927273393492),\n",
       "   'time': 1612744300},\n",
       "  {'pesq': 2.721210479736328,\n",
       "   'stoi': np.float64(0.9892647445943236),\n",
       "   'time': 1572476500},\n",
       "  {'pesq': 1.727437973022461,\n",
       "   'stoi': np.float64(0.8677734427993666),\n",
       "   'time': 1575025800},\n",
       "  {'pesq': 1.5411810874938965,\n",
       "   'stoi': np.float64(0.8895545402592092),\n",
       "   'time': 1581753700},\n",
       "  {'pesq': 2.135042190551758,\n",
       "   'stoi': np.float64(0.9500806983992943),\n",
       "   'time': 1586425600},\n",
       "  {'pesq': 1.3906338214874268,\n",
       "   'stoi': np.float64(0.9260165812652195),\n",
       "   'time': 1570879700},\n",
       "  {'pesq': 1.9411284923553467,\n",
       "   'stoi': np.float64(0.9246396420454734),\n",
       "   'time': 1572505500},\n",
       "  {'pesq': 1.670669436454773,\n",
       "   'stoi': np.float64(0.4641020461316255),\n",
       "   'time': 1586215600},\n",
       "  {'pesq': 1.8039721250534058,\n",
       "   'stoi': np.float64(0.9428699823545239),\n",
       "   'time': 1580424000},\n",
       "  {'pesq': 2.0829758644104004,\n",
       "   'stoi': np.float64(0.9136821426150984),\n",
       "   'time': 1612064000},\n",
       "  {'pesq': 1.117672324180603,\n",
       "   'stoi': np.float64(0.7756043532324661),\n",
       "   'time': 1582472500},\n",
       "  {'pesq': 2.397719144821167,\n",
       "   'stoi': np.float64(0.9558925342814808),\n",
       "   'time': 1562594500},\n",
       "  {'pesq': 1.8543727397918701,\n",
       "   'stoi': np.float64(0.9515666367898279),\n",
       "   'time': 1577295000},\n",
       "  {'pesq': 1.31969153881073,\n",
       "   'stoi': np.float64(0.8476739637159535),\n",
       "   'time': 1577974100},\n",
       "  {'pesq': 2.697176218032837,\n",
       "   'stoi': np.float64(0.9814176817523909),\n",
       "   'time': 1578398600},\n",
       "  {'pesq': 1.6935415267944336,\n",
       "   'stoi': np.float64(0.8846471405518114),\n",
       "   'time': 1628963400},\n",
       "  {'pesq': 1.464299201965332,\n",
       "   'stoi': np.float64(0.848677340969568),\n",
       "   'time': 1610411100},\n",
       "  {'pesq': 1.3327407836914062,\n",
       "   'stoi': np.float64(0.8420314747670664),\n",
       "   'time': 1640699800},\n",
       "  {'pesq': 2.4046614170074463,\n",
       "   'stoi': np.float64(0.9712736427538261),\n",
       "   'time': 1637659400},\n",
       "  {'pesq': 1.148781657218933,\n",
       "   'stoi': np.float64(0.7143179756505684),\n",
       "   'time': 1644906000},\n",
       "  {'pesq': 1.129751443862915,\n",
       "   'stoi': np.float64(0.8407899660509294),\n",
       "   'time': 1591048200},\n",
       "  {'pesq': 1.463634967803955,\n",
       "   'stoi': np.float64(0.6808391857999163),\n",
       "   'time': 1599620500},\n",
       "  {'pesq': 1.6483089923858643,\n",
       "   'stoi': np.float64(0.8989981581689761),\n",
       "   'time': 1582574100},\n",
       "  {'pesq': 1.4600461721420288,\n",
       "   'stoi': np.float64(0.2356416349445221),\n",
       "   'time': 1600708600},\n",
       "  {'pesq': 2.030810832977295,\n",
       "   'stoi': np.float64(0.9268504439854969),\n",
       "   'time': 1583585200},\n",
       "  {'pesq': 1.2110437154769897,\n",
       "   'stoi': np.float64(0.6915498791778792),\n",
       "   'time': 1583067100},\n",
       "  {'pesq': 1.2267837524414062,\n",
       "   'stoi': np.float64(0.8012586936220149),\n",
       "   'time': 1597708700},\n",
       "  {'pesq': 1.9206671714782715,\n",
       "   'stoi': np.float64(0.9688362661338737),\n",
       "   'time': 1571686600},\n",
       "  {'pesq': 1.4437285661697388,\n",
       "   'stoi': np.float64(0.736113598587023),\n",
       "   'time': 1579025100},\n",
       "  {'pesq': 1.2683005332946777,\n",
       "   'stoi': np.float64(0.8227330469428734),\n",
       "   'time': 1576829000},\n",
       "  {'pesq': 1.7608921527862549,\n",
       "   'stoi': np.float64(0.9194523769652563),\n",
       "   'time': 1608211300},\n",
       "  {'pesq': 2.6938576698303223,\n",
       "   'stoi': np.float64(0.9245509036169699),\n",
       "   'time': 1574909800},\n",
       "  {'pesq': 1.2569398880004883,\n",
       "   'stoi': np.float64(0.5597213358154008),\n",
       "   'time': 1607876000},\n",
       "  {'pesq': 1.62074875831604,\n",
       "   'stoi': np.float64(0.9023725445020113),\n",
       "   'time': 1577919700},\n",
       "  {'pesq': 1.3340991735458374,\n",
       "   'stoi': np.float64(0.844858750046537),\n",
       "   'time': 1573461500},\n",
       "  {'pesq': 1.0744054317474365,\n",
       "   'stoi': np.float64(0.7399479222035927),\n",
       "   'time': 1579494100},\n",
       "  {'pesq': 2.596916913986206,\n",
       "   'stoi': np.float64(0.9177700740570791),\n",
       "   'time': 1613223400},\n",
       "  {'pesq': 2.8296284675598145,\n",
       "   'stoi': np.float64(0.9825856151514448),\n",
       "   'time': 1604509600},\n",
       "  {'pesq': 2.8941190242767334,\n",
       "   'stoi': np.float64(0.9256049527308313),\n",
       "   'time': 1632445100},\n",
       "  {'pesq': 2.044447660446167,\n",
       "   'stoi': np.float64(0.9606006919447719),\n",
       "   'time': 1575944000},\n",
       "  {'pesq': 1.1318864822387695,\n",
       "   'stoi': np.float64(0.6864608591717833),\n",
       "   'time': 1573481700},\n",
       "  {'pesq': 1.1762304306030273,\n",
       "   'stoi': np.float64(0.8285720122543809),\n",
       "   'time': 1600111100},\n",
       "  {'pesq': 1.6926069259643555, 'stoi': 1e-05, 'time': 1631787300},\n",
       "  {'pesq': 1.3705872297286987,\n",
       "   'stoi': np.float64(0.7962022844629593),\n",
       "   'time': 1574097000},\n",
       "  {'pesq': 1.2797890901565552,\n",
       "   'stoi': np.float64(0.8643400133413568),\n",
       "   'time': 1574223400},\n",
       "  {'pesq': 1.1559351682662964,\n",
       "   'stoi': np.float64(0.6151949897808813),\n",
       "   'time': 1559532800},\n",
       "  {'pesq': 2.386674165725708,\n",
       "   'stoi': np.float64(0.9682291980884605),\n",
       "   'time': 1584194000},\n",
       "  {'pesq': 1.5637028217315674,\n",
       "   'stoi': np.float64(0.79207898747426),\n",
       "   'time': 1576456200},\n",
       "  {'pesq': 1.1289122104644775,\n",
       "   'stoi': np.float64(0.38761771671920003),\n",
       "   'time': 1568540800},\n",
       "  {'pesq': 2.3426783084869385,\n",
       "   'stoi': np.float64(0.8042860945771876),\n",
       "   'time': 1569369900},\n",
       "  {'pesq': 1.219873309135437,\n",
       "   'stoi': np.float64(0.24221576181590565),\n",
       "   'time': 1576798200},\n",
       "  {'pesq': 1.7816829681396484,\n",
       "   'stoi': np.float64(0.9366053806933731),\n",
       "   'time': 1582344400},\n",
       "  {'pesq': 1.040041446685791,\n",
       "   'stoi': np.float64(-0.015384791575308946),\n",
       "   'time': 1603229800},\n",
       "  {'pesq': 1.6035830974578857,\n",
       "   'stoi': np.float64(0.9264381076607671),\n",
       "   'time': 1583318900},\n",
       "  {'pesq': 1.1096620559692383,\n",
       "   'stoi': np.float64(0.5798204865309469),\n",
       "   'time': 1580310700},\n",
       "  {'pesq': 1.0338531732559204,\n",
       "   'stoi': np.float64(0.5736751904373887),\n",
       "   'time': 1592383500},\n",
       "  {'pesq': 1.617283582687378,\n",
       "   'stoi': np.float64(0.549696883133522),\n",
       "   'time': 1587628900},\n",
       "  {'pesq': 2.0694050788879395,\n",
       "   'stoi': np.float64(0.9037120008289147),\n",
       "   'time': 1609917200},\n",
       "  {'pesq': 1.8669042587280273,\n",
       "   'stoi': np.float64(0.9385545279691659),\n",
       "   'time': 1578766700},\n",
       "  {'pesq': 2.320737600326538,\n",
       "   'stoi': np.float64(0.9422227813812184),\n",
       "   'time': 1568260300},\n",
       "  {'pesq': 1.6461107730865479,\n",
       "   'stoi': np.float64(0.8223907366203901),\n",
       "   'time': 1571712700},\n",
       "  {'pesq': 1.376875877380371,\n",
       "   'stoi': np.float64(0.8201804519237399),\n",
       "   'time': 1565827500},\n",
       "  {'pesq': 1.5427358150482178,\n",
       "   'stoi': np.float64(0.8555415465226492),\n",
       "   'time': 1565889300},\n",
       "  {'pesq': 1.2103161811828613,\n",
       "   'stoi': np.float64(0.3324731816921695),\n",
       "   'time': 1584195600},\n",
       "  {'pesq': 1.3514642715454102,\n",
       "   'stoi': np.float64(0.966332574094128),\n",
       "   'time': 1562763400},\n",
       "  {'pesq': 1.625334620475769,\n",
       "   'stoi': np.float64(0.8686006803962197),\n",
       "   'time': 1567776700},\n",
       "  {'pesq': 1.0606564283370972,\n",
       "   'stoi': np.float64(0.4859983523589661),\n",
       "   'time': 1563060200},\n",
       "  {'pesq': 1.3821824789047241,\n",
       "   'stoi': np.float64(0.6318506270741454),\n",
       "   'time': 1561966800},\n",
       "  {'pesq': 1.8388543128967285,\n",
       "   'stoi': np.float64(0.9722188748286313),\n",
       "   'time': 1578916000},\n",
       "  {'pesq': 1.6367840766906738,\n",
       "   'stoi': np.float64(0.8884030489353113),\n",
       "   'time': 1570770000},\n",
       "  {'pesq': 1.4426451921463013,\n",
       "   'stoi': np.float64(0.8899944058002427),\n",
       "   'time': 1579576000},\n",
       "  {'pesq': 1.6050236225128174,\n",
       "   'stoi': np.float64(0.8091457680838643),\n",
       "   'time': 1562756100},\n",
       "  {'pesq': 2.0836334228515625,\n",
       "   'stoi': np.float64(0.5299055387107794),\n",
       "   'time': 1575522500},\n",
       "  {'pesq': 1.8255743980407715,\n",
       "   'stoi': np.float64(0.8659366143309192),\n",
       "   'time': 1590958200},\n",
       "  {'pesq': 1.172516942024231,\n",
       "   'stoi': np.float64(0.8408717924143914),\n",
       "   'time': 1651752000},\n",
       "  {'pesq': 2.2985129356384277,\n",
       "   'stoi': np.float64(0.9639756265968227),\n",
       "   'time': 1621334600},\n",
       "  {'pesq': 1.872818946838379,\n",
       "   'stoi': np.float64(0.9769359435744532),\n",
       "   'time': 1610970100},\n",
       "  {'pesq': 1.2652487754821777,\n",
       "   'stoi': np.float64(0.8626731138440107),\n",
       "   'time': 1578449900},\n",
       "  {'pesq': 1.3726441860198975,\n",
       "   'stoi': np.float64(0.9333203255558651),\n",
       "   'time': 1582211500},\n",
       "  {'pesq': 2.058192491531372,\n",
       "   'stoi': np.float64(0.9166644626172714),\n",
       "   'time': 1604488300},\n",
       "  {'pesq': 1.2321715354919434,\n",
       "   'stoi': np.float64(0.8909742174448378),\n",
       "   'time': 1591506400},\n",
       "  {'pesq': 2.2427918910980225,\n",
       "   'stoi': np.float64(0.951444262355765),\n",
       "   'time': 1575516200},\n",
       "  {'pesq': 1.3822994232177734,\n",
       "   'stoi': np.float64(0.8927825655036977),\n",
       "   'time': 1594874200},\n",
       "  {'pesq': 1.2729130983352661,\n",
       "   'stoi': np.float64(0.8428054428562746),\n",
       "   'time': 1580139000},\n",
       "  {'pesq': 2.5597691535949707,\n",
       "   'stoi': np.float64(0.9829755731221713),\n",
       "   'time': 1574969900},\n",
       "  {'pesq': 1.5876939296722412,\n",
       "   'stoi': np.float64(0.8531201550331428),\n",
       "   'time': 1588944700},\n",
       "  {'pesq': 1.6070351600646973,\n",
       "   'stoi': np.float64(0.903195593119686),\n",
       "   'time': 1632119200},\n",
       "  {'pesq': 1.3918514251708984,\n",
       "   'stoi': np.float64(0.7917994721667817),\n",
       "   'time': 1588449400},\n",
       "  {'pesq': 1.8623396158218384,\n",
       "   'stoi': np.float64(0.8611591370738367),\n",
       "   'time': 1624359800},\n",
       "  {'pesq': 1.535231351852417,\n",
       "   'stoi': np.float64(0.844701807650325),\n",
       "   'time': 1600264700},\n",
       "  {'pesq': 1.1427127122879028,\n",
       "   'stoi': np.float64(0.7674773450138663),\n",
       "   'time': 1610510200},\n",
       "  {'pesq': 1.1400805711746216,\n",
       "   'stoi': np.float64(0.7883201167752762),\n",
       "   'time': 1589713600},\n",
       "  {'pesq': 1.3662188053131104,\n",
       "   'stoi': np.float64(0.9118951419911944),\n",
       "   'time': 1631161700},\n",
       "  {'pesq': 1.8690171241760254,\n",
       "   'stoi': np.float64(0.9827581877101357),\n",
       "   'time': 1583062400},\n",
       "  {'pesq': 1.3471620082855225,\n",
       "   'stoi': np.float64(0.83499173088886),\n",
       "   'time': 1582341400},\n",
       "  {'pesq': 1.517610788345337,\n",
       "   'stoi': np.float64(0.8238225980843784),\n",
       "   'time': 1589775800},\n",
       "  {'pesq': 1.0684338808059692,\n",
       "   'stoi': np.float64(0.5481218594805203),\n",
       "   'time': 1562834400},\n",
       "  {'pesq': 1.7633306980133057,\n",
       "   'stoi': np.float64(0.830254827099189),\n",
       "   'time': 1572143500},\n",
       "  {'pesq': 1.307857871055603,\n",
       "   'stoi': np.float64(0.7161971061647306),\n",
       "   'time': 1578325000},\n",
       "  {'pesq': 1.085881233215332,\n",
       "   'stoi': np.float64(0.6172064103461835),\n",
       "   'time': 1621283200},\n",
       "  {'pesq': 1.510963797569275,\n",
       "   'stoi': np.float64(0.8407764911650796),\n",
       "   'time': 1651972600},\n",
       "  {'pesq': 2.760129451751709,\n",
       "   'stoi': np.float64(0.9736301789217439),\n",
       "   'time': 1602764100},\n",
       "  {'pesq': 2.122664213180542,\n",
       "   'stoi': np.float64(0.9679266332949713),\n",
       "   'time': 1593226400},\n",
       "  {'pesq': 1.8144723176956177,\n",
       "   'stoi': np.float64(0.9213069866914104),\n",
       "   'time': 1589202700},\n",
       "  {'pesq': 1.1101908683776855,\n",
       "   'stoi': np.float64(0.3428432325507978),\n",
       "   'time': 1589181100},\n",
       "  {'pesq': 1.1405001878738403,\n",
       "   'stoi': np.float64(0.9094422506804571),\n",
       "   'time': 1582587000},\n",
       "  {'pesq': 1.0696502923965454,\n",
       "   'stoi': np.float64(0.7368031598548911),\n",
       "   'time': 1580949900},\n",
       "  {'pesq': 1.6785062551498413,\n",
       "   'stoi': np.float64(0.8341750675668854),\n",
       "   'time': 1610567300},\n",
       "  {'pesq': 1.056662678718567,\n",
       "   'stoi': np.float64(0.6934888945513235),\n",
       "   'time': 1579829500},\n",
       "  {'pesq': 2.5207576751708984,\n",
       "   'stoi': np.float64(0.981281562830122),\n",
       "   'time': 1584248900},\n",
       "  {'pesq': 3.7205724716186523,\n",
       "   'stoi': np.float64(0.9584271776480641),\n",
       "   'time': 1588521200},\n",
       "  {'pesq': 2.1193618774414062,\n",
       "   'stoi': np.float64(0.989163564307038),\n",
       "   'time': 1593827400},\n",
       "  {'pesq': 2.3226065635681152,\n",
       "   'stoi': np.float64(0.9528135090666715),\n",
       "   'time': 1588794700},\n",
       "  {'pesq': 1.394555687904358,\n",
       "   'stoi': np.float64(0.8338302109300348),\n",
       "   'time': 1590110100},\n",
       "  {'pesq': 1.0655051469802856,\n",
       "   'stoi': np.float64(0.1998300680940363),\n",
       "   'time': 1585509000},\n",
       "  {'pesq': 1.8946056365966797,\n",
       "   'stoi': np.float64(0.9758809842309407),\n",
       "   'time': 1586959200},\n",
       "  {'pesq': 1.217889428138733,\n",
       "   'stoi': np.float64(0.7592515008410494),\n",
       "   'time': 1578285600},\n",
       "  {'pesq': 1.0796712636947632,\n",
       "   'stoi': np.float64(0.5717652666271444),\n",
       "   'time': 1593983400},\n",
       "  {'pesq': 1.1914989948272705,\n",
       "   'stoi': np.float64(0.437512485032049),\n",
       "   'time': 1575472100},\n",
       "  {'pesq': 2.4229116439819336,\n",
       "   'stoi': np.float64(0.9519727804827718),\n",
       "   'time': 1599985100},\n",
       "  {'pesq': 2.532874822616577,\n",
       "   'stoi': np.float64(0.9822707041241253),\n",
       "   'time': 1582914600},\n",
       "  {'pesq': 1.8473515510559082,\n",
       "   'stoi': np.float64(0.904598615605537),\n",
       "   'time': 1584472500},\n",
       "  {'pesq': 1.5706920623779297,\n",
       "   'stoi': np.float64(0.9519113712158669),\n",
       "   'time': 1584180700},\n",
       "  {'pesq': 1.479157567024231,\n",
       "   'stoi': np.float64(0.9214114346343147),\n",
       "   'time': 1595739100},\n",
       "  {'pesq': 2.5323593616485596,\n",
       "   'stoi': np.float64(0.9848062372349928),\n",
       "   'time': 1586979500},\n",
       "  {'pesq': 1.3205808401107788,\n",
       "   'stoi': np.float64(0.8159620692462438),\n",
       "   'time': 1588537900},\n",
       "  {'pesq': 1.4625895023345947,\n",
       "   'stoi': np.float64(0.6164790622126122),\n",
       "   'time': 1587700300},\n",
       "  {'pesq': 1.565368890762329,\n",
       "   'stoi': np.float64(0.9715328696028899),\n",
       "   'time': 1591819200},\n",
       "  {'pesq': 1.1946676969528198,\n",
       "   'stoi': np.float64(0.835651740314218),\n",
       "   'time': 1586860500},\n",
       "  {'pesq': 1.0943684577941895,\n",
       "   'stoi': np.float64(0.8000628000629838),\n",
       "   'time': 1603121600},\n",
       "  {'pesq': 1.4661332368850708,\n",
       "   'stoi': np.float64(0.9313288981172837),\n",
       "   'time': 1580069400},\n",
       "  {'pesq': 1.1665267944335938,\n",
       "   'stoi': np.float64(0.7988987260085076),\n",
       "   'time': 1603316400},\n",
       "  {'pesq': 1.811720848083496,\n",
       "   'stoi': np.float64(0.9313853152429931),\n",
       "   'time': 1595962800},\n",
       "  {'pesq': 1.7700214385986328,\n",
       "   'stoi': np.float64(0.9436235708366241),\n",
       "   'time': 1593742800},\n",
       "  {'pesq': 1.0930784940719604,\n",
       "   'stoi': np.float64(0.8953325104289906),\n",
       "   'time': 1586052300},\n",
       "  {'pesq': 1.4758087396621704,\n",
       "   'stoi': np.float64(0.8350729855109728),\n",
       "   'time': 1591054700},\n",
       "  {'pesq': 1.5892202854156494,\n",
       "   'stoi': np.float64(0.9660108272377811),\n",
       "   'time': 1600762300},\n",
       "  {'pesq': 1.2672772407531738,\n",
       "   'stoi': np.float64(0.9197396195112224),\n",
       "   'time': 1661641700},\n",
       "  {'pesq': 1.4689126014709473,\n",
       "   'stoi': np.float64(0.8252798720557122),\n",
       "   'time': 1612034400},\n",
       "  {'pesq': 1.3025456666946411,\n",
       "   'stoi': np.float64(0.6596716676786238),\n",
       "   'time': 1617138200},\n",
       "  {'pesq': 1.0358989238739014,\n",
       "   'stoi': np.float64(0.5102038758278615),\n",
       "   'time': 1643011600},\n",
       "  {'pesq': 1.8604652881622314,\n",
       "   'stoi': np.float64(0.8789225532596383),\n",
       "   'time': 1588341600},\n",
       "  {'pesq': 1.6905746459960938,\n",
       "   'stoi': np.float64(0.9248140362774571),\n",
       "   'time': 1617053700},\n",
       "  {'pesq': 1.123780369758606,\n",
       "   'stoi': np.float64(0.7399449002081693),\n",
       "   'time': 1623533700},\n",
       "  {'pesq': 1.0666619539260864,\n",
       "   'stoi': np.float64(0.6799715774386889),\n",
       "   'time': 1608619800},\n",
       "  {'pesq': 1.0781489610671997,\n",
       "   'stoi': np.float64(0.6102842842682898),\n",
       "   'time': 1596913000},\n",
       "  {'pesq': 1.375192403793335,\n",
       "   'stoi': np.float64(0.8779797152988422),\n",
       "   'time': 1595222400},\n",
       "  {'pesq': 2.5066823959350586,\n",
       "   'stoi': np.float64(0.9190678972714703),\n",
       "   'time': 1616554300},\n",
       "  {'pesq': 1.1814866065979004,\n",
       "   'stoi': np.float64(0.7693190974091355),\n",
       "   'time': 1594711400},\n",
       "  {'pesq': 1.2333056926727295,\n",
       "   'stoi': np.float64(0.8421069773713551),\n",
       "   'time': 1592334500},\n",
       "  {'pesq': 1.4995203018188477,\n",
       "   'stoi': np.float64(0.9291630813591805),\n",
       "   'time': 1597352000},\n",
       "  {'pesq': 3.0772368907928467,\n",
       "   'stoi': np.float64(0.9925403432775369),\n",
       "   'time': 1587292300},\n",
       "  {'pesq': 1.0467582941055298,\n",
       "   'stoi': np.float64(0.640512068794054),\n",
       "   'time': 1593520400},\n",
       "  {'pesq': 1.1289985179901123,\n",
       "   'stoi': np.float64(0.8513170114725161),\n",
       "   'time': 1583569600},\n",
       "  {'pesq': 1.4358350038528442,\n",
       "   'stoi': np.float64(0.9067153333679223),\n",
       "   'time': 1585691900},\n",
       "  {'pesq': 1.5254852771759033,\n",
       "   'stoi': np.float64(0.8724229548967405),\n",
       "   'time': 1577635100},\n",
       "  {'pesq': 1.129072904586792,\n",
       "   'stoi': np.float64(0.73774902049288),\n",
       "   'time': 1584362500},\n",
       "  {'pesq': 2.061983823776245,\n",
       "   'stoi': np.float64(0.7418202509501195),\n",
       "   'time': 1577886800},\n",
       "  {'pesq': 1.0707783699035645,\n",
       "   'stoi': np.float64(0.5686239099015102),\n",
       "   'time': 1583450000},\n",
       "  {'pesq': 1.2285994291305542,\n",
       "   'stoi': np.float64(0.8217862334498365),\n",
       "   'time': 1614307200},\n",
       "  {'pesq': 2.302643299102783,\n",
       "   'stoi': np.float64(0.967904590784583),\n",
       "   'time': 1587647700},\n",
       "  {'pesq': 1.6782341003417969,\n",
       "   'stoi': np.float64(0.7236968421205597),\n",
       "   'time': 1605246700},\n",
       "  {'pesq': 2.1799545288085938,\n",
       "   'stoi': np.float64(0.9537908568682816),\n",
       "   'time': 1695658500},\n",
       "  {'pesq': 2.5866165161132812,\n",
       "   'stoi': np.float64(0.9570640953026771),\n",
       "   'time': 1701515900},\n",
       "  {'pesq': 1.1432669162750244,\n",
       "   'stoi': np.float64(0.8686941933282306),\n",
       "   'time': 1634718500},\n",
       "  {'pesq': 1.152192234992981,\n",
       "   'stoi': np.float64(0.7892108902412872),\n",
       "   'time': 1595516300},\n",
       "  {'pesq': 1.7774837017059326,\n",
       "   'stoi': np.float64(0.9688086533738661),\n",
       "   'time': 1666029100},\n",
       "  {'pesq': 1.2032006978988647,\n",
       "   'stoi': np.float64(0.6600006069308201),\n",
       "   'time': 1620483700},\n",
       "  {'pesq': 1.772432565689087,\n",
       "   'stoi': np.float64(0.8434024730652986),\n",
       "   'time': 1601238100},\n",
       "  {'pesq': 1.6366417407989502,\n",
       "   'stoi': np.float64(0.900182397689031),\n",
       "   'time': 1602236900},\n",
       "  {'pesq': 1.8184969425201416,\n",
       "   'stoi': np.float64(0.9513164691418429),\n",
       "   'time': 1577005100},\n",
       "  {'pesq': 1.111232042312622,\n",
       "   'stoi': np.float64(0.8112595125376214),\n",
       "   'time': 1619137900},\n",
       "  {'pesq': 1.063725471496582,\n",
       "   'stoi': np.float64(0.4251100241776032),\n",
       "   'time': 1588940400},\n",
       "  {'pesq': 1.0988274812698364,\n",
       "   'stoi': np.float64(0.6025238310493446),\n",
       "   'time': 1668558900},\n",
       "  {'pesq': 1.2203986644744873,\n",
       "   'stoi': np.float64(0.7975702696001508),\n",
       "   'time': 1642239000},\n",
       "  {'pesq': 1.6939973831176758,\n",
       "   'stoi': np.float64(0.9657974785433101),\n",
       "   'time': 1609359700},\n",
       "  {'pesq': 2.3374545574188232,\n",
       "   'stoi': np.float64(0.8840764039428325),\n",
       "   'time': 1585647900},\n",
       "  {'pesq': 1.1582565307617188,\n",
       "   'stoi': np.float64(0.6150754687068269),\n",
       "   'time': 1574938100},\n",
       "  {'pesq': 1.603050947189331,\n",
       "   'stoi': np.float64(0.9372427808218075),\n",
       "   'time': 1566992700},\n",
       "  {'pesq': 1.5066691637039185,\n",
       "   'stoi': np.float64(0.8930160044792276),\n",
       "   'time': 1571003100},\n",
       "  {'pesq': 1.298140048980713,\n",
       "   'stoi': np.float64(0.8718161791951768),\n",
       "   'time': 1596618200},\n",
       "  {'pesq': 1.3000500202178955,\n",
       "   'stoi': np.float64(0.840621743344128),\n",
       "   'time': 1575916500},\n",
       "  {'pesq': 1.4326493740081787,\n",
       "   'stoi': np.float64(0.886190489040149),\n",
       "   'time': 1569490000},\n",
       "  {'pesq': 2.232832193374634,\n",
       "   'stoi': np.float64(0.9568030873283209),\n",
       "   'time': 1576909300},\n",
       "  {'pesq': 1.9976959228515625,\n",
       "   'stoi': np.float64(0.9087531324970232),\n",
       "   'time': 1577932000},\n",
       "  {'pesq': 1.1065824031829834,\n",
       "   'stoi': np.float64(0.8092999121586502),\n",
       "   'time': 1570157500},\n",
       "  {'pesq': 1.455310583114624,\n",
       "   'stoi': np.float64(0.8771997837619715),\n",
       "   'time': 1589524900},\n",
       "  {'pesq': 1.3088330030441284,\n",
       "   'stoi': np.float64(0.937526157487766),\n",
       "   'time': 1611869400},\n",
       "  {'pesq': 1.1786545515060425,\n",
       "   'stoi': np.float64(0.9296489130249379),\n",
       "   'time': 1578132700},\n",
       "  {'pesq': 1.4651132822036743,\n",
       "   'stoi': np.float64(0.876809354320852),\n",
       "   'time': 1577108600},\n",
       "  {'pesq': 2.1068248748779297,\n",
       "   'stoi': np.float64(0.9370033184433393),\n",
       "   'time': 1578249800},\n",
       "  {'pesq': 1.8738980293273926,\n",
       "   'stoi': np.float64(0.9754822997765414),\n",
       "   'time': 1609767400},\n",
       "  {'pesq': 1.4435490369796753,\n",
       "   'stoi': np.float64(0.5247505028136472),\n",
       "   'time': 1571126800},\n",
       "  {'pesq': 1.1031270027160645,\n",
       "   'stoi': np.float64(0.8070605150488275),\n",
       "   'time': 1584192400},\n",
       "  {'pesq': 1.5353617668151855,\n",
       "   'stoi': np.float64(0.78999412324702),\n",
       "   'time': 1582823300},\n",
       "  {'pesq': 1.1020190715789795,\n",
       "   'stoi': np.float64(0.5133084317022863),\n",
       "   'time': 1576170500},\n",
       "  {'pesq': 1.9762670993804932,\n",
       "   'stoi': np.float64(0.9831192129380677),\n",
       "   'time': 1594786700},\n",
       "  {'pesq': 1.425931453704834,\n",
       "   'stoi': np.float64(0.2710016389436301),\n",
       "   'time': 1572989100},\n",
       "  {'pesq': 1.1928631067276,\n",
       "   'stoi': np.float64(0.9077710436029156),\n",
       "   'time': 1570461500},\n",
       "  {'pesq': 2.678095817565918,\n",
       "   'stoi': np.float64(0.981013158528903),\n",
       "   'time': 1585452400},\n",
       "  {'pesq': 1.150087594985962,\n",
       "   'stoi': np.float64(0.7045389899621167),\n",
       "   'time': 1594363500},\n",
       "  {'pesq': 2.374499797821045,\n",
       "   'stoi': np.float64(0.9697915081673195),\n",
       "   'time': 1693888400},\n",
       "  {'pesq': 1.463401436805725,\n",
       "   'stoi': np.float64(0.7350769476225575),\n",
       "   'time': 1609768300},\n",
       "  {'pesq': 2.055147409439087,\n",
       "   'stoi': np.float64(0.9545862708747924),\n",
       "   'time': 1601408200},\n",
       "  {'pesq': 1.0423890352249146,\n",
       "   'stoi': np.float64(-0.07142328406342902),\n",
       "   'time': 1574177700},\n",
       "  {'pesq': 1.223813772201538,\n",
       "   'stoi': np.float64(0.8155656797523099),\n",
       "   'time': 1628209900},\n",
       "  {'pesq': 1.3314614295959473,\n",
       "   'stoi': np.float64(0.8113256678450186),\n",
       "   'time': 1632605100},\n",
       "  {'pesq': 1.4660899639129639,\n",
       "   'stoi': np.float64(0.9498254810448667),\n",
       "   'time': 1615199800},\n",
       "  {'pesq': 2.092796802520752,\n",
       "   'stoi': np.float64(0.9511379279199859),\n",
       "   'time': 1595146400},\n",
       "  {'pesq': 1.1588892936706543,\n",
       "   'stoi': np.float64(0.7847466187970237),\n",
       "   'time': 1596533100},\n",
       "  {'pesq': 2.071476459503174,\n",
       "   'stoi': np.float64(0.9313974439534193),\n",
       "   'time': 1609008000},\n",
       "  {'pesq': 1.3186008930206299,\n",
       "   'stoi': np.float64(0.6187018719438292),\n",
       "   'time': 1615820500},\n",
       "  {'pesq': 1.2461540699005127,\n",
       "   'stoi': np.float64(0.7790088504366617),\n",
       "   'time': 1680259700},\n",
       "  {'pesq': 2.267117977142334,\n",
       "   'stoi': np.float64(0.7696930664784106),\n",
       "   'time': 1623472900},\n",
       "  {'pesq': 3.0508923530578613,\n",
       "   'stoi': np.float64(0.9886098364123375),\n",
       "   'time': 1580271100},\n",
       "  {'pesq': 1.6378836631774902,\n",
       "   'stoi': np.float64(0.800655938383592),\n",
       "   'time': 1574850300},\n",
       "  {'pesq': 1.0729012489318848,\n",
       "   'stoi': np.float64(0.46643780985013134),\n",
       "   'time': 1624492200},\n",
       "  {'pesq': 1.391108751296997,\n",
       "   'stoi': np.float64(0.8432492257503061),\n",
       "   'time': 1657096600},\n",
       "  {'pesq': 2.417785882949829,\n",
       "   'stoi': np.float64(0.9915576755315404),\n",
       "   'time': 1636522500},\n",
       "  {'pesq': 1.896100401878357,\n",
       "   'stoi': np.float64(0.9351551893331144),\n",
       "   'time': 1589190100},\n",
       "  {'pesq': 2.365070104598999,\n",
       "   'stoi': np.float64(0.9679476456624388),\n",
       "   'time': 1598587100},\n",
       "  {'pesq': 1.3014683723449707,\n",
       "   'stoi': np.float64(0.8790213235497623),\n",
       "   'time': 1586602200},\n",
       "  {'pesq': 1.2639620304107666,\n",
       "   'stoi': np.float64(0.9393519776177847),\n",
       "   'time': 1670514400},\n",
       "  {'pesq': 2.7189791202545166,\n",
       "   'stoi': np.float64(0.991845224437271),\n",
       "   'time': 1649506800},\n",
       "  {'pesq': 1.5656077861785889,\n",
       "   'stoi': np.float64(0.8993003279752566),\n",
       "   'time': 1633574800},\n",
       "  {'pesq': 1.3398629426956177,\n",
       "   'stoi': np.float64(0.9215720915169926),\n",
       "   'time': 1610081700},\n",
       "  {'pesq': 1.8562824726104736,\n",
       "   'stoi': np.float64(0.9508736618277412),\n",
       "   'time': 1589217900},\n",
       "  {'pesq': 1.0242723226547241,\n",
       "   'stoi': np.float64(0.31431327337754555),\n",
       "   'time': 1606620800},\n",
       "  {'pesq': 1.7920078039169312,\n",
       "   'stoi': np.float64(0.9447371900492352),\n",
       "   'time': 1615033700},\n",
       "  {'pesq': 1.932068109512329,\n",
       "   'stoi': np.float64(0.9501082519464829),\n",
       "   'time': 1621891500},\n",
       "  {'pesq': 1.3433406352996826,\n",
       "   'stoi': np.float64(0.8337727886549435),\n",
       "   'time': 1632112100},\n",
       "  {'pesq': 1.3190107345581055,\n",
       "   'stoi': np.float64(0.8474445752353169),\n",
       "   'time': 1578283700},\n",
       "  {'pesq': 1.0463804006576538,\n",
       "   'stoi': np.float64(0.6641987598805482),\n",
       "   'time': 1566929400},\n",
       "  {'pesq': 2.1408536434173584,\n",
       "   'stoi': np.float64(0.9397767514902181),\n",
       "   'time': 1606501200},\n",
       "  {'pesq': 1.9819252490997314,\n",
       "   'stoi': np.float64(0.9463250860352218),\n",
       "   'time': 1622034500},\n",
       "  {'pesq': 1.367281198501587,\n",
       "   'stoi': np.float64(0.9488921347599304),\n",
       "   'time': 1649135200},\n",
       "  {'pesq': 1.225700855255127,\n",
       "   'stoi': np.float64(0.39960856593891075),\n",
       "   'time': 1585455700},\n",
       "  {'pesq': 1.2843563556671143,\n",
       "   'stoi': np.float64(0.5477460790568001),\n",
       "   'time': 1583670500},\n",
       "  {'pesq': 1.5740677118301392,\n",
       "   'stoi': np.float64(0.8969354503247481),\n",
       "   'time': 1657843000},\n",
       "  {'pesq': 1.546976089477539,\n",
       "   'stoi': np.float64(0.48523701572972194),\n",
       "   'time': 1604611000},\n",
       "  {'pesq': 1.0552414655685425,\n",
       "   'stoi': np.float64(0.6192983556112078),\n",
       "   'time': 1579243600},\n",
       "  {'pesq': 1.2682000398635864,\n",
       "   'stoi': np.float64(0.8274544101979214),\n",
       "   'time': 1591702300},\n",
       "  {'pesq': 1.2121038436889648,\n",
       "   'stoi': np.float64(0.6174467088097206),\n",
       "   'time': 1567088900},\n",
       "  {'pesq': 2.265859842300415,\n",
       "   'stoi': np.float64(0.9406354265304836),\n",
       "   'time': 1583798000},\n",
       "  {'pesq': 1.5819052457809448,\n",
       "   'stoi': np.float64(0.8913037981501496),\n",
       "   'time': 1569261800},\n",
       "  {'pesq': 1.8062925338745117,\n",
       "   'stoi': np.float64(0.9383336591953448),\n",
       "   'time': 1573999800},\n",
       "  {'pesq': 2.620981454849243,\n",
       "   'stoi': np.float64(0.962829126299329),\n",
       "   'time': 1575376900},\n",
       "  {'pesq': 1.111870527267456,\n",
       "   'stoi': np.float64(0.7357495383838633),\n",
       "   'time': 1564926500},\n",
       "  {'pesq': 1.1067488193511963,\n",
       "   'stoi': np.float64(0.5018804398707516),\n",
       "   'time': 1611534600},\n",
       "  {'pesq': 1.1339560747146606,\n",
       "   'stoi': np.float64(0.7879585306919297),\n",
       "   'time': 1634629700},\n",
       "  {'pesq': 1.4272396564483643,\n",
       "   'stoi': np.float64(0.9130938538616543),\n",
       "   'time': 1627596000},\n",
       "  {'pesq': 1.7478384971618652,\n",
       "   'stoi': np.float64(0.9531942812031997),\n",
       "   'time': 1618024700},\n",
       "  {'pesq': 1.4074914455413818,\n",
       "   'stoi': np.float64(0.30059040284661986),\n",
       "   'time': 1622948400},\n",
       "  {'pesq': 2.0331552028656006,\n",
       "   'stoi': np.float64(0.9667420971258951),\n",
       "   'time': 1650915200},\n",
       "  {'pesq': 1.2714234590530396,\n",
       "   'stoi': np.float64(0.9149943634963955),\n",
       "   'time': 1653037300},\n",
       "  {'pesq': 2.4061055183410645,\n",
       "   'stoi': np.float64(0.9907814877315414),\n",
       "   'time': 1648007600},\n",
       "  {'pesq': 1.6206063032150269,\n",
       "   'stoi': np.float64(0.8907060213218863),\n",
       "   'time': 1612778000},\n",
       "  {'pesq': 1.0823709964752197,\n",
       "   'stoi': np.float64(0.7226073544388412),\n",
       "   'time': 1594276200},\n",
       "  {'pesq': 1.1874806880950928,\n",
       "   'stoi': np.float64(0.915473321019506),\n",
       "   'time': 1618053900},\n",
       "  {'pesq': 1.2232999801635742,\n",
       "   'stoi': np.float64(0.81116491999128),\n",
       "   'time': 1638674200},\n",
       "  {'pesq': 1.5349411964416504,\n",
       "   'stoi': np.float64(0.9794125286529854),\n",
       "   'time': 1617196500},\n",
       "  {'pesq': 1.3643676042556763,\n",
       "   'stoi': np.float64(0.9368476550679017),\n",
       "   'time': 1643766300},\n",
       "  {'pesq': 1.7645258903503418,\n",
       "   'stoi': np.float64(0.9389290245476827),\n",
       "   'time': 1601080800},\n",
       "  {'pesq': 1.2399147748947144,\n",
       "   'stoi': np.float64(0.6298469919898113),\n",
       "   'time': 1586617000},\n",
       "  {'pesq': 1.1022430658340454,\n",
       "   'stoi': np.float64(0.5801450105703883),\n",
       "   'time': 1582629600},\n",
       "  {'pesq': 2.1492531299591064,\n",
       "   'stoi': np.float64(0.9787668982672807),\n",
       "   'time': 1606540700},\n",
       "  {'pesq': 1.7636969089508057,\n",
       "   'stoi': np.float64(0.926485306977036),\n",
       "   'time': 1605151200},\n",
       "  {'pesq': 1.2626395225524902,\n",
       "   'stoi': np.float64(0.4883644971293268),\n",
       "   'time': 1585882900},\n",
       "  {'pesq': 1.5390355587005615,\n",
       "   'stoi': np.float64(0.9024460394208194),\n",
       "   'time': 1583909600},\n",
       "  {'pesq': 1.5694875717163086,\n",
       "   'stoi': np.float64(0.9390371152902459),\n",
       "   'time': 1576708700},\n",
       "  {'pesq': 3.282369613647461,\n",
       "   'stoi': np.float64(0.9828760713386445),\n",
       "   'time': 1588251500},\n",
       "  {'pesq': 1.0794001817703247,\n",
       "   'stoi': np.float64(0.7293630751583015),\n",
       "   'time': 1581166900},\n",
       "  {'pesq': 2.5316286087036133,\n",
       "   'stoi': np.float64(0.9774360871646447),\n",
       "   'time': 1578314100},\n",
       "  {'pesq': 1.0939278602600098,\n",
       "   'stoi': np.float64(0.8261935363613595),\n",
       "   'time': 1582134900},\n",
       "  {'pesq': 1.130744457244873,\n",
       "   'stoi': np.float64(0.724208887132742),\n",
       "   'time': 1568141800},\n",
       "  {'pesq': 1.5025110244750977,\n",
       "   'stoi': np.float64(0.9356381244789137),\n",
       "   'time': 1587861000},\n",
       "  {'pesq': 1.503301978111267,\n",
       "   'stoi': np.float64(0.6648463288651459),\n",
       "   'time': 1579960900},\n",
       "  {'pesq': 2.0444769859313965,\n",
       "   'stoi': np.float64(0.900686183670286),\n",
       "   'time': 1573852300},\n",
       "  {'pesq': 1.6193170547485352,\n",
       "   'stoi': np.float64(0.8573342039231762),\n",
       "   'time': 1584477800},\n",
       "  {'pesq': 1.707519769668579,\n",
       "   'stoi': np.float64(0.9482189686574513),\n",
       "   'time': 1578125800},\n",
       "  {'pesq': 2.5103609561920166,\n",
       "   'stoi': np.float64(0.9451369743110526),\n",
       "   'time': 1586728700},\n",
       "  {'pesq': 1.2533818483352661,\n",
       "   'stoi': np.float64(0.8812874101858916),\n",
       "   'time': 1614878000},\n",
       "  {'pesq': 1.1091341972351074,\n",
       "   'stoi': np.float64(0.764814131026412),\n",
       "   'time': 1598117300},\n",
       "  {'pesq': 3.22440767288208,\n",
       "   'stoi': np.float64(0.969405936002036),\n",
       "   'time': 1595481000},\n",
       "  {'pesq': 2.0249621868133545,\n",
       "   'stoi': np.float64(0.9521604459476584),\n",
       "   'time': 1589397100},\n",
       "  {'pesq': 1.3101041316986084,\n",
       "   'stoi': np.float64(0.8012721546608971),\n",
       "   'time': 1591332600},\n",
       "  {'pesq': 1.3336141109466553,\n",
       "   'stoi': np.float64(0.9222390956075944),\n",
       "   'time': 1604793300},\n",
       "  {'pesq': 1.437646746635437,\n",
       "   'stoi': np.float64(0.9286597173826096),\n",
       "   'time': 1586393700},\n",
       "  {'pesq': 2.4374499320983887,\n",
       "   'stoi': np.float64(0.9550297995162318),\n",
       "   'time': 1590754400},\n",
       "  {'pesq': 1.372909665107727,\n",
       "   'stoi': np.float64(0.7996993567690557),\n",
       "   'time': 1574005000},\n",
       "  {'pesq': 1.7737185955047607,\n",
       "   'stoi': np.float64(0.9611689732804002),\n",
       "   'time': 1580230100},\n",
       "  {'pesq': 1.8090457916259766,\n",
       "   'stoi': np.float64(0.874923626735282),\n",
       "   'time': 1594909500},\n",
       "  {'pesq': 1.4783741235733032,\n",
       "   'stoi': np.float64(0.9370755019535626),\n",
       "   'time': 1588331000},\n",
       "  {'pesq': 2.7560887336730957,\n",
       "   'stoi': np.float64(0.9613902297428873),\n",
       "   'time': 1584371100},\n",
       "  {'pesq': 2.488241195678711,\n",
       "   'stoi': np.float64(0.9611062467484212),\n",
       "   'time': 1571943200},\n",
       "  {'pesq': 1.3104205131530762,\n",
       "   'stoi': np.float64(0.6227897996147321),\n",
       "   'time': 1570675000},\n",
       "  {'pesq': 2.334587335586548,\n",
       "   'stoi': np.float64(0.9545498546089883),\n",
       "   'time': 1573983700},\n",
       "  {'pesq': 1.2279374599456787,\n",
       "   'stoi': np.float64(0.7314959000575617),\n",
       "   'time': 1603925700},\n",
       "  {'pesq': 1.446553349494934,\n",
       "   'stoi': np.float64(0.9751435393087705),\n",
       "   'time': 1581086800},\n",
       "  {'pesq': 1.961272120475769,\n",
       "   'stoi': np.float64(0.977124605448857),\n",
       "   'time': 1575479700},\n",
       "  {'pesq': 3.381165027618408,\n",
       "   'stoi': np.float64(0.9873069803704273),\n",
       "   'time': 1569871500},\n",
       "  {'pesq': 1.5119965076446533,\n",
       "   'stoi': np.float64(0.9223359323632478),\n",
       "   'time': 1581704600},\n",
       "  {'pesq': 2.226799488067627,\n",
       "   'stoi': np.float64(0.9852088681017998),\n",
       "   'time': 1590991000},\n",
       "  {'pesq': 1.0518158674240112,\n",
       "   'stoi': np.float64(0.5683759451671869),\n",
       "   'time': 1626559500},\n",
       "  {'pesq': 2.3501808643341064,\n",
       "   'stoi': np.float64(0.969791639016602),\n",
       "   'time': 1601353700},\n",
       "  {'pesq': 1.0465011596679688,\n",
       "   'stoi': np.float64(0.6043011277691162),\n",
       "   'time': 1612917200},\n",
       "  {'pesq': 1.225129246711731,\n",
       "   'stoi': np.float64(0.939414975859057),\n",
       "   'time': 1615321300},\n",
       "  {'pesq': 1.6341874599456787,\n",
       "   'stoi': np.float64(0.8586419314863364),\n",
       "   'time': 1593889900},\n",
       "  {'pesq': 1.4615576267242432,\n",
       "   'stoi': np.float64(0.578853458606448),\n",
       "   'time': 1611903400},\n",
       "  {'pesq': 1.9746466875076294,\n",
       "   'stoi': np.float64(0.9587984831484244),\n",
       "   'time': 1593835500},\n",
       "  {'pesq': 1.3860912322998047,\n",
       "   'stoi': np.float64(0.8880906773400157),\n",
       "   'time': 1606669700},\n",
       "  {'pesq': 1.0529893636703491,\n",
       "   'stoi': np.float64(0.5144743519575027),\n",
       "   'time': 1593713600},\n",
       "  {'pesq': 1.0759141445159912,\n",
       "   'stoi': np.float64(0.6016806251985731),\n",
       "   'time': 1586540800},\n",
       "  {'pesq': 1.174278974533081,\n",
       "   'stoi': np.float64(0.444631387604733),\n",
       "   'time': 1590083800},\n",
       "  {'pesq': 1.3671557903289795,\n",
       "   'stoi': np.float64(0.9435178391817636),\n",
       "   'time': 1600496000},\n",
       "  {'pesq': 1.3964017629623413,\n",
       "   'stoi': np.float64(0.9189952510818565),\n",
       "   'time': 1596913900},\n",
       "  {'pesq': 1.7371423244476318,\n",
       "   'stoi': np.float64(0.9278183243432093),\n",
       "   'time': 1603269400},\n",
       "  {'pesq': 1.0778547525405884,\n",
       "   'stoi': np.float64(0.7393994012054337),\n",
       "   'time': 1642648400},\n",
       "  {'pesq': 1.6796720027923584,\n",
       "   'stoi': np.float64(0.9255041783918244),\n",
       "   'time': 1639257100},\n",
       "  {'pesq': 2.873993158340454,\n",
       "   'stoi': np.float64(0.9377050367942942),\n",
       "   'time': 1618631300},\n",
       "  {'pesq': 1.2173020839691162,\n",
       "   'stoi': np.float64(0.6229322608067328),\n",
       "   'time': 1597138500},\n",
       "  {'pesq': 1.3332949876785278,\n",
       "   'stoi': np.float64(0.8353246449745928),\n",
       "   'time': 1634055500},\n",
       "  {'pesq': 1.7489209175109863,\n",
       "   'stoi': np.float64(0.968543996562734),\n",
       "   'time': 1636630700},\n",
       "  {'pesq': 1.5210580825805664,\n",
       "   'stoi': np.float64(0.8582063000080855),\n",
       "   'time': 1661374300},\n",
       "  {'pesq': 1.2860723733901978,\n",
       "   'stoi': np.float64(0.8361257343765354),\n",
       "   'time': 1640292900},\n",
       "  {'pesq': 1.038405418395996,\n",
       "   'stoi': np.float64(0.5391000848111053),\n",
       "   'time': 1640240700},\n",
       "  {'pesq': 2.2880501747131348,\n",
       "   'stoi': np.float64(0.904939970455255),\n",
       "   'time': 1651711300},\n",
       "  {'pesq': 2.1603972911834717,\n",
       "   'stoi': np.float64(0.9257011950319146),\n",
       "   'time': 1606022500},\n",
       "  {'pesq': 1.2829513549804688,\n",
       "   'stoi': np.float64(0.8891561452798069),\n",
       "   'time': 1644789000},\n",
       "  {'pesq': 1.661245584487915,\n",
       "   'stoi': np.float64(0.8533148209714432),\n",
       "   'time': 1611843700},\n",
       "  {'pesq': 1.1777094602584839,\n",
       "   'stoi': np.float64(0.8715367233187565),\n",
       "   'time': 1670333700},\n",
       "  {'pesq': 2.7544658184051514,\n",
       "   'stoi': np.float64(0.9681839819742059),\n",
       "   'time': 1633104400},\n",
       "  {'pesq': 1.4442532062530518,\n",
       "   'stoi': np.float64(0.9187833888518723),\n",
       "   'time': 1614870500},\n",
       "  {'pesq': 1.1827263832092285,\n",
       "   'stoi': np.float64(0.7838703826729746),\n",
       "   'time': 1617007800},\n",
       "  {'pesq': 1.7671282291412354,\n",
       "   'stoi': np.float64(0.9095050254015876),\n",
       "   'time': 1672113200},\n",
       "  {'pesq': 1.7864446640014648,\n",
       "   'stoi': np.float64(0.945995133368412),\n",
       "   'time': 1601428500},\n",
       "  {'pesq': 1.1351693868637085,\n",
       "   'stoi': np.float64(0.8355975968339585),\n",
       "   'time': 1610263200},\n",
       "  {'pesq': 1.9843333959579468,\n",
       "   'stoi': np.float64(0.9563725723357053),\n",
       "   'time': 1616128200},\n",
       "  {'pesq': 2.3385250568389893,\n",
       "   'stoi': np.float64(0.9697937570980983),\n",
       "   'time': 1652849200},\n",
       "  {'pesq': 1.2415133714675903,\n",
       "   'stoi': np.float64(0.8412396423100064),\n",
       "   'time': 1641419400},\n",
       "  {'pesq': 1.5394549369812012,\n",
       "   'stoi': np.float64(0.9476360400880489),\n",
       "   'time': 1657893000},\n",
       "  {'pesq': 1.8347535133361816,\n",
       "   'stoi': np.float64(0.969806639485877),\n",
       "   'time': 1647961800},\n",
       "  {'pesq': 1.7201380729675293,\n",
       "   'stoi': np.float64(0.549147659924156),\n",
       "   'time': 1628102700},\n",
       "  {'pesq': 2.132582664489746,\n",
       "   'stoi': np.float64(0.9731984016582169),\n",
       "   'time': 1611184500},\n",
       "  {'pesq': 1.5720491409301758,\n",
       "   'stoi': np.float64(0.9489669562113502),\n",
       "   'time': 1622341900},\n",
       "  {'pesq': 1.1790655851364136,\n",
       "   'stoi': np.float64(0.8511424516531146),\n",
       "   'time': 1612359100},\n",
       "  {'pesq': 2.2565674781799316,\n",
       "   'stoi': np.float64(0.980924203708506),\n",
       "   'time': 1628712500},\n",
       "  {'pesq': 1.4341059923171997,\n",
       "   'stoi': np.float64(0.9183226021751412),\n",
       "   'time': 1628143800},\n",
       "  {'pesq': 1.1462767124176025,\n",
       "   'stoi': np.float64(0.8101052659285831),\n",
       "   'time': 1600798000},\n",
       "  {'pesq': 1.1414854526519775,\n",
       "   'stoi': np.float64(0.8283350267331887),\n",
       "   'time': 1603395000},\n",
       "  {'pesq': 2.611680269241333,\n",
       "   'stoi': np.float64(0.9602424776204854),\n",
       "   'time': 1675015300},\n",
       "  {'pesq': 1.4255582094192505,\n",
       "   'stoi': np.float64(0.9266753680784914),\n",
       "   'time': 1638674800},\n",
       "  {'pesq': 1.9601243734359741,\n",
       "   'stoi': np.float64(0.8889821170617686),\n",
       "   'time': 1670539800},\n",
       "  {'pesq': 1.9626234769821167,\n",
       "   'stoi': np.float64(0.9615788674414457),\n",
       "   'time': 1664215400},\n",
       "  {'pesq': 1.0524184703826904,\n",
       "   'stoi': np.float64(0.7155639221543929),\n",
       "   'time': 1637297900},\n",
       "  {'pesq': 1.3912854194641113,\n",
       "   'stoi': np.float64(0.9119590048250598),\n",
       "   'time': 1656385300},\n",
       "  {'pesq': 2.1506588459014893,\n",
       "   'stoi': np.float64(0.904648586208121),\n",
       "   'time': 1630446800},\n",
       "  {'pesq': 2.2897708415985107,\n",
       "   'stoi': np.float64(0.9538114875797368),\n",
       "   'time': 1605688700},\n",
       "  {'pesq': 1.5320087671279907,\n",
       "   'stoi': np.float64(0.9449379421807382),\n",
       "   'time': 1623320400},\n",
       "  {'pesq': 1.5559327602386475,\n",
       "   'stoi': np.float64(0.9167280352858058),\n",
       "   'time': 1661683200},\n",
       "  {'pesq': 1.1214395761489868,\n",
       "   'stoi': np.float64(0.4408603755453659),\n",
       "   'time': 1595949400},\n",
       "  {'pesq': 1.355591058731079,\n",
       "   'stoi': np.float64(0.9197048512112174),\n",
       "   'time': 1595438300},\n",
       "  {'pesq': 1.666364312171936,\n",
       "   'stoi': np.float64(0.870144110721504),\n",
       "   'time': 1629428500},\n",
       "  {'pesq': 1.2054972648620605,\n",
       "   'stoi': np.float64(0.615052505911034),\n",
       "   'time': 1633891300},\n",
       "  {'pesq': 1.2668346166610718,\n",
       "   'stoi': np.float64(0.4351924566136868),\n",
       "   'time': 1669564300},\n",
       "  {'pesq': 2.302572250366211,\n",
       "   'stoi': np.float64(0.9695156490123434),\n",
       "   'time': 1604061000},\n",
       "  {'pesq': 2.392474412918091,\n",
       "   'stoi': np.float64(0.9521365988229752),\n",
       "   'time': 1597955800},\n",
       "  {'pesq': 1.6768170595169067,\n",
       "   'stoi': np.float64(0.9482225546355797),\n",
       "   'time': 1605966500},\n",
       "  {'pesq': 1.24749755859375,\n",
       "   'stoi': np.float64(0.9096921408405322),\n",
       "   'time': 1640359600},\n",
       "  {'pesq': 1.1060041189193726,\n",
       "   'stoi': np.float64(0.720720892681668),\n",
       "   'time': 1610163200},\n",
       "  {'pesq': 1.8469948768615723,\n",
       "   'stoi': np.float64(0.8910171949361948),\n",
       "   'time': 1659396400},\n",
       "  {'pesq': 1.4161086082458496,\n",
       "   'stoi': np.float64(0.9495446060745603),\n",
       "   'time': 1663432600},\n",
       "  {'pesq': 1.3588088750839233,\n",
       "   'stoi': np.float64(0.930255461743199),\n",
       "   'time': 1645694700},\n",
       "  {'pesq': 1.4953844547271729,\n",
       "   'stoi': np.float64(0.980506634998405),\n",
       "   'time': 1620394900},\n",
       "  {'pesq': 2.159233331680298,\n",
       "   'stoi': np.float64(0.9583931683272054),\n",
       "   'time': 1613797400},\n",
       "  {'pesq': 1.1225413084030151,\n",
       "   'stoi': np.float64(0.8280881716556902),\n",
       "   'time': 1605977100},\n",
       "  {'pesq': 2.673875331878662,\n",
       "   'stoi': np.float64(0.9643113531023491),\n",
       "   'time': 1620876000},\n",
       "  {'pesq': 2.097684621810913,\n",
       "   'stoi': np.float64(0.982178211629674),\n",
       "   'time': 1648807100},\n",
       "  {'pesq': 2.8443474769592285,\n",
       "   'stoi': np.float64(0.982390071379025),\n",
       "   'time': 1624435200},\n",
       "  {'pesq': 1.4826992750167847,\n",
       "   'stoi': np.float64(0.8936048063640629),\n",
       "   'time': 1641692100},\n",
       "  {'pesq': 1.0826750993728638,\n",
       "   'stoi': np.float64(0.7151233396427464),\n",
       "   'time': 1611738500},\n",
       "  {'pesq': 1.6678725481033325,\n",
       "   'stoi': np.float64(0.8870507066512292),\n",
       "   'time': 1599024800},\n",
       "  {'pesq': 2.5889432430267334,\n",
       "   'stoi': np.float64(0.9771706194632167),\n",
       "   'time': 1611660000},\n",
       "  {'pesq': 1.1942917108535767,\n",
       "   'stoi': np.float64(0.7563512241900574),\n",
       "   'time': 1585886300},\n",
       "  {'pesq': 1.0435552597045898,\n",
       "   'stoi': np.float64(0.5340815772723908),\n",
       "   'time': 1573478800},\n",
       "  {'pesq': 1.7152156829833984,\n",
       "   'stoi': np.float64(0.8698488902386697),\n",
       "   'time': 1578298400},\n",
       "  {'pesq': 2.3738605976104736,\n",
       "   'stoi': np.float64(0.9478808061315729),\n",
       "   'time': 1590711900},\n",
       "  {'pesq': 2.0396645069122314,\n",
       "   'stoi': np.float64(0.9786033804312259),\n",
       "   'time': 1614917300},\n",
       "  {'pesq': 1.2004188299179077,\n",
       "   'stoi': np.float64(0.8320726176716807),\n",
       "   'time': 1594438300},\n",
       "  {'pesq': 1.2943320274353027,\n",
       "   'stoi': np.float64(0.7852425404072235),\n",
       "   'time': 1581854600},\n",
       "  {'pesq': 1.4219939708709717,\n",
       "   'stoi': np.float64(0.8859295520413718),\n",
       "   'time': 1581298700},\n",
       "  {'pesq': 1.6325421333312988,\n",
       "   'stoi': np.float64(0.9541457812641346),\n",
       "   'time': 1599384600},\n",
       "  {'pesq': 1.3936471939086914,\n",
       "   'stoi': np.float64(0.7749653835780784),\n",
       "   'time': 1588346000},\n",
       "  {'pesq': 1.1338036060333252,\n",
       "   'stoi': np.float64(0.7800318121641593),\n",
       "   'time': 1588704100},\n",
       "  {'pesq': 1.5929946899414062,\n",
       "   'stoi': np.float64(0.9073504363468647),\n",
       "   'time': 1594850400},\n",
       "  {'pesq': 2.207212209701538,\n",
       "   'stoi': np.float64(0.9534200016967015),\n",
       "   'time': 1584239500},\n",
       "  {'pesq': 1.7171623706817627,\n",
       "   'stoi': np.float64(0.9472041709354588),\n",
       "   'time': 1582462400},\n",
       "  {'pesq': 1.440888524055481,\n",
       "   'stoi': np.float64(0.9658440151188488),\n",
       "   'time': 1621232700},\n",
       "  {'pesq': 2.691464424133301,\n",
       "   'stoi': np.float64(0.8210477883141709),\n",
       "   'time': 1579846800},\n",
       "  {'pesq': 2.198453903198242,\n",
       "   'stoi': np.float64(0.9191932137763424),\n",
       "   'time': 1584906000},\n",
       "  {'pesq': 1.556395411491394,\n",
       "   'stoi': np.float64(0.9508789059170563),\n",
       "   'time': 1595892500},\n",
       "  {'pesq': 1.1428313255310059,\n",
       "   'stoi': np.float64(0.8349724968304518),\n",
       "   'time': 1593274800},\n",
       "  {'pesq': 1.2966933250427246,\n",
       "   'stoi': np.float64(0.8401108435835328),\n",
       "   'time': 1595916300},\n",
       "  {'pesq': 1.8675894737243652,\n",
       "   'stoi': np.float64(0.9656386854109148),\n",
       "   'time': 1586640300},\n",
       "  {'pesq': 1.5117024183273315,\n",
       "   'stoi': np.float64(0.9619034109303194),\n",
       "   'time': 1585437500},\n",
       "  {'pesq': 1.9751286506652832,\n",
       "   'stoi': np.float64(0.9213945315361625),\n",
       "   'time': 1583976500},\n",
       "  {'pesq': 1.241385817527771,\n",
       "   'stoi': np.float64(0.9093646224404317),\n",
       "   'time': 1582394800},\n",
       "  {'pesq': 1.2833528518676758,\n",
       "   'stoi': np.float64(0.7792539241456243),\n",
       "   'time': 1588099700},\n",
       "  {'pesq': 1.1974012851715088,\n",
       "   'stoi': np.float64(0.9114095967567637),\n",
       "   'time': 1583582300},\n",
       "  {'pesq': 1.6194097995758057,\n",
       "   'stoi': np.float64(0.9330766065335648),\n",
       "   'time': 1599995800},\n",
       "  {'pesq': 2.1400115489959717,\n",
       "   'stoi': np.float64(0.9447051178004057),\n",
       "   'time': 1586998100},\n",
       "  {'pesq': 1.921907663345337,\n",
       "   'stoi': np.float64(0.9667421394686865),\n",
       "   'time': 1579679700},\n",
       "  {'pesq': 1.3439990282058716,\n",
       "   'stoi': np.float64(0.8778552157096315),\n",
       "   'time': 1579290500},\n",
       "  {'pesq': 1.405392050743103,\n",
       "   'stoi': np.float64(0.9308244887443764),\n",
       "   'time': 1618181700},\n",
       "  {'pesq': 1.2355132102966309,\n",
       "   'stoi': np.float64(0.8894647356767738),\n",
       "   'time': 1584320500},\n",
       "  {'pesq': 1.801278829574585,\n",
       "   'stoi': np.float64(0.8227754099467728),\n",
       "   'time': 1590222900},\n",
       "  {'pesq': 2.400228500366211,\n",
       "   'stoi': np.float64(0.9298624815550196),\n",
       "   'time': 1650921600},\n",
       "  {'pesq': 1.5777783393859863,\n",
       "   'stoi': np.float64(0.7145893329491235),\n",
       "   'time': 1640018400},\n",
       "  {'pesq': 1.9188029766082764,\n",
       "   'stoi': np.float64(0.9538062266185167),\n",
       "   'time': 1667747400},\n",
       "  {'pesq': 1.7665388584136963,\n",
       "   'stoi': np.float64(0.949074362624331),\n",
       "   'time': 1711945700},\n",
       "  {'pesq': 2.5784285068511963,\n",
       "   'stoi': np.float64(0.9900541676828454),\n",
       "   'time': 1563187600},\n",
       "  {'pesq': 1.4533908367156982,\n",
       "   'stoi': np.float64(0.919880613852661),\n",
       "   'time': 1548715400},\n",
       "  {'pesq': 2.3318755626678467,\n",
       "   'stoi': np.float64(0.9693812689254727),\n",
       "   'time': 1537178100},\n",
       "  {'pesq': 2.180537223815918,\n",
       "   'stoi': np.float64(0.9552869610730718),\n",
       "   'time': 1553609800},\n",
       "  {'pesq': 1.282327651977539,\n",
       "   'stoi': np.float64(0.568647352094678),\n",
       "   'time': 1559600500},\n",
       "  {'pesq': 1.360804557800293,\n",
       "   'stoi': np.float64(0.8318879820817949),\n",
       "   'time': 1748086700},\n",
       "  {'pesq': 1.288947582244873,\n",
       "   'stoi': np.float64(0.8974341996219614),\n",
       "   'time': 1622052300},\n",
       "  {'pesq': 2.9212393760681152,\n",
       "   'stoi': np.float64(0.9898545414189845),\n",
       "   'time': 1680271600},\n",
       "  {'pesq': 1.2814159393310547,\n",
       "   'stoi': np.float64(0.844328838273125),\n",
       "   'time': 1638202400},\n",
       "  {'pesq': 1.197028398513794,\n",
       "   'stoi': np.float64(0.9085794757846287),\n",
       "   'time': 1647886000},\n",
       "  {'pesq': 1.0970216989517212,\n",
       "   'stoi': np.float64(0.523055023426679),\n",
       "   'time': 1626651400},\n",
       "  {'pesq': 1.8706971406936646,\n",
       "   'stoi': np.float64(0.9788997626692736),\n",
       "   'time': 1645045600},\n",
       "  {'pesq': 1.6682672500610352,\n",
       "   'stoi': np.float64(0.8938710679651111),\n",
       "   'time': 1617968200},\n",
       "  {'pesq': 1.1409296989440918,\n",
       "   'stoi': np.float64(0.5054019265740471),\n",
       "   'time': 1616143100},\n",
       "  {'pesq': 1.165785312652588,\n",
       "   'stoi': np.float64(0.8370185757504969),\n",
       "   'time': 1616838900},\n",
       "  {'pesq': 1.921621322631836,\n",
       "   'stoi': np.float64(0.953639753317478),\n",
       "   'time': 1606378300},\n",
       "  {'pesq': 2.049236297607422,\n",
       "   'stoi': np.float64(0.9578895052478565),\n",
       "   'time': 1608631100},\n",
       "  {'pesq': 2.3430776596069336,\n",
       "   'stoi': np.float64(0.9609231874814679),\n",
       "   'time': 1602508600},\n",
       "  {'pesq': 1.1091477870941162,\n",
       "   'stoi': np.float64(0.7726446416605092),\n",
       "   'time': 1586056700},\n",
       "  {'pesq': 1.4343268871307373,\n",
       "   'stoi': np.float64(0.7995576728791384),\n",
       "   'time': 1592055600},\n",
       "  {'pesq': 1.5947721004486084,\n",
       "   'stoi': np.float64(0.7583890450114809),\n",
       "   'time': 1594866600},\n",
       "  {'pesq': 2.288386106491089,\n",
       "   'stoi': np.float64(0.9766001930972018),\n",
       "   'time': 1583479600},\n",
       "  {'pesq': 1.132365107536316,\n",
       "   'stoi': np.float64(0.7748976340649331),\n",
       "   'time': 1591587600},\n",
       "  {'pesq': 2.112043857574463,\n",
       "   'stoi': np.float64(0.9545434662925842),\n",
       "   'time': 1586963000},\n",
       "  {'pesq': 1.9144620895385742,\n",
       "   'stoi': np.float64(0.9796318389410397),\n",
       "   'time': 1602021000},\n",
       "  {'pesq': 2.401498317718506,\n",
       "   'stoi': np.float64(0.9499752329598352),\n",
       "   'time': 1592682800},\n",
       "  {'pesq': 1.256400465965271,\n",
       "   'stoi': np.float64(0.8700066099703306),\n",
       "   'time': 1583809700},\n",
       "  {'pesq': 1.1676594018936157,\n",
       "   'stoi': np.float64(0.6282819722411762),\n",
       "   'time': 1586249600},\n",
       "  {'pesq': 1.097243309020996,\n",
       "   'stoi': np.float64(0.9149124394663568),\n",
       "   'time': 1586608300},\n",
       "  {'pesq': 1.0426088571548462,\n",
       "   'stoi': np.float64(0.5006269247037843),\n",
       "   'time': 1600864200},\n",
       "  {'pesq': 1.1807913780212402,\n",
       "   'stoi': np.float64(0.7944887551240688),\n",
       "   'time': 1601120100},\n",
       "  {'pesq': 1.3451677560806274,\n",
       "   'stoi': np.float64(0.9059864525732657),\n",
       "   'time': 1590645800},\n",
       "  {'pesq': 1.6605534553527832,\n",
       "   'stoi': np.float64(0.8336324658206374),\n",
       "   'time': 1595796400},\n",
       "  {'pesq': 1.1213560104370117,\n",
       "   'stoi': np.float64(0.8131462716411044),\n",
       "   'time': 1578508400},\n",
       "  {'pesq': 1.9407291412353516,\n",
       "   'stoi': np.float64(0.9531840488386558),\n",
       "   'time': 1588936100},\n",
       "  {'pesq': 1.591202735900879,\n",
       "   'stoi': np.float64(0.9183911141737441),\n",
       "   'time': 1591542200},\n",
       "  {'pesq': 1.9090347290039062,\n",
       "   'stoi': np.float64(0.9337031344711839),\n",
       "   'time': 1601225100},\n",
       "  {'pesq': 1.2987223863601685,\n",
       "   'stoi': np.float64(0.884939265984693),\n",
       "   'time': 1585486600},\n",
       "  {'pesq': 1.7422852516174316,\n",
       "   'stoi': np.float64(0.8728600549888629),\n",
       "   'time': 1580716100},\n",
       "  {'pesq': 1.2955551147460938,\n",
       "   'stoi': np.float64(0.9758468412273065),\n",
       "   'time': 1584375600},\n",
       "  {'pesq': 1.2468233108520508,\n",
       "   'stoi': np.float64(0.8406535287712122),\n",
       "   'time': 1601474900},\n",
       "  {'pesq': 1.6109139919281006,\n",
       "   'stoi': np.float64(0.9469855920054988),\n",
       "   'time': 1592293000},\n",
       "  {'pesq': 2.598963737487793,\n",
       "   'stoi': np.float64(0.9804558632411099),\n",
       "   'time': 1591034800},\n",
       "  {'pesq': 2.020615339279175,\n",
       "   'stoi': np.float64(0.9668735343488802),\n",
       "   'time': 1593756200},\n",
       "  {'pesq': 1.3754810094833374,\n",
       "   'stoi': np.float64(0.9359319154239328),\n",
       "   'time': 1582521700},\n",
       "  {'pesq': 1.2475370168685913,\n",
       "   'stoi': np.float64(0.8788788268286774),\n",
       "   'time': 1581406400},\n",
       "  {'pesq': 1.257636308670044,\n",
       "   'stoi': np.float64(0.8471329424028022),\n",
       "   'time': 1604130700},\n",
       "  {'pesq': 1.8892297744750977,\n",
       "   'stoi': np.float64(0.9529656297469787),\n",
       "   'time': 1581682600},\n",
       "  {'pesq': 1.9984354972839355,\n",
       "   'stoi': np.float64(0.9429612135301626),\n",
       "   'time': 1602896100},\n",
       "  {'pesq': 1.4030749797821045,\n",
       "   'stoi': np.float64(0.8609374678217587),\n",
       "   'time': 1591174000},\n",
       "  {'pesq': 1.268315076828003,\n",
       "   'stoi': np.float64(0.7986234177436823),\n",
       "   'time': 1597708700},\n",
       "  {'pesq': 1.7266716957092285,\n",
       "   'stoi': np.float64(0.6931196109371979),\n",
       "   'time': 1587930200},\n",
       "  {'pesq': 1.3695276975631714,\n",
       "   'stoi': np.float64(0.7121088772659191),\n",
       "   'time': 1591848100},\n",
       "  {'pesq': 1.8459515571594238,\n",
       "   'stoi': np.float64(0.974383113950771),\n",
       "   'time': 1587219800},\n",
       "  {'pesq': 1.652603030204773,\n",
       "   'stoi': np.float64(0.8475089170850683),\n",
       "   'time': 1593414800},\n",
       "  {'pesq': 1.1073925495147705,\n",
       "   'stoi': np.float64(0.7479866122728378),\n",
       "   'time': 1581336900},\n",
       "  {'pesq': 1.2412700653076172,\n",
       "   'stoi': np.float64(0.8832561259001436),\n",
       "   'time': 1592866300},\n",
       "  {'pesq': 1.2662441730499268,\n",
       "   'stoi': np.float64(0.78493135485186),\n",
       "   'time': 1587421500},\n",
       "  {'pesq': 2.4785077571868896,\n",
       "   'stoi': np.float64(0.9768086658135036),\n",
       "   'time': 1587129300},\n",
       "  {'pesq': 1.2063541412353516,\n",
       "   'stoi': np.float64(0.7842184879164447),\n",
       "   'time': 1582874600},\n",
       "  {'pesq': 1.6976191997528076,\n",
       "   'stoi': np.float64(0.5379143808218867),\n",
       "   'time': 1592931700},\n",
       "  {'pesq': 1.4326661825180054,\n",
       "   'stoi': np.float64(0.7181987281639783),\n",
       "   'time': 1594657100},\n",
       "  {'pesq': 1.6469776630401611,\n",
       "   'stoi': np.float64(0.8672215786595397),\n",
       "   'time': 1602214100},\n",
       "  {'pesq': 1.2069045305252075,\n",
       "   'stoi': np.float64(0.5568173664579861),\n",
       "   'time': 1586915500},\n",
       "  {'pesq': 2.8208394050598145,\n",
       "   'stoi': np.float64(0.9748026451768396),\n",
       "   'time': 1583938300},\n",
       "  {'pesq': 1.7405016422271729,\n",
       "   'stoi': np.float64(0.7638474339198071),\n",
       "   'time': 1589480300},\n",
       "  {'pesq': 2.0226356983184814,\n",
       "   'stoi': np.float64(0.8821488000955615),\n",
       "   'time': 1593979000},\n",
       "  {'pesq': 1.7540490627288818,\n",
       "   'stoi': np.float64(0.9330914947619754),\n",
       "   'time': 1578373500},\n",
       "  {'pesq': 1.6001312732696533,\n",
       "   'stoi': np.float64(0.9239102100479177),\n",
       "   'time': 1611344800},\n",
       "  {'pesq': 1.1315799951553345,\n",
       "   'stoi': np.float64(0.7832244374938748),\n",
       "   'time': 1581770700},\n",
       "  {'pesq': 1.0905789136886597,\n",
       "   'stoi': np.float64(0.6221795624246894),\n",
       "   'time': 1605883700},\n",
       "  {'pesq': 1.8062448501586914,\n",
       "   'stoi': np.float64(0.9563649804372442),\n",
       "   'time': 1594849700},\n",
       "  {'pesq': 1.2885072231292725,\n",
       "   'stoi': np.float64(0.9279602791456574),\n",
       "   'time': 1610225000},\n",
       "  {'pesq': 1.2708399295806885,\n",
       "   'stoi': np.float64(0.9117759436169117),\n",
       "   'time': 1605464200},\n",
       "  {'pesq': 1.268634557723999,\n",
       "   'stoi': np.float64(0.7644628428302487),\n",
       "   'time': 1591684600},\n",
       "  {'pesq': 1.5681369304656982,\n",
       "   'stoi': np.float64(0.8883057970936649),\n",
       "   'time': 1594652300},\n",
       "  {'pesq': 1.149598479270935,\n",
       "   'stoi': np.float64(0.8860895864469945),\n",
       "   'time': 1591157300},\n",
       "  {'pesq': 1.068415641784668,\n",
       "   'stoi': np.float64(0.7022745669854465),\n",
       "   'time': 1592616800},\n",
       "  {'pesq': 1.8544059991836548,\n",
       "   'stoi': np.float64(0.6093410786009585),\n",
       "   'time': 1604760600},\n",
       "  {'pesq': 1.1515036821365356,\n",
       "   'stoi': np.float64(0.7842345573815871),\n",
       "   'time': 1590204800},\n",
       "  {'pesq': 1.78834867477417,\n",
       "   'stoi': np.float64(0.9494306334265551),\n",
       "   'time': 1587367400},\n",
       "  {'pesq': 1.7496877908706665,\n",
       "   'stoi': np.float64(0.7320003304640672),\n",
       "   'time': 1578151800},\n",
       "  {'pesq': 1.1274375915527344,\n",
       "   'stoi': np.float64(0.6747852840720033),\n",
       "   'time': 1583916300},\n",
       "  {'pesq': 2.388468027114868,\n",
       "   'stoi': np.float64(0.9921825432748811),\n",
       "   'time': 1587410700},\n",
       "  {'pesq': 1.4123966693878174,\n",
       "   'stoi': np.float64(0.8068471533791856),\n",
       "   'time': 1595067900},\n",
       "  {'pesq': 1.5327210426330566,\n",
       "   'stoi': np.float64(0.8719752890225151),\n",
       "   'time': 1593136900},\n",
       "  {'pesq': 2.4069530963897705,\n",
       "   'stoi': np.float64(0.980829939662543),\n",
       "   'time': 1594124900},\n",
       "  {'pesq': 2.0741734504699707,\n",
       "   'stoi': np.float64(0.962913727779081),\n",
       "   'time': 1586553000},\n",
       "  {'pesq': 1.1407654285430908,\n",
       "   'stoi': np.float64(0.8135711991688853),\n",
       "   'time': 1593668100},\n",
       "  {'pesq': 1.7156134843826294,\n",
       "   'stoi': np.float64(0.8335231840988799),\n",
       "   'time': 1602149600},\n",
       "  {'pesq': 1.08864164352417,\n",
       "   'stoi': np.float64(0.7202913922538866),\n",
       "   'time': 1581281100},\n",
       "  {'pesq': 2.203934669494629,\n",
       "   'stoi': np.float64(0.971742629373331),\n",
       "   'time': 1597009700},\n",
       "  {'pesq': 2.0050480365753174,\n",
       "   'stoi': np.float64(0.9856168192811676),\n",
       "   'time': 1583171000},\n",
       "  {'pesq': 2.3780367374420166,\n",
       "   'stoi': np.float64(0.9619235754448919),\n",
       "   'time': 1585232600},\n",
       "  {'pesq': 2.0287511348724365,\n",
       "   'stoi': np.float64(0.9386684274129432),\n",
       "   'time': 1596922100},\n",
       "  {'pesq': 1.15106201171875,\n",
       "   'stoi': np.float64(0.7977643422845094),\n",
       "   'time': 1585258400},\n",
       "  {'pesq': 2.5742604732513428,\n",
       "   'stoi': np.float64(0.9861335152369671),\n",
       "   'time': 1579990600},\n",
       "  {'pesq': 1.573541522026062,\n",
       "   'stoi': np.float64(0.8857005365719953),\n",
       "   'time': 1595028300},\n",
       "  {'pesq': 1.5655972957611084,\n",
       "   'stoi': np.float64(0.49231395424946583),\n",
       "   'time': 1581121700},\n",
       "  {'pesq': 2.297325611114502,\n",
       "   'stoi': np.float64(0.9536284784917819),\n",
       "   'time': 1584317300},\n",
       "  {'pesq': 1.4126980304718018,\n",
       "   'stoi': np.float64(0.9018557260570651),\n",
       "   'time': 1597364300},\n",
       "  {'pesq': 1.7595698833465576,\n",
       "   'stoi': np.float64(0.9399504876427885),\n",
       "   'time': 1586418200},\n",
       "  {'pesq': 1.331331491470337,\n",
       "   'stoi': np.float64(0.8158322620843221),\n",
       "   'time': 1586414100},\n",
       "  {'pesq': 2.3361380100250244,\n",
       "   'stoi': np.float64(0.9719432031329732),\n",
       "   'time': 1589416800},\n",
       "  {'pesq': 1.284029483795166,\n",
       "   'stoi': np.float64(0.8396851730515572),\n",
       "   'time': 1615595100},\n",
       "  {'pesq': 1.8469595909118652,\n",
       "   'stoi': np.float64(0.7380610280751242),\n",
       "   'time': 1586812700},\n",
       "  {'pesq': 2.8784897327423096,\n",
       "   'stoi': np.float64(0.9937541069816214),\n",
       "   'time': 1591065500},\n",
       "  {'pesq': 1.4333045482635498,\n",
       "   'stoi': np.float64(0.8855211867099041),\n",
       "   'time': 1597696400},\n",
       "  {'pesq': 2.025306463241577,\n",
       "   'stoi': np.float64(0.9038430933872666),\n",
       "   'time': 1633206400},\n",
       "  {'pesq': 1.0386561155319214,\n",
       "   'stoi': np.float64(0.3031318719294467),\n",
       "   'time': 1611498500},\n",
       "  {'pesq': 2.0896964073181152,\n",
       "   'stoi': np.float64(0.9732899307952452),\n",
       "   'time': 1633112800},\n",
       "  {'pesq': 1.1131361722946167,\n",
       "   'stoi': np.float64(0.6581646757891536),\n",
       "   'time': 1603893700},\n",
       "  {'pesq': 1.2156282663345337,\n",
       "   'stoi': np.float64(0.7070099368981858),\n",
       "   'time': 1604070600},\n",
       "  {'pesq': 1.5671987533569336,\n",
       "   'stoi': np.float64(0.9356543821445442),\n",
       "   'time': 1606223500},\n",
       "  {'pesq': 1.0954996347427368,\n",
       "   'stoi': np.float64(0.6856987113429494),\n",
       "   'time': 1616999400},\n",
       "  {'pesq': 1.1898550987243652,\n",
       "   'stoi': np.float64(0.7529448222914039),\n",
       "   'time': 1701177600},\n",
       "  {'pesq': 2.3919522762298584,\n",
       "   'stoi': np.float64(0.9804827819306539),\n",
       "   'time': 1639146000},\n",
       "  {'pesq': 1.0640101432800293,\n",
       "   'stoi': np.float64(0.539356410729045),\n",
       "   'time': 1612008800},\n",
       "  {'pesq': 2.346646308898926,\n",
       "   'stoi': np.float64(0.9782240663606001),\n",
       "   'time': 1614052400},\n",
       "  {'pesq': 2.15567684173584,\n",
       "   'stoi': np.float64(0.9690070475743398),\n",
       "   'time': 1613671300},\n",
       "  {'pesq': 1.9492545127868652,\n",
       "   'stoi': np.float64(0.9753001953129807),\n",
       "   'time': 1630195000},\n",
       "  {'pesq': 1.4192824363708496,\n",
       "   'stoi': np.float64(0.8223527767993066),\n",
       "   'time': 1618107000},\n",
       "  {'pesq': 2.0956614017486572,\n",
       "   'stoi': np.float64(0.9334852968433746),\n",
       "   'time': 1611136000},\n",
       "  {'pesq': 1.3475477695465088,\n",
       "   'stoi': np.float64(0.9357761681696554),\n",
       "   'time': 1603251900},\n",
       "  {'pesq': 1.7256394624710083,\n",
       "   'stoi': np.float64(0.9488915032948132),\n",
       "   'time': 1602683600},\n",
       "  {'pesq': 2.657590866088867,\n",
       "   'stoi': np.float64(0.9838434793637133),\n",
       "   'time': 1619443000},\n",
       "  {'pesq': 1.712409496307373,\n",
       "   'stoi': np.float64(0.9387695296261556),\n",
       "   'time': 1642496600},\n",
       "  {'pesq': 1.486619234085083,\n",
       "   'stoi': np.float64(0.8774741151279405),\n",
       "   'time': 1601708300},\n",
       "  {'pesq': 1.109291911125183,\n",
       "   'stoi': np.float64(0.9267318324483174),\n",
       "   'time': 1606080900},\n",
       "  {'pesq': 1.1339317560195923,\n",
       "   'stoi': np.float64(0.8205567402887494),\n",
       "   'time': 1602675600},\n",
       "  {'pesq': 1.4898556470870972,\n",
       "   'stoi': np.float64(0.7977375686370984),\n",
       "   'time': 1601028800},\n",
       "  {'pesq': 2.041872024536133,\n",
       "   'stoi': np.float64(0.9653584970250182),\n",
       "   'time': 1608970500},\n",
       "  {'pesq': 1.3510799407958984,\n",
       "   'stoi': np.float64(0.9285329152403278),\n",
       "   'time': 1675001800},\n",
       "  {'pesq': 2.077855110168457,\n",
       "   'stoi': np.float64(0.9683201240534397),\n",
       "   'time': 1599926700},\n",
       "  {'pesq': 2.7730398178100586,\n",
       "   'stoi': np.float64(0.9742556900886182),\n",
       "   'time': 1598785200},\n",
       "  {'pesq': 1.7587647438049316,\n",
       "   'stoi': np.float64(0.7306427395221312),\n",
       "   'time': 1602317900},\n",
       "  {'pesq': 1.408145785331726,\n",
       "   'stoi': np.float64(0.8171279714705687),\n",
       "   'time': 1615545100},\n",
       "  {'pesq': 1.0873459577560425,\n",
       "   'stoi': np.float64(0.2202895352849738),\n",
       "   'time': 1597655600},\n",
       "  {'pesq': 1.3427201509475708,\n",
       "   'stoi': np.float64(0.5190263842135735),\n",
       "   'time': 1616050100},\n",
       "  {'pesq': 1.3376613855361938,\n",
       "   'stoi': np.float64(0.8803439863082775),\n",
       "   'time': 1604156000},\n",
       "  {'pesq': 1.5069818496704102,\n",
       "   'stoi': np.float64(0.9446902126815573),\n",
       "   'time': 1615171200},\n",
       "  {'pesq': 2.0759313106536865,\n",
       "   'stoi': np.float64(0.9886358331859533),\n",
       "   'time': 1607418000},\n",
       "  {'pesq': 1.2064827680587769,\n",
       "   'stoi': np.float64(0.8370262739891069),\n",
       "   'time': 1604688600},\n",
       "  {'pesq': 2.6875789165496826,\n",
       "   'stoi': np.float64(0.96381366890099),\n",
       "   'time': 1607575200},\n",
       "  {'pesq': 1.1654574871063232,\n",
       "   'stoi': np.float64(0.7885212091115325),\n",
       "   'time': 1635653900},\n",
       "  {'pesq': 1.4047844409942627,\n",
       "   'stoi': np.float64(0.853917017256747),\n",
       "   'time': 1655506600},\n",
       "  {'pesq': 1.2254741191864014,\n",
       "   'stoi': np.float64(0.7422997491283317),\n",
       "   'time': 1653504900},\n",
       "  {'pesq': 1.1733622550964355,\n",
       "   'stoi': np.float64(0.7941688737518006),\n",
       "   'time': 1627711700},\n",
       "  {'pesq': 1.9355435371398926,\n",
       "   'stoi': np.float64(0.9321046862276781),\n",
       "   'time': 1670859500},\n",
       "  {'pesq': 1.0899951457977295,\n",
       "   'stoi': np.float64(0.4073203963568454),\n",
       "   'time': 1641864300},\n",
       "  {'pesq': 1.1750551462173462,\n",
       "   'stoi': np.float64(0.648302050275576),\n",
       "   'time': 1623252400},\n",
       "  {'pesq': 1.7271496057510376,\n",
       "   'stoi': np.float64(0.887709664992824),\n",
       "   'time': 1606439800},\n",
       "  {'pesq': 1.8599953651428223,\n",
       "   'stoi': np.float64(0.9708982989916064),\n",
       "   'time': 1642120600},\n",
       "  {'pesq': 2.8540735244750977,\n",
       "   'stoi': np.float64(0.9739681114522591),\n",
       "   'time': 1660513400},\n",
       "  {'pesq': 1.7233457565307617,\n",
       "   'stoi': np.float64(0.9496941673683794),\n",
       "   'time': 1617289000},\n",
       "  {'pesq': 1.1649682521820068,\n",
       "   'stoi': np.float64(0.6770701913059086),\n",
       "   'time': 1653049100},\n",
       "  {'pesq': 1.036152720451355,\n",
       "   'stoi': np.float64(0.437057761581231),\n",
       "   'time': 1635381400},\n",
       "  {'pesq': 2.167257308959961,\n",
       "   'stoi': np.float64(0.9618030926582111),\n",
       "   'time': 1657309600},\n",
       "  {'pesq': 1.9454729557037354,\n",
       "   'stoi': np.float64(0.9342429827040487),\n",
       "   'time': 1617455300},\n",
       "  {'pesq': 1.3686141967773438,\n",
       "   'stoi': np.float64(0.7903746081382962),\n",
       "   'time': 1669560800},\n",
       "  {'pesq': 1.6290993690490723,\n",
       "   'stoi': np.float64(0.9499588351678158),\n",
       "   'time': 1641874000},\n",
       "  {'pesq': 1.5570601224899292,\n",
       "   'stoi': np.float64(0.8909551592345603),\n",
       "   'time': 1627899100},\n",
       "  {'pesq': 1.8721942901611328,\n",
       "   'stoi': np.float64(0.9261088262531122),\n",
       "   'time': 1604305900},\n",
       "  {'pesq': 1.178505301475525,\n",
       "   'stoi': np.float64(0.7425542531923729),\n",
       "   'time': 1620695800},\n",
       "  {'pesq': 2.044119358062744,\n",
       "   'stoi': np.float64(0.9814467451234116),\n",
       "   'time': 1642067600},\n",
       "  {'pesq': 1.792285680770874,\n",
       "   'stoi': np.float64(0.6756403983308501),\n",
       "   'time': 1651130900},\n",
       "  {'pesq': 1.854109525680542,\n",
       "   'stoi': np.float64(0.938731754408574),\n",
       "   'time': 1665925100},\n",
       "  {'pesq': 1.4831913709640503,\n",
       "   'stoi': np.float64(0.9149165352763421),\n",
       "   'time': 1634170100},\n",
       "  {'pesq': 1.1239454746246338,\n",
       "   'stoi': np.float64(0.6916302414415304),\n",
       "   'time': 1613033900},\n",
       "  {'pesq': 1.1815418004989624,\n",
       "   'stoi': np.float64(0.7352953497309334),\n",
       "   'time': 1625337300},\n",
       "  {'pesq': 1.1723827123641968,\n",
       "   'stoi': np.float64(0.7812160537245871),\n",
       "   'time': 1655185300},\n",
       "  {'pesq': 2.034353494644165,\n",
       "   'stoi': np.float64(0.932152999470423),\n",
       "   'time': 1644767900},\n",
       "  {'pesq': 1.3311957120895386,\n",
       "   'stoi': np.float64(0.6625215517131069),\n",
       "   'time': 1600694800},\n",
       "  {'pesq': 1.374426007270813,\n",
       "   'stoi': np.float64(0.8737180466898173),\n",
       "   'time': 1607938000},\n",
       "  {'pesq': 1.4040849208831787,\n",
       "   'stoi': np.float64(0.5003354174701301),\n",
       "   'time': 1585319900},\n",
       "  {'pesq': 1.4967840909957886,\n",
       "   'stoi': np.float64(0.9129600318857549),\n",
       "   'time': 1615810900},\n",
       "  {'pesq': 2.3361949920654297,\n",
       "   'stoi': np.float64(0.546814791754252),\n",
       "   'time': 1602991000},\n",
       "  {'pesq': 1.1937953233718872,\n",
       "   'stoi': np.float64(0.7776399938382009),\n",
       "   'time': 1603823800},\n",
       "  {'pesq': 2.2373111248016357,\n",
       "   'stoi': np.float64(0.9699234340372597),\n",
       "   'time': 1592912000},\n",
       "  {'pesq': 2.3338258266448975, 'stoi': 1e-05, 'time': 1593747300},\n",
       "  {'pesq': 1.952412486076355,\n",
       "   'stoi': np.float64(0.9723582201063287),\n",
       "   'time': 1598403200},\n",
       "  {'pesq': 2.008669137954712,\n",
       "   'stoi': np.float64(0.9557757113156014),\n",
       "   'time': 1613171800},\n",
       "  {'pesq': 1.5310426950454712,\n",
       "   'stoi': np.float64(0.8956586034136398),\n",
       "   'time': 1616642600},\n",
       "  {'pesq': 1.0664581060409546,\n",
       "   'stoi': np.float64(0.54809306806067),\n",
       "   'time': 1601731900},\n",
       "  {'pesq': 2.2362020015716553,\n",
       "   'stoi': np.float64(0.9590970733876231),\n",
       "   'time': 1597005000},\n",
       "  {'pesq': 1.8647547960281372,\n",
       "   'stoi': np.float64(0.9656246821127957),\n",
       "   'time': 1597709800},\n",
       "  {'pesq': 1.306921362876892,\n",
       "   'stoi': np.float64(0.893885674775844),\n",
       "   'time': 1580787900},\n",
       "  {'pesq': 1.4594188928604126,\n",
       "   'stoi': np.float64(0.904359013846026),\n",
       "   'time': 1599536300},\n",
       "  {'pesq': 1.4009255170822144,\n",
       "   'stoi': np.float64(0.8133091272091297),\n",
       "   'time': 1646554100},\n",
       "  {'pesq': 1.1932413578033447,\n",
       "   'stoi': np.float64(0.8590200721693456),\n",
       "   'time': 1596559900},\n",
       "  {'pesq': 1.0607130527496338,\n",
       "   'stoi': np.float64(0.5385482119452598),\n",
       "   'time': 1591512800},\n",
       "  {'pesq': 1.5979702472686768,\n",
       "   'stoi': np.float64(0.9015718579188197),\n",
       "   'time': 1602060500},\n",
       "  {'pesq': 1.4286420345306396,\n",
       "   'stoi': np.float64(0.858412014166982),\n",
       "   'time': 1637182300},\n",
       "  {'pesq': 2.4039783477783203,\n",
       "   'stoi': np.float64(0.9617342096215726),\n",
       "   'time': 1615537200},\n",
       "  {'pesq': 1.140250325202942,\n",
       "   'stoi': np.float64(0.7517897705095796),\n",
       "   'time': 1661218000},\n",
       "  {'pesq': 1.1798635721206665,\n",
       "   'stoi': np.float64(0.8243163506595871),\n",
       "   'time': 1630004000},\n",
       "  {'pesq': 1.3305796384811401,\n",
       "   'stoi': np.float64(0.8165623656537973),\n",
       "   'time': 1646113700},\n",
       "  {'pesq': 1.4993176460266113,\n",
       "   'stoi': np.float64(0.7383421509806043),\n",
       "   'time': 1597490100},\n",
       "  {'pesq': 1.3168617486953735,\n",
       "   'stoi': np.float64(0.9211151827561758),\n",
       "   'time': 1602672500},\n",
       "  {'pesq': 1.708942174911499,\n",
       "   'stoi': np.float64(0.9530561758949139),\n",
       "   'time': 1679745900},\n",
       "  {'pesq': 2.098341464996338,\n",
       "   'stoi': np.float64(0.9253446411664725),\n",
       "   'time': 1657672600},\n",
       "  {'pesq': 1.1028730869293213,\n",
       "   'stoi': np.float64(0.8343344957669978),\n",
       "   'time': 1657901100},\n",
       "  {'pesq': 1.256401777267456,\n",
       "   'stoi': np.float64(0.7835566673607599),\n",
       "   'time': 1608159900},\n",
       "  {'pesq': 1.5350232124328613,\n",
       "   'stoi': np.float64(0.886298366000627),\n",
       "   'time': 1639936600},\n",
       "  {'pesq': 1.2846044301986694,\n",
       "   'stoi': np.float64(0.8158927480182214),\n",
       "   'time': 1664931700},\n",
       "  {'pesq': 1.1593772172927856,\n",
       "   'stoi': np.float64(0.758477561922113),\n",
       "   'time': 1659026700},\n",
       "  {'pesq': 1.4642808437347412,\n",
       "   'stoi': np.float64(0.8603175451772738),\n",
       "   'time': 1646605600},\n",
       "  {'pesq': 1.1791596412658691,\n",
       "   'stoi': np.float64(0.7059196705552699),\n",
       "   'time': 1602202100},\n",
       "  {'pesq': 1.4718923568725586,\n",
       "   'stoi': np.float64(0.9169957388706791),\n",
       "   'time': 1646627100},\n",
       "  {'pesq': 1.844794511795044,\n",
       "   'stoi': np.float64(0.9559119840667084),\n",
       "   'time': 1665568000},\n",
       "  {'pesq': 2.397550582885742,\n",
       "   'stoi': np.float64(0.9695595849991224),\n",
       "   'time': 1612416900},\n",
       "  {'pesq': 1.0553805828094482,\n",
       "   'stoi': np.float64(0.5521318325609212),\n",
       "   'time': 1598271700},\n",
       "  {'pesq': 1.83280348777771,\n",
       "   'stoi': np.float64(0.9581087497515333),\n",
       "   'time': 1672508900},\n",
       "  {'pesq': 1.2255476713180542,\n",
       "   'stoi': np.float64(0.5705537281557904),\n",
       "   'time': 1700917700},\n",
       "  {'pesq': 1.7881628274917603,\n",
       "   'stoi': np.float64(0.9420062990955609),\n",
       "   'time': 1783539100},\n",
       "  {'pesq': 1.6402779817581177,\n",
       "   'stoi': np.float64(0.8129788497739858),\n",
       "   'time': 1700622000},\n",
       "  {'pesq': 1.4816354513168335,\n",
       "   'stoi': np.float64(0.939016155720912),\n",
       "   'time': 1619490000},\n",
       "  {'pesq': 1.5494002103805542,\n",
       "   'stoi': np.float64(0.9113162566225567),\n",
       "   'time': 1581480000},\n",
       "  {'pesq': 1.5017704963684082,\n",
       "   'stoi': np.float64(0.9056363654086824),\n",
       "   'time': 1595985800},\n",
       "  {'pesq': 1.5075907707214355,\n",
       "   'stoi': np.float64(0.9313783988166542),\n",
       "   'time': 1681240700},\n",
       "  {'pesq': 1.368331789970398,\n",
       "   'stoi': np.float64(0.8209037198812895),\n",
       "   'time': 1568807900},\n",
       "  {'pesq': 1.230600357055664,\n",
       "   'stoi': np.float64(0.7009335432472465),\n",
       "   'time': 1620228700},\n",
       "  {'pesq': 2.5463593006134033,\n",
       "   'stoi': np.float64(0.9827127664915138),\n",
       "   'time': 1568216100},\n",
       "  {'pesq': 1.2841140031814575,\n",
       "   'stoi': np.float64(0.8369983093366931),\n",
       "   'time': 1614751900},\n",
       "  {'pesq': 2.286158561706543,\n",
       "   'stoi': np.float64(0.9915158064175296),\n",
       "   'time': 1631250500},\n",
       "  {'pesq': 1.3632638454437256,\n",
       "   'stoi': np.float64(0.5164535573165935),\n",
       "   'time': 1679268800},\n",
       "  {'pesq': 1.2832973003387451,\n",
       "   'stoi': np.float64(0.6410461062029088),\n",
       "   'time': 1615267300},\n",
       "  {'pesq': 1.512970209121704,\n",
       "   'stoi': np.float64(0.9720143070964796),\n",
       "   'time': 1612689800},\n",
       "  {'pesq': 2.134394645690918,\n",
       "   'stoi': np.float64(0.8749560103103246),\n",
       "   'time': 1599282000},\n",
       "  {'pesq': 1.9636738300323486,\n",
       "   'stoi': np.float64(0.9304768935957668),\n",
       "   'time': 1607627400},\n",
       "  {'pesq': 1.1600253582000732,\n",
       "   'stoi': np.float64(0.8574050009870288),\n",
       "   'time': 1678246200},\n",
       "  {'pesq': 2.175835609436035,\n",
       "   'stoi': np.float64(0.9666352022009121),\n",
       "   'time': 1600862300},\n",
       "  {'pesq': 1.593024492263794,\n",
       "   'stoi': np.float64(0.9760533780336138),\n",
       "   'time': 1585741100},\n",
       "  {'pesq': 1.569244146347046,\n",
       "   'stoi': np.float64(0.8920568083084649),\n",
       "   'time': 1584188400},\n",
       "  {'pesq': 1.2301517724990845,\n",
       "   'stoi': np.float64(0.8845799135841931),\n",
       "   'time': 1589333900},\n",
       "  {'pesq': 1.0903977155685425,\n",
       "   'stoi': np.float64(0.3393096179640621),\n",
       "   'time': 1601328700},\n",
       "  {'pesq': 3.14460825920105,\n",
       "   'stoi': np.float64(0.9816815942592889),\n",
       "   'time': 1676839600},\n",
       "  {'pesq': 2.385763168334961,\n",
       "   'stoi': np.float64(0.9458863111285493),\n",
       "   'time': 1651483500},\n",
       "  {'pesq': 2.3151488304138184,\n",
       "   'stoi': np.float64(0.9648184619518179),\n",
       "   'time': 1649754400},\n",
       "  {'pesq': 2.315138816833496,\n",
       "   'stoi': np.float64(0.9705436508059582),\n",
       "   'time': 1664504500},\n",
       "  {'pesq': 1.1903256177902222,\n",
       "   'stoi': np.float64(0.8609991365977306),\n",
       "   'time': 1629140400},\n",
       "  {'pesq': 1.5275695323944092,\n",
       "   'stoi': np.float64(0.9353119433316093),\n",
       "   'time': 1676345400},\n",
       "  {'pesq': 2.576098680496216,\n",
       "   'stoi': np.float64(0.9860815656637486),\n",
       "   'time': 1652618600},\n",
       "  {'pesq': 1.2222402095794678,\n",
       "   'stoi': np.float64(0.819740082015616),\n",
       "   'time': 1644683100},\n",
       "  {'pesq': 1.169573426246643,\n",
       "   'stoi': np.float64(0.6769240884382297),\n",
       "   'time': 1636901200},\n",
       "  {'pesq': 2.294193983078003,\n",
       "   'stoi': np.float64(0.9513073244991899),\n",
       "   'time': 1603641400},\n",
       "  {'pesq': 2.0045158863067627,\n",
       "   'stoi': np.float64(0.9643861464980847),\n",
       "   'time': 1608809100},\n",
       "  {'pesq': 1.620395541191101,\n",
       "   'stoi': np.float64(0.9150611386727523),\n",
       "   'time': 1607004300},\n",
       "  {'pesq': 1.7515790462493896,\n",
       "   'stoi': np.float64(0.9247389703464891),\n",
       "   'time': 1592837200},\n",
       "  {'pesq': 1.055200219154358,\n",
       "   'stoi': np.float64(0.33920101457031515),\n",
       "   'time': 1600371900},\n",
       "  {'pesq': 1.2759053707122803,\n",
       "   'stoi': np.float64(0.9179668514869831),\n",
       "   'time': 1672379400},\n",
       "  {'pesq': 1.0540074110031128,\n",
       "   'stoi': np.float64(0.6308709877042725),\n",
       "   'time': 1669710300},\n",
       "  {'pesq': 1.5867478847503662,\n",
       "   'stoi': np.float64(0.8788565626174019),\n",
       "   'time': 1612542900},\n",
       "  {'pesq': 2.3551928997039795,\n",
       "   'stoi': np.float64(0.9310792665010187),\n",
       "   'time': 1609189000},\n",
       "  {'pesq': 2.0212435722351074,\n",
       "   'stoi': np.float64(0.9610727704223551),\n",
       "   'time': 1618261700},\n",
       "  {'pesq': 2.0829520225524902,\n",
       "   'stoi': np.float64(0.9590500411367735),\n",
       "   'time': 1656005300},\n",
       "  {'pesq': 1.1755142211914062,\n",
       "   'stoi': np.float64(0.794975342421906),\n",
       "   'time': 1633537300},\n",
       "  {'pesq': 1.1755696535110474,\n",
       "   'stoi': np.float64(0.8923961992549841),\n",
       "   'time': 1656751000},\n",
       "  {'pesq': 1.3338453769683838,\n",
       "   'stoi': np.float64(0.8015574797922308),\n",
       "   'time': 1660802600},\n",
       "  {'pesq': 1.9096605777740479,\n",
       "   'stoi': np.float64(0.9353805780190781),\n",
       "   'time': 1636435800},\n",
       "  {'pesq': 1.2432136535644531,\n",
       "   'stoi': np.float64(0.8635942393650688),\n",
       "   'time': 1650706000},\n",
       "  {'pesq': 1.3855291604995728,\n",
       "   'stoi': np.float64(0.8793662841319361),\n",
       "   'time': 1599069000},\n",
       "  {'pesq': 1.732393741607666,\n",
       "   'stoi': np.float64(0.8889460715316367),\n",
       "   'time': 1600983300},\n",
       "  {'pesq': 2.525479793548584,\n",
       "   'stoi': np.float64(0.8265102545151897),\n",
       "   'time': 1590541900},\n",
       "  {'pesq': 2.7898459434509277,\n",
       "   'stoi': np.float64(0.9790525459807171),\n",
       "   'time': 1591555400},\n",
       "  {'pesq': 1.6899609565734863,\n",
       "   'stoi': np.float64(0.8738602035550741),\n",
       "   'time': 1648298500},\n",
       "  {'pesq': 1.0748412609100342,\n",
       "   'stoi': np.float64(0.7416093763693851),\n",
       "   'time': 1606515400},\n",
       "  {'pesq': 1.530407190322876,\n",
       "   'stoi': np.float64(0.9437792759624091),\n",
       "   'time': 1589363000},\n",
       "  {'pesq': 1.462035894393921,\n",
       "   'stoi': np.float64(0.9583178196984692),\n",
       "   'time': 1582658800},\n",
       "  {'pesq': 1.1100480556488037,\n",
       "   'stoi': np.float64(0.5821830705718128),\n",
       "   'time': 1590231500},\n",
       "  {'pesq': 1.5823397636413574,\n",
       "   'stoi': np.float64(0.8631478383953077),\n",
       "   'time': 1585108100},\n",
       "  {'pesq': 2.140704870223999,\n",
       "   'stoi': np.float64(0.928995188240104),\n",
       "   'time': 1589091700},\n",
       "  {'pesq': 1.877013921737671,\n",
       "   'stoi': np.float64(0.9487792106315825),\n",
       "   'time': 1604302600},\n",
       "  {'pesq': 1.0292634963989258,\n",
       "   'stoi': np.float64(0.4611403462931339),\n",
       "   'time': 1586058300},\n",
       "  {'pesq': 1.7223596572875977,\n",
       "   'stoi': np.float64(0.9560678936083589),\n",
       "   'time': 1609691600},\n",
       "  {'pesq': 2.468315601348877,\n",
       "   'stoi': np.float64(0.969319157740097),\n",
       "   'time': 1607947100},\n",
       "  {'pesq': 2.2923645973205566,\n",
       "   'stoi': np.float64(0.9341826532959364),\n",
       "   'time': 1666047200},\n",
       "  {'pesq': 1.7678241729736328,\n",
       "   'stoi': np.float64(0.9446545249690115),\n",
       "   'time': 1581400100},\n",
       "  {'pesq': 1.1977766752243042,\n",
       "   'stoi': np.float64(0.8492289344901842),\n",
       "   'time': 1590196700},\n",
       "  {'pesq': 1.175502061843872,\n",
       "   'stoi': np.float64(0.8092609790116104),\n",
       "   'time': 1614471700},\n",
       "  {'pesq': 1.1839814186096191,\n",
       "   'stoi': np.float64(0.6729895471202085),\n",
       "   'time': 1625802700},\n",
       "  {'pesq': 1.6535382270812988,\n",
       "   'stoi': np.float64(0.9154849107995464),\n",
       "   'time': 1600307500},\n",
       "  {'pesq': 1.8395190238952637,\n",
       "   'stoi': np.float64(0.9554656326513462),\n",
       "   'time': 1591291600},\n",
       "  {'pesq': 1.1125681400299072,\n",
       "   'stoi': np.float64(0.6765006353885228),\n",
       "   'time': 1576740400},\n",
       "  {'pesq': 2.575784921646118,\n",
       "   'stoi': np.float64(0.9587037552927391),\n",
       "   'time': 1588349000},\n",
       "  {'pesq': 1.2860779762268066,\n",
       "   'stoi': np.float64(0.9443257458766194),\n",
       "   'time': 1583529000},\n",
       "  {'pesq': 1.17365300655365,\n",
       "   'stoi': np.float64(0.8273171783093257),\n",
       "   'time': 1586121000},\n",
       "  {'pesq': 1.8768903017044067,\n",
       "   'stoi': np.float64(0.8835317200341887),\n",
       "   'time': 1578191100},\n",
       "  {'pesq': 2.818187952041626,\n",
       "   'stoi': np.float64(0.9810820200973438),\n",
       "   'time': 1594512900},\n",
       "  {'pesq': 1.1485283374786377,\n",
       "   'stoi': np.float64(0.769357909100129),\n",
       "   'time': 1578094200},\n",
       "  {'pesq': 1.8091909885406494,\n",
       "   'stoi': np.float64(0.9488433010795634),\n",
       "   'time': 1581442800},\n",
       "  {'pesq': 1.3792004585266113,\n",
       "   'stoi': np.float64(0.870730382798951),\n",
       "   'time': 1604494800},\n",
       "  {'pesq': 1.7929046154022217,\n",
       "   'stoi': np.float64(0.962745549448404),\n",
       "   'time': 1594696200},\n",
       "  {'pesq': 2.6292483806610107,\n",
       "   'stoi': np.float64(0.9620192276277307),\n",
       "   'time': 1587255600},\n",
       "  {'pesq': 1.2689464092254639,\n",
       "   'stoi': np.float64(0.7385716189853768),\n",
       "   'time': 1584795000},\n",
       "  {'pesq': 3.623934507369995,\n",
       "   'stoi': np.float64(0.9970626432605514),\n",
       "   'time': 1578201500},\n",
       "  {'pesq': 1.7325447797775269,\n",
       "   'stoi': np.float64(0.9396569333910366),\n",
       "   'time': 1583859200},\n",
       "  {'pesq': 1.5842009782791138,\n",
       "   'stoi': np.float64(0.9135940203886578),\n",
       "   'time': 1588649700},\n",
       "  {'pesq': 1.059183955192566,\n",
       "   'stoi': np.float64(0.49438831292650054),\n",
       "   'time': 1600502300},\n",
       "  {'pesq': 2.170013904571533,\n",
       "   'stoi': np.float64(0.9339693691424023),\n",
       "   'time': 1598719700},\n",
       "  {'pesq': 1.7868070602416992,\n",
       "   'stoi': np.float64(0.9714229485754634),\n",
       "   'time': 1580036500},\n",
       "  {'pesq': 1.7315900325775146,\n",
       "   'stoi': np.float64(0.8905113062758003),\n",
       "   'time': 1579385700},\n",
       "  {'pesq': 1.1541376113891602,\n",
       "   'stoi': np.float64(0.8236990621877549),\n",
       "   'time': 1585020800},\n",
       "  {'pesq': 1.5610387325286865,\n",
       "   'stoi': np.float64(0.9006555193141397),\n",
       "   'time': 1596700000},\n",
       "  {'pesq': 1.872624158859253,\n",
       "   'stoi': np.float64(0.9657989268675001),\n",
       "   'time': 1589653800},\n",
       "  {'pesq': 2.054657459259033,\n",
       "   'stoi': np.float64(0.9610897546112327),\n",
       "   'time': 1583262600},\n",
       "  {'pesq': 1.8682830333709717,\n",
       "   'stoi': np.float64(0.9546396738251753),\n",
       "   'time': 1581499800},\n",
       "  {'pesq': 1.0646716356277466,\n",
       "   'stoi': np.float64(0.6732298587781973),\n",
       "   'time': 1584441200},\n",
       "  {'pesq': 1.8947256803512573,\n",
       "   'stoi': np.float64(0.9799939285248631),\n",
       "   'time': 1600707900},\n",
       "  {'pesq': 1.5268296003341675,\n",
       "   'stoi': np.float64(0.8752399146937733),\n",
       "   'time': 1595957600},\n",
       "  {'pesq': 1.1287055015563965,\n",
       "   'stoi': np.float64(0.7490033214021112),\n",
       "   'time': 1584969300},\n",
       "  {'pesq': 2.7047221660614014,\n",
       "   'stoi': np.float64(0.943018611130921),\n",
       "   'time': 1577634800},\n",
       "  {'pesq': 1.7601131200790405,\n",
       "   'stoi': np.float64(0.9372243388138193),\n",
       "   'time': 1580284900},\n",
       "  {'pesq': 1.134577751159668,\n",
       "   'stoi': np.float64(0.7151596091076315),\n",
       "   'time': 1578376500},\n",
       "  {'pesq': 1.6770167350769043,\n",
       "   'stoi': np.float64(0.7568848258756743),\n",
       "   'time': 1593421700},\n",
       "  {'pesq': 2.1701059341430664,\n",
       "   'stoi': np.float64(0.9375193334606797),\n",
       "   'time': 1589354300},\n",
       "  {'pesq': 1.7799255847930908,\n",
       "   'stoi': np.float64(0.8953498868228226),\n",
       "   'time': 1615480500},\n",
       "  {'pesq': 1.1981788873672485,\n",
       "   'stoi': np.float64(0.9375571425387929),\n",
       "   'time': 1584339000},\n",
       "  {'pesq': 2.3613030910491943,\n",
       "   'stoi': np.float64(0.9371250267626975),\n",
       "   'time': 1583263800},\n",
       "  {'pesq': 1.2773605585098267,\n",
       "   'stoi': np.float64(0.7948223584239335),\n",
       "   'time': 1587802500},\n",
       "  {'pesq': 2.3274221420288086,\n",
       "   'stoi': np.float64(0.8960847711359943),\n",
       "   'time': 1604276700},\n",
       "  {'pesq': 1.253456473350525,\n",
       "   'stoi': np.float64(0.6785806212374546),\n",
       "   'time': 1588295300},\n",
       "  {'pesq': 1.6359479427337646,\n",
       "   'stoi': np.float64(0.9174304790092721),\n",
       "   'time': 1593690100},\n",
       "  {'pesq': 2.989863395690918,\n",
       "   'stoi': np.float64(0.9597897305566182),\n",
       "   'time': 1585676900},\n",
       "  {'pesq': 2.7353146076202393,\n",
       "   'stoi': np.float64(0.9524117384445457),\n",
       "   'time': 1595895200},\n",
       "  {'pesq': 2.4775116443634033,\n",
       "   'stoi': np.float64(0.9621687832113105),\n",
       "   'time': 1591232800},\n",
       "  {'pesq': 2.465094804763794,\n",
       "   'stoi': np.float64(0.9656892426065691),\n",
       "   'time': 1584006200},\n",
       "  {'pesq': 1.2512562274932861,\n",
       "   'stoi': np.float64(0.6329322386388943),\n",
       "   'time': 1590105200},\n",
       "  {'pesq': 1.2645461559295654,\n",
       "   'stoi': np.float64(0.6808239191773273),\n",
       "   'time': 1598120900},\n",
       "  {'pesq': 1.8475850820541382,\n",
       "   'stoi': np.float64(0.9341343740666097),\n",
       "   'time': 1590609100},\n",
       "  {'pesq': 1.591923713684082,\n",
       "   'stoi': np.float64(0.9058770988634913),\n",
       "   'time': 1595711000},\n",
       "  {'pesq': 1.1039677858352661,\n",
       "   'stoi': np.float64(0.7463162614732198),\n",
       "   'time': 1586353400},\n",
       "  {'pesq': 1.2470335960388184,\n",
       "   'stoi': np.float64(0.8568679144700729),\n",
       "   'time': 1600706500},\n",
       "  {'pesq': 1.059985637664795,\n",
       "   'stoi': np.float64(0.77960943934596),\n",
       "   'time': 1602937800},\n",
       "  {'pesq': 1.3559038639068604,\n",
       "   'stoi': np.float64(0.7811945255413076),\n",
       "   'time': 1606896500},\n",
       "  {'pesq': 2.1030592918395996,\n",
       "   'stoi': np.float64(0.8922479567442053),\n",
       "   'time': 1576844600},\n",
       "  {'pesq': 2.324002504348755,\n",
       "   'stoi': np.float64(0.925899338916468),\n",
       "   'time': 1595410000},\n",
       "  {'pesq': 1.7162413597106934,\n",
       "   'stoi': np.float64(0.9785242126006163),\n",
       "   'time': 1587230900},\n",
       "  {'pesq': 2.389538288116455,\n",
       "   'stoi': np.float64(0.9551647917833634),\n",
       "   'time': 1585664300},\n",
       "  {'pesq': 1.5096991062164307,\n",
       "   'stoi': np.float64(0.8494196223424346),\n",
       "   'time': 1588224700},\n",
       "  {'pesq': 1.093174695968628,\n",
       "   'stoi': np.float64(0.7486111650137907),\n",
       "   'time': 1609284700},\n",
       "  {'pesq': 2.575059413909912,\n",
       "   'stoi': np.float64(0.9327782330467718),\n",
       "   'time': 1589643400},\n",
       "  {'pesq': 1.0668658018112183,\n",
       "   'stoi': np.float64(0.637322214998821),\n",
       "   'time': 1592647300},\n",
       "  {'pesq': 1.5863111019134521,\n",
       "   'stoi': np.float64(0.9519443279080809),\n",
       "   'time': 1586688100},\n",
       "  {'pesq': 1.283916711807251,\n",
       "   'stoi': np.float64(0.8396843250776183),\n",
       "   'time': 1587221600},\n",
       "  {'pesq': 1.8563508987426758,\n",
       "   'stoi': np.float64(0.9585144488070969),\n",
       "   'time': 1596580500},\n",
       "  {'pesq': 1.6171209812164307,\n",
       "   'stoi': np.float64(0.8910594296917086),\n",
       "   'time': 1602686800},\n",
       "  {'pesq': 1.3620308637619019,\n",
       "   'stoi': np.float64(0.8832320779669773),\n",
       "   'time': 1661204200},\n",
       "  {'pesq': 2.2007951736450195,\n",
       "   'stoi': np.float64(0.9924290285438904),\n",
       "   'time': 1640919500},\n",
       "  {'pesq': 1.9670910835266113,\n",
       "   'stoi': np.float64(0.9363805200029783),\n",
       "   'time': 1623685800},\n",
       "  {'pesq': 1.657758116722107,\n",
       "   'stoi': np.float64(0.6250477121635403),\n",
       "   'time': 1615760700},\n",
       "  {'pesq': 1.065541386604309,\n",
       "   'stoi': np.float64(0.6334330636777279),\n",
       "   'time': 1622989400},\n",
       "  {'pesq': 1.2489066123962402,\n",
       "   'stoi': np.float64(0.7327353341221982),\n",
       "   'time': 1650880100},\n",
       "  {'pesq': 1.343868374824524,\n",
       "   'stoi': np.float64(0.8094831424004131),\n",
       "   'time': 1626763200},\n",
       "  {'pesq': 1.138418436050415,\n",
       "   'stoi': np.float64(0.721783813063014),\n",
       "   'time': 1613634400},\n",
       "  {'pesq': 2.1161301136016846,\n",
       "   'stoi': np.float64(0.9302200268168683),\n",
       "   'time': 1619254500},\n",
       "  {'pesq': 1.802811622619629,\n",
       "   'stoi': np.float64(0.9428974584357948),\n",
       "   'time': 1632531400},\n",
       "  {'pesq': 1.687486171722412,\n",
       "   'stoi': np.float64(0.9441462886518727),\n",
       "   'time': 1616695000},\n",
       "  {'pesq': 1.605694055557251,\n",
       "   'stoi': np.float64(0.8592020436742528),\n",
       "   'time': 1630891000},\n",
       "  {'pesq': 2.37431263923645,\n",
       "   'stoi': np.float64(0.9728553406249039),\n",
       "   'time': 1625349700},\n",
       "  {'pesq': 1.8680951595306396,\n",
       "   'stoi': np.float64(0.9681163120629604),\n",
       "   'time': 1615340600},\n",
       "  {'pesq': 2.273348569869995,\n",
       "   'stoi': np.float64(0.8924350172366087),\n",
       "   'time': 1639733500},\n",
       "  {'pesq': 1.6064515113830566,\n",
       "   'stoi': np.float64(0.928995742419746),\n",
       "   'time': 1619776200},\n",
       "  {'pesq': 1.4599461555480957,\n",
       "   'stoi': np.float64(0.9347718685712179),\n",
       "   'time': 1613323300},\n",
       "  {'pesq': 2.512071371078491,\n",
       "   'stoi': np.float64(0.9170015550825991),\n",
       "   'time': 1621994400},\n",
       "  {'pesq': 2.288808822631836,\n",
       "   'stoi': np.float64(0.9864378313943679),\n",
       "   'time': 1636488900},\n",
       "  {'pesq': 1.151415467262268,\n",
       "   'stoi': np.float64(0.7573811214246537),\n",
       "   'time': 1617289600},\n",
       "  {'pesq': 1.5501039028167725,\n",
       "   'stoi': np.float64(0.8547605937101942),\n",
       "   'time': 1623606500},\n",
       "  {'pesq': 1.1093653440475464,\n",
       "   'stoi': np.float64(0.5901135104188523),\n",
       "   'time': 1621736500},\n",
       "  {'pesq': 1.051737666130066,\n",
       "   'stoi': np.float64(0.5255879183446092),\n",
       "   'time': 1624198600},\n",
       "  {'pesq': 1.6066124439239502,\n",
       "   'stoi': np.float64(0.8679640308846311),\n",
       "   'time': 1633191800},\n",
       "  {'pesq': 1.6579550504684448,\n",
       "   'stoi': np.float64(0.9391016029661144),\n",
       "   'time': 1629486700},\n",
       "  {'pesq': 2.1090312004089355,\n",
       "   'stoi': np.float64(0.9707449533477834),\n",
       "   'time': 1638861500},\n",
       "  {'pesq': 1.0726122856140137,\n",
       "   'stoi': np.float64(0.7941132196315853),\n",
       "   'time': 1619619500},\n",
       "  {'pesq': 2.509172201156616,\n",
       "   'stoi': np.float64(0.9715969525485599),\n",
       "   'time': 1618566200},\n",
       "  {'pesq': 2.0269360542297363,\n",
       "   'stoi': np.float64(0.9179430684605353),\n",
       "   'time': 1628334400},\n",
       "  {'pesq': 2.0993101596832275,\n",
       "   'stoi': np.float64(0.9719352454937075),\n",
       "   'time': 1621651500},\n",
       "  {'pesq': 1.2337400913238525,\n",
       "   'stoi': np.float64(0.7389645039103676),\n",
       "   'time': 1645863400},\n",
       "  {'pesq': 1.4316192865371704,\n",
       "   'stoi': np.float64(0.9073688008959953),\n",
       "   'time': 1630087500},\n",
       "  {'pesq': 1.282560110092163,\n",
       "   'stoi': np.float64(0.7714097349889347),\n",
       "   'time': 1628718900},\n",
       "  {'pesq': 1.728217363357544,\n",
       "   'stoi': np.float64(0.9424169889076761),\n",
       "   'time': 1632964100},\n",
       "  {'pesq': 1.3678914308547974,\n",
       "   'stoi': np.float64(0.5372042133304111),\n",
       "   'time': 1626275500},\n",
       "  {'pesq': 2.0192148685455322,\n",
       "   'stoi': np.float64(0.9294472462685976),\n",
       "   'time': 1636641200},\n",
       "  {'pesq': 1.0620816946029663,\n",
       "   'stoi': np.float64(0.7876706619286504),\n",
       "   'time': 1656626900},\n",
       "  {'pesq': 1.213822364807129,\n",
       "   'stoi': np.float64(0.6748552535470145),\n",
       "   'time': 1634504500},\n",
       "  {'pesq': 1.6738840341567993,\n",
       "   'stoi': np.float64(0.8645754744684863),\n",
       "   'time': 1625039900},\n",
       "  {'pesq': 1.6508702039718628,\n",
       "   'stoi': np.float64(0.8393430475966247),\n",
       "   'time': 1632131800},\n",
       "  {'pesq': 1.9517565965652466,\n",
       "   'stoi': np.float64(0.9451371819677542),\n",
       "   'time': 1634319000},\n",
       "  {'pesq': 1.6626394987106323,\n",
       "   'stoi': np.float64(0.8661329313598497),\n",
       "   'time': 1629150400},\n",
       "  {'pesq': 1.7045574188232422,\n",
       "   'stoi': np.float64(0.935750928866019),\n",
       "   'time': 1623547500},\n",
       "  {'pesq': 1.6679686307907104,\n",
       "   'stoi': np.float64(0.9533983200066816),\n",
       "   'time': 1626162000},\n",
       "  {'pesq': 1.6426870822906494,\n",
       "   'stoi': np.float64(0.9185417069452936),\n",
       "   'time': 1633507100},\n",
       "  {'pesq': 1.6641817092895508,\n",
       "   'stoi': np.float64(0.9354766234021218),\n",
       "   'time': 1633930900},\n",
       "  {'pesq': 1.4951280355453491,\n",
       "   'stoi': np.float64(0.8091994189785461),\n",
       "   'time': 1630747300},\n",
       "  {'pesq': 2.098021984100342,\n",
       "   'stoi': np.float64(0.9879504220601347),\n",
       "   'time': 1636153400},\n",
       "  {'pesq': 1.1792352199554443,\n",
       "   'stoi': np.float64(0.9010166330887915),\n",
       "   'time': 1640953100},\n",
       "  {'pesq': 2.86088490486145,\n",
       "   'stoi': np.float64(0.9570771801206339),\n",
       "   'time': 1620759300},\n",
       "  {'pesq': 1.4033621549606323,\n",
       "   'stoi': np.float64(0.8094806416141785),\n",
       "   'time': 1629927200},\n",
       "  {'pesq': 1.3059858083724976,\n",
       "   'stoi': np.float64(0.8471490047376974),\n",
       "   'time': 1630779600},\n",
       "  {'pesq': 1.0452985763549805,\n",
       "   'stoi': np.float64(0.522562635460782),\n",
       "   'time': 1623175300},\n",
       "  {'pesq': 1.0777171850204468, 'stoi': 1e-05, 'time': 1638645500},\n",
       "  {'pesq': 2.342348098754883,\n",
       "   'stoi': np.float64(0.9526723120080133),\n",
       "   'time': 1635864000},\n",
       "  {'pesq': 1.9923574924468994,\n",
       "   'stoi': np.float64(0.8154198781798069),\n",
       "   'time': 1637344300},\n",
       "  {'pesq': 1.2928975820541382,\n",
       "   'stoi': np.float64(0.6637796590710785),\n",
       "   'time': 1627188300},\n",
       "  {'pesq': 1.590716004371643,\n",
       "   'stoi': np.float64(0.9440873687398148),\n",
       "   'time': 1621662300},\n",
       "  {'pesq': 1.7693777084350586,\n",
       "   'stoi': np.float64(0.8960130648505007),\n",
       "   'time': 1615815700},\n",
       "  {'pesq': 1.2814103364944458,\n",
       "   'stoi': np.float64(0.8697380000157598),\n",
       "   'time': 1624128700},\n",
       "  {'pesq': 2.3342106342315674,\n",
       "   'stoi': np.float64(0.8766984143991253),\n",
       "   'time': 1629055900},\n",
       "  {'pesq': 1.7881247997283936,\n",
       "   'stoi': np.float64(0.9602781879113517),\n",
       "   'time': 1634877600},\n",
       "  {'pesq': 1.1412088871002197,\n",
       "   'stoi': np.float64(0.6177437739735167),\n",
       "   'time': 1624379700},\n",
       "  {'pesq': 1.259750485420227,\n",
       "   'stoi': np.float64(0.7731917268936439),\n",
       "   'time': 1623561500},\n",
       "  {'pesq': 1.9082993268966675,\n",
       "   'stoi': np.float64(0.9585020777432897),\n",
       "   'time': 1618654500},\n",
       "  {'pesq': 1.995072841644287,\n",
       "   'stoi': np.float64(0.9717004400087786),\n",
       "   'time': 1622550800},\n",
       "  {'pesq': 2.7265615463256836,\n",
       "   'stoi': np.float64(0.9736320544446285),\n",
       "   'time': 1624537700},\n",
       "  {'pesq': 1.3682305812835693,\n",
       "   'stoi': np.float64(0.8618774904231773),\n",
       "   'time': 1629717200},\n",
       "  {'pesq': 1.6423282623291016,\n",
       "   'stoi': np.float64(0.9109599194758354),\n",
       "   'time': 1651269600},\n",
       "  {'pesq': 1.9450587034225464,\n",
       "   'stoi': np.float64(0.7775788241193727),\n",
       "   'time': 1631920400},\n",
       "  {'pesq': 2.3274619579315186,\n",
       "   'stoi': np.float64(0.9413377544566592),\n",
       "   'time': 1618054900},\n",
       "  {'pesq': 1.041605830192566,\n",
       "   'stoi': np.float64(0.5433235842703278),\n",
       "   'time': 1643337300},\n",
       "  {'pesq': 1.308483362197876,\n",
       "   'stoi': np.float64(0.8107349551070859),\n",
       "   'time': 1633497800},\n",
       "  {'pesq': 1.3592252731323242,\n",
       "   'stoi': np.float64(0.9142413519299715),\n",
       "   'time': 1620923600},\n",
       "  {'pesq': 1.305281162261963,\n",
       "   'stoi': np.float64(0.8501669770798757),\n",
       "   'time': 1617151100},\n",
       "  {'pesq': 1.7514173984527588,\n",
       "   'stoi': np.float64(0.9563417148088714),\n",
       "   'time': 1632892600},\n",
       "  {'pesq': 1.0644915103912354,\n",
       "   'stoi': np.float64(0.7082666933218025),\n",
       "   'time': 1659078700},\n",
       "  {'pesq': 1.0735312700271606,\n",
       "   'stoi': np.float64(0.7121277922127204),\n",
       "   'time': 1663745900},\n",
       "  {'pesq': 1.3740427494049072,\n",
       "   'stoi': np.float64(0.9015120541646877),\n",
       "   'time': 1632235100},\n",
       "  {'pesq': 1.25596022605896,\n",
       "   'stoi': np.float64(0.930708549060552),\n",
       "   'time': 1625103700},\n",
       "  {'pesq': 1.1747685670852661,\n",
       "   'stoi': np.float64(0.7921199877270043),\n",
       "   'time': 1616846600},\n",
       "  {'pesq': 1.0889372825622559,\n",
       "   'stoi': np.float64(0.7793643444677367),\n",
       "   'time': 1611522800},\n",
       "  {'pesq': 2.062472105026245,\n",
       "   'stoi': np.float64(0.9688288617521134),\n",
       "   'time': 1619982700},\n",
       "  {'pesq': 1.9508423805236816,\n",
       "   'stoi': np.float64(0.927102124624381),\n",
       "   'time': 1642676800},\n",
       "  {'pesq': 1.3456991910934448,\n",
       "   'stoi': np.float64(0.8535251908796383),\n",
       "   'time': 1632845600},\n",
       "  {'pesq': 1.2289196252822876,\n",
       "   'stoi': np.float64(0.9522295625154304),\n",
       "   'time': 1615525400},\n",
       "  {'pesq': 2.039763927459717,\n",
       "   'stoi': np.float64(0.9141167054919174),\n",
       "   'time': 1631339800},\n",
       "  {'pesq': 1.4297215938568115,\n",
       "   'stoi': np.float64(0.8615290309008466),\n",
       "   'time': 1630962800},\n",
       "  {'pesq': 1.1469374895095825,\n",
       "   'stoi': np.float64(0.7946849119992404),\n",
       "   'time': 1622794500},\n",
       "  {'pesq': 1.6675543785095215,\n",
       "   'stoi': np.float64(0.9608502771544533),\n",
       "   'time': 1615682100},\n",
       "  {'pesq': 2.24513840675354,\n",
       "   'stoi': np.float64(0.964724888207277),\n",
       "   'time': 1626137500},\n",
       "  {'pesq': 1.1596564054489136,\n",
       "   'stoi': np.float64(0.5144965670289836),\n",
       "   'time': 1630343300},\n",
       "  {'pesq': 1.6659154891967773,\n",
       "   'stoi': np.float64(0.9446120187332806),\n",
       "   'time': 1651281600},\n",
       "  {'pesq': 1.9954123497009277,\n",
       "   'stoi': np.float64(0.9766183069423902),\n",
       "   'time': 1618096000},\n",
       "  {'pesq': 2.241988182067871,\n",
       "   'stoi': np.float64(0.960322377040408),\n",
       "   'time': 1617338900},\n",
       "  {'pesq': 1.7680518627166748,\n",
       "   'stoi': np.float64(0.9322948897740444),\n",
       "   'time': 1622683700},\n",
       "  {'pesq': 2.313255786895752,\n",
       "   'stoi': np.float64(0.9786649989341258),\n",
       "   'time': 1616351400},\n",
       "  {'pesq': 1.4645955562591553,\n",
       "   'stoi': np.float64(0.8346620377098315),\n",
       "   'time': 1616004900},\n",
       "  {'pesq': 1.033362865447998,\n",
       "   'stoi': np.float64(0.2544255793522556),\n",
       "   'time': 1654811500},\n",
       "  {'pesq': 2.3255112171173096,\n",
       "   'stoi': np.float64(0.96669099912044),\n",
       "   'time': 1629397600},\n",
       "  {'pesq': 2.6294620037078857,\n",
       "   'stoi': np.float64(0.9752670908508372),\n",
       "   'time': 1631143600},\n",
       "  {'pesq': 1.8200782537460327,\n",
       "   'stoi': np.float64(0.9581997970155257),\n",
       "   'time': 1616305800},\n",
       "  {'pesq': 2.188992500305176,\n",
       "   'stoi': np.float64(0.9400506682186925),\n",
       "   'time': 1632724300},\n",
       "  {'pesq': 1.3889873027801514,\n",
       "   'stoi': np.float64(0.8889074689453635),\n",
       "   'time': 1614836100},\n",
       "  {'pesq': 1.1885617971420288,\n",
       "   'stoi': np.float64(0.5670709176451404),\n",
       "   'time': 1617178500},\n",
       "  {'pesq': 2.60794997215271,\n",
       "   'stoi': np.float64(0.9829222350907475),\n",
       "   'time': 1616595300},\n",
       "  {'pesq': 2.3711400032043457,\n",
       "   'stoi': np.float64(0.9820117139927694),\n",
       "   'time': 1615055400},\n",
       "  {'pesq': 2.072173595428467,\n",
       "   'stoi': np.float64(0.9728187168890823),\n",
       "   'time': 1635016400},\n",
       "  {'pesq': 2.7171106338500977,\n",
       "   'stoi': np.float64(0.9889559031388758),\n",
       "   'time': 1623818100},\n",
       "  {'pesq': 2.6854758262634277,\n",
       "   'stoi': np.float64(0.9674257528012041),\n",
       "   'time': 1621275400},\n",
       "  {'pesq': 1.1614108085632324,\n",
       "   'stoi': np.float64(0.6972797434538803),\n",
       "   'time': 1622118800},\n",
       "  {'pesq': 2.703390598297119,\n",
       "   'stoi': np.float64(0.9869421207446409),\n",
       "   'time': 1613433900},\n",
       "  {'pesq': 1.4820157289505005,\n",
       "   'stoi': np.float64(0.9471894096840029),\n",
       "   'time': 1617259700},\n",
       "  {'pesq': 2.519502639770508,\n",
       "   'stoi': np.float64(0.9841039474268742),\n",
       "   'time': 1620415400},\n",
       "  {'pesq': 1.580434799194336,\n",
       "   'stoi': np.float64(0.8942445988113835),\n",
       "   'time': 1628659700},\n",
       "  {'pesq': 2.4144935607910156,\n",
       "   'stoi': np.float64(0.9702058895208733),\n",
       "   'time': 1611141400},\n",
       "  {'pesq': 1.4511357545852661,\n",
       "   'stoi': np.float64(0.9360043456023476),\n",
       "   'time': 1613307500},\n",
       "  {'pesq': 1.234416127204895,\n",
       "   'stoi': np.float64(0.8768152785327014),\n",
       "   'time': 1643301700},\n",
       "  {'pesq': 1.477508544921875,\n",
       "   'stoi': np.float64(0.841130486758522),\n",
       "   'time': 1615605500},\n",
       "  {'pesq': 1.5537456274032593,\n",
       "   'stoi': np.float64(0.9123240541331484),\n",
       "   'time': 1625093300},\n",
       "  {'pesq': 1.634429693222046,\n",
       "   'stoi': np.float64(0.8843471322543665),\n",
       "   'time': 1617681700},\n",
       "  {'pesq': 1.1160300970077515,\n",
       "   'stoi': np.float64(0.6111939218966637),\n",
       "   'time': 1611144000},\n",
       "  {'pesq': 1.1493436098098755,\n",
       "   'stoi': np.float64(0.4433950443410132),\n",
       "   'time': 1634364800},\n",
       "  {'pesq': 1.3788625001907349,\n",
       "   'stoi': np.float64(0.935714158275588),\n",
       "   'time': 1628612400},\n",
       "  {'pesq': 1.2569077014923096,\n",
       "   'stoi': np.float64(0.7231355531891337),\n",
       "   'time': 1622959500},\n",
       "  {'pesq': 1.1009501218795776,\n",
       "   'stoi': np.float64(0.7036388505681412),\n",
       "   'time': 1616280600},\n",
       "  {'pesq': 1.8781129121780396,\n",
       "   'stoi': np.float64(0.9736104829651794),\n",
       "   'time': 1628912200},\n",
       "  {'pesq': 1.2069499492645264,\n",
       "   'stoi': np.float64(0.7036403932425772),\n",
       "   'time': 1630633100},\n",
       "  {'pesq': 1.4943766593933105,\n",
       "   'stoi': np.float64(0.8853097275195336),\n",
       "   'time': 1621006800},\n",
       "  {'pesq': 2.6867363452911377,\n",
       "   'stoi': np.float64(0.9943074785301532),\n",
       "   'time': 1643654800},\n",
       "  {'pesq': 1.4372018575668335,\n",
       "   'stoi': np.float64(0.8381578090617405),\n",
       "   'time': 1621019300},\n",
       "  {'pesq': 1.0505822896957397,\n",
       "   'stoi': np.float64(0.7105642678442241),\n",
       "   'time': 1639035500},\n",
       "  {'pesq': 2.4555246829986572,\n",
       "   'stoi': np.float64(0.9696164007454031),\n",
       "   'time': 1628477200},\n",
       "  {'pesq': 1.5540874004364014,\n",
       "   'stoi': np.float64(0.8374841488099872),\n",
       "   'time': 1644362600},\n",
       "  {'pesq': 1.5532474517822266,\n",
       "   'stoi': np.float64(0.9441674005792215),\n",
       "   'time': 1621409800},\n",
       "  {'pesq': 1.3192706108093262,\n",
       "   'stoi': np.float64(0.854474927694461),\n",
       "   'time': 1642810900},\n",
       "  {'pesq': 1.4803035259246826,\n",
       "   'stoi': np.float64(0.9545875159228925),\n",
       "   'time': 1626097600},\n",
       "  {'pesq': 1.3816742897033691,\n",
       "   'stoi': np.float64(0.7361650866033485),\n",
       "   'time': 1622841400},\n",
       "  {'pesq': 1.3479094505310059,\n",
       "   'stoi': np.float64(0.8435784668128342),\n",
       "   'time': 1641656100},\n",
       "  {'pesq': 2.4261178970336914,\n",
       "   'stoi': np.float64(0.9703253030315874),\n",
       "   'time': 1631165500},\n",
       "  {'pesq': 1.5528810024261475,\n",
       "   'stoi': np.float64(0.847953627508411),\n",
       "   'time': 1633154100},\n",
       "  {'pesq': 1.838269591331482,\n",
       "   'stoi': np.float64(0.9396509359122466),\n",
       "   'time': 1623590900},\n",
       "  {'pesq': 1.412038803100586,\n",
       "   'stoi': np.float64(0.9454547391646132),\n",
       "   'time': 1615874800},\n",
       "  {'pesq': 1.3202967643737793,\n",
       "   'stoi': np.float64(0.8396048154236075),\n",
       "   'time': 1632496700},\n",
       "  {'pesq': 3.2065389156341553,\n",
       "   'stoi': np.float64(0.9870711327978063),\n",
       "   'time': 1632325500},\n",
       "  {'pesq': 1.600370168685913,\n",
       "   'stoi': np.float64(0.619833501786609),\n",
       "   'time': 1633816600},\n",
       "  {'pesq': 2.0522496700286865,\n",
       "   'stoi': np.float64(0.6605699237727359),\n",
       "   'time': 1630691700},\n",
       "  {'pesq': 1.6665995121002197,\n",
       "   'stoi': np.float64(0.7649193285461352),\n",
       "   'time': 1618129300},\n",
       "  {'pesq': 1.2116940021514893,\n",
       "   'stoi': np.float64(0.8752240750481332),\n",
       "   'time': 1621553100},\n",
       "  {'pesq': 2.2515571117401123,\n",
       "   'stoi': np.float64(0.9850150238807819),\n",
       "   'time': 1631434600},\n",
       "  {'pesq': 1.6635594367980957,\n",
       "   'stoi': np.float64(0.896506664318576),\n",
       "   'time': 1623820900},\n",
       "  {'pesq': 1.175073504447937,\n",
       "   'stoi': np.float64(0.8420158650477527),\n",
       "   'time': 1617308300},\n",
       "  {'pesq': 1.214151382446289,\n",
       "   'stoi': np.float64(0.7082244018432453),\n",
       "   'time': 1615482300},\n",
       "  {'pesq': 1.2190145254135132,\n",
       "   'stoi': np.float64(0.48872850617214686),\n",
       "   'time': 1621845800},\n",
       "  {'pesq': 1.0857129096984863,\n",
       "   'stoi': np.float64(0.684963037434694),\n",
       "   'time': 1631796400},\n",
       "  {'pesq': 1.4008525609970093,\n",
       "   'stoi': np.float64(0.9342192883722387),\n",
       "   'time': 1623101100},\n",
       "  {'pesq': 1.1929731369018555,\n",
       "   'stoi': np.float64(0.8854737628091925),\n",
       "   'time': 1617619600},\n",
       "  {'pesq': 1.7672038078308105,\n",
       "   'stoi': np.float64(0.8681291945470142),\n",
       "   'time': 1624575300},\n",
       "  {'pesq': 1.514005422592163,\n",
       "   'stoi': np.float64(0.608452047156343),\n",
       "   'time': 1629391700},\n",
       "  {'pesq': 1.1515843868255615,\n",
       "   'stoi': np.float64(0.7818340987151133),\n",
       "   'time': 1626833500},\n",
       "  {'pesq': 1.631838083267212,\n",
       "   'stoi': np.float64(0.8932453125350067),\n",
       "   'time': 1626644800},\n",
       "  {'pesq': 1.645141363143921,\n",
       "   'stoi': np.float64(0.8654732983882218),\n",
       "   'time': 1630538600},\n",
       "  {'pesq': 1.3357932567596436,\n",
       "   'stoi': np.float64(0.9159167464143937),\n",
       "   'time': 1634208500},\n",
       "  {'pesq': 2.7121341228485107,\n",
       "   'stoi': np.float64(0.9804939727180507),\n",
       "   'time': 1627420600},\n",
       "  {'pesq': 1.5341941118240356,\n",
       "   'stoi': np.float64(0.7484084783614626),\n",
       "   'time': 1638288400},\n",
       "  {'pesq': 1.4625399112701416,\n",
       "   'stoi': np.float64(0.8116466634910998),\n",
       "   'time': 1629085700},\n",
       "  {'pesq': 1.1915309429168701,\n",
       "   'stoi': np.float64(0.5719575164556995),\n",
       "   'time': 1624968200},\n",
       "  {'pesq': 1.5580295324325562,\n",
       "   'stoi': np.float64(0.9172742374144838),\n",
       "   'time': 1629358000},\n",
       "  {'pesq': 1.5361120700836182,\n",
       "   'stoi': np.float64(0.9633862845223826),\n",
       "   'time': 1643742500},\n",
       "  {'pesq': 2.2315335273742676,\n",
       "   'stoi': np.float64(0.9582679567162768),\n",
       "   'time': 1640535800},\n",
       "  {'pesq': 1.2047501802444458,\n",
       "   'stoi': np.float64(0.9059814018049734),\n",
       "   'time': 1648308000},\n",
       "  {'pesq': 1.484103798866272,\n",
       "   'stoi': np.float64(0.9342645321851358),\n",
       "   'time': 1633764400},\n",
       "  {'pesq': 1.8090825080871582,\n",
       "   'stoi': np.float64(0.9545439151706984),\n",
       "   'time': 1629360400},\n",
       "  {'pesq': 1.5728659629821777,\n",
       "   'stoi': np.float64(0.8094170780560913),\n",
       "   'time': 1637638300},\n",
       "  {'pesq': 1.2039525508880615,\n",
       "   'stoi': np.float64(0.659333928624093),\n",
       "   'time': 1625595900},\n",
       "  {'pesq': 2.174161911010742,\n",
       "   'stoi': np.float64(0.9627031175121814),\n",
       "   'time': 1622848700},\n",
       "  {'pesq': 1.5905711650848389,\n",
       "   'stoi': np.float64(0.9530637937903068),\n",
       "   'time': 1637041200},\n",
       "  {'pesq': 1.5302624702453613,\n",
       "   'stoi': np.float64(0.8094128875759395),\n",
       "   'time': 1623546600},\n",
       "  {'pesq': 1.4962773323059082,\n",
       "   'stoi': np.float64(0.8704837069074193),\n",
       "   'time': 1617078900},\n",
       "  {'pesq': 1.0429316759109497,\n",
       "   'stoi': np.float64(0.4100347506613123),\n",
       "   'time': 1633547900},\n",
       "  {'pesq': 1.698146104812622,\n",
       "   'stoi': np.float64(0.9685073731314826),\n",
       "   'time': 1643827500},\n",
       "  {'pesq': 1.80869460105896,\n",
       "   'stoi': np.float64(0.867428408308256),\n",
       "   'time': 1617626200},\n",
       "  {'pesq': 3.07206392288208,\n",
       "   'stoi': np.float64(0.982693506172073),\n",
       "   'time': 1620448300},\n",
       "  {'pesq': 1.2647991180419922,\n",
       "   'stoi': np.float64(0.7661970823460799),\n",
       "   'time': 1623457900},\n",
       "  {'pesq': 1.4448679685592651,\n",
       "   'stoi': np.float64(0.8854236084808403),\n",
       "   'time': 1622168900},\n",
       "  {'pesq': 1.0689527988433838,\n",
       "   'stoi': np.float64(0.5746760864138328),\n",
       "   'time': 1637859100},\n",
       "  {'pesq': 2.8203125,\n",
       "   'stoi': np.float64(0.8879336354152917),\n",
       "   'time': 1631047100},\n",
       "  {'pesq': 2.46685528755188,\n",
       "   'stoi': np.float64(0.9679362751590397),\n",
       "   'time': 1635346300},\n",
       "  {'pesq': 1.489319920539856,\n",
       "   'stoi': np.float64(0.9082844862019813),\n",
       "   'time': 1636498600},\n",
       "  {'pesq': 2.3316380977630615,\n",
       "   'stoi': np.float64(0.9413891592699791),\n",
       "   'time': 1648296800},\n",
       "  {'pesq': 1.3661123514175415,\n",
       "   'stoi': np.float64(0.9495142392543479),\n",
       "   'time': 1634816400},\n",
       "  {'pesq': 2.1748366355895996,\n",
       "   'stoi': np.float64(0.9694625347375595),\n",
       "   'time': 1654295000},\n",
       "  {'pesq': 1.2186049222946167,\n",
       "   'stoi': np.float64(0.7796407159214952),\n",
       "   'time': 1723252300},\n",
       "  {'pesq': 2.254772186279297,\n",
       "   'stoi': np.float64(0.9299224935311382),\n",
       "   'time': 1649086000},\n",
       "  {'pesq': 2.0585358142852783,\n",
       "   'stoi': np.float64(0.9176637810588848),\n",
       "   'time': 1631542500},\n",
       "  {'pesq': 2.041365623474121,\n",
       "   'stoi': np.float64(0.9529610818967469),\n",
       "   'time': 1633298900},\n",
       "  {'pesq': 1.5900771617889404,\n",
       "   'stoi': np.float64(0.897621024323038),\n",
       "   'time': 1630967800},\n",
       "  {'pesq': 1.4624658823013306,\n",
       "   'stoi': np.float64(0.8709814780608427),\n",
       "   'time': 1685683200},\n",
       "  {'pesq': 1.2357087135314941,\n",
       "   'stoi': np.float64(0.6851398718404664),\n",
       "   'time': 1688798300},\n",
       "  {'pesq': 2.4499664306640625,\n",
       "   'stoi': np.float64(0.9846004550195059),\n",
       "   'time': 1679803100},\n",
       "  {'pesq': 2.4820446968078613,\n",
       "   'stoi': np.float64(0.9840330586694375),\n",
       "   'time': 1703657000},\n",
       "  {'pesq': 2.016948938369751, 'stoi': 1e-05, 'time': 1626042100},\n",
       "  {'pesq': 1.526720643043518,\n",
       "   'stoi': np.float64(0.8707959605092053),\n",
       "   'time': 1630852100},\n",
       "  {'pesq': 1.249459981918335,\n",
       "   'stoi': np.float64(0.8421649122827423),\n",
       "   'time': 1645045300},\n",
       "  {'pesq': 1.205579161643982,\n",
       "   'stoi': np.float64(0.7687058535236488),\n",
       "   'time': 1667911500},\n",
       "  {'pesq': 1.8495274782180786,\n",
       "   'stoi': np.float64(0.9828306282596286),\n",
       "   'time': 1696007400},\n",
       "  {'pesq': 1.0665913820266724,\n",
       "   'stoi': np.float64(0.6082622025199825),\n",
       "   'time': 1682822700},\n",
       "  {'pesq': 1.2738317251205444,\n",
       "   'stoi': np.float64(0.9305453648500985),\n",
       "   'time': 1656845100},\n",
       "  {'pesq': 1.9812190532684326,\n",
       "   'stoi': np.float64(0.575390573706634),\n",
       "   'time': 1699012000},\n",
       "  {'pesq': 1.9587984085083008,\n",
       "   'stoi': np.float64(0.9559936499310366),\n",
       "   'time': 1697178400},\n",
       "  {'pesq': 1.3617961406707764,\n",
       "   'stoi': np.float64(0.916646620522425),\n",
       "   'time': 1689820000},\n",
       "  {'pesq': 1.577057123184204,\n",
       "   'stoi': np.float64(0.9607077317575748),\n",
       "   'time': 1643466100},\n",
       "  {'pesq': 1.294163465499878,\n",
       "   'stoi': np.float64(0.9019940059315444),\n",
       "   'time': 1655649100},\n",
       "  {'pesq': 1.823972225189209,\n",
       "   'stoi': np.float64(0.946708059223242),\n",
       "   'time': 1642180800},\n",
       "  {'pesq': 1.316740870475769,\n",
       "   'stoi': np.float64(0.8941916906758113),\n",
       "   'time': 1690972500},\n",
       "  {'pesq': 1.932727336883545,\n",
       "   'stoi': np.float64(0.9359473885891558),\n",
       "   'time': 1658837800},\n",
       "  {'pesq': 1.1986291408538818,\n",
       "   'stoi': np.float64(0.8470859052802365),\n",
       "   'time': 1687590200},\n",
       "  {'pesq': 2.501711845397949,\n",
       "   'stoi': np.float64(0.9729659301364927),\n",
       "   'time': 1654794600},\n",
       "  {'pesq': 1.4037472009658813,\n",
       "   'stoi': np.float64(0.9202840871946988),\n",
       "   'time': 1695412000},\n",
       "  ...]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.segan import Generator\n",
    "from models.tcnn import TCNN\n",
    "from models.rhrnet import RHRNet\n",
    "# from models.wavecrn import ConvBSRU\n",
    "from pesq.cypesq import NoUtterancesError\n",
    "\n",
    "def gan_one_sec_test(model: Generator, dl: DataLoader, hp: dict, n_samples = None):\n",
    "    try:\n",
    "        results = []\n",
    "        if n_samples == None:\n",
    "            n_samples = len(dl)\n",
    "        model.eval()\n",
    "        sample: torch.Tensor\n",
    "        rnd = random.Random()\n",
    "        z = torch.zeros((hp[\"batch_size\"],1024,8)).to(device=device)\n",
    "        i = 0\n",
    "        for sample in dl:\n",
    "            perf_time = time.perf_counter_ns()\n",
    "            if i >= n_samples:\n",
    "                break\n",
    "            i+=1\n",
    "            start = rnd.randint(0, sample.shape[-1]-hp[\"frame_size\"])\n",
    "            slc = (start, start + hp[\"frame_size\"])\n",
    "            batch = sample[slice(*slc)].clone().detach()\n",
    "            with torch.no_grad():\n",
    "                x, y = batch[0].to(device=device), batch[1].to(device=device)\n",
    "                nn.init.normal_(z)\n",
    "                y_pred: torch.Tensor = model(x, z)\n",
    "            perf_time = time.perf_counter_ns() - perf_time\n",
    "            y_pred_np = y_pred.numpy(force=True)\n",
    "            y_np = y.numpy(force=True)\n",
    "            # x_np = x.numpy(force=True)\n",
    "            try:\n",
    "                sq = calc_pesq(y_np, y_pred_np)\n",
    "                si = calc_stoi(y_np, y_pred_np)\n",
    "            except:\n",
    "                continue\n",
    "            res = {\n",
    "                \"pesq\": sq, \"stoi\": si, \"time\": perf_time\n",
    "            }\n",
    "            results.append(res)\n",
    "    finally:\n",
    "        return results\n",
    "    \n",
    "# def crn_one_sec_test(model: ConvBSRU, dl: DataLoader, hp: dict, n_samples = None):\n",
    "#     '''`dl` should be a DataLoader that provides the full audio file, not a FrameLoader.'''\n",
    "#     try:\n",
    "#         results = []\n",
    "#         if n_samples == None:\n",
    "#             n_samples = len(dl)\n",
    "#         model.eval()\n",
    "#         sample: torch.Tensor\n",
    "#         rnd = random.Random()\n",
    "#         proc_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], 1)\n",
    "#         clean_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], 1)\n",
    "#         # noisy_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], 1)\n",
    "#         i = 0\n",
    "#         for sample in dl:\n",
    "#             if i >= n_samples:\n",
    "#                 break\n",
    "#             i+=1\n",
    "#             start = rnd.randint(0, sample[0].shape[-1]-hp[\"frame_size\"])\n",
    "#             slc = (start, start + hp[\"frame_size\"])\n",
    "#             _noisy, _clean = sample[0][slice(*slc)].clone().detach(), sample[1][slice(*slc)].clone().detach()\n",
    "#             _,_,pad = calc_windowing(_noisy.shape[-1],hp[\"frame_size\"], hp[\"frame_shift\"])\n",
    "#             _noisy, _clean = torch.nn.functional.pad(_noisy,(0,pad), value=0.0), torch.nn.functional.pad(_clean,(0,pad), value=0.0)\n",
    "#             noisy, clean = get_all_frames(_noisy,hp[\"frame_size\"], hp[\"frame_shift\"]), get_all_frames(_clean,hp[\"frame_size\"], hp[\"frame_shift\"])\n",
    "#             perf_time = time.perf_counter_ns()\n",
    "#             for j in range(noisy.shape[1]):\n",
    "#                 batch = noisy.narrow(1, j, 1), clean.narrow(1, j, 1)    #   Frame num dimension becomes 1, can be reused as channel index\n",
    "#                 with torch.no_grad():\n",
    "#                     x, y = batch[0].to(device=device), batch[1].to(device=device)\n",
    "#                     y_pred: torch.Tensor = model(x)\n",
    "#                     proc_frame_constructor.add_frame(y_pred)\n",
    "#                     clean_frame_constructor.add_frame(y)\n",
    "#                     # noisy_frame_constructor.add_frame(x)\n",
    "\n",
    "#             perf_time = time.perf_counter_ns() - perf_time\n",
    "#             y_pred = proc_frame_constructor.get_current_audio()\n",
    "#             y = clean_frame_constructor.get_current_audio()\n",
    "#             proc_frame_constructor.reset()\n",
    "#             clean_frame_constructor.reset()\n",
    "#             # x = noisy_frame_constructor.get_current_audio()\n",
    "#             y_pred_np = y_pred.numpy(force=True)\n",
    "#             y_np = y.numpy(force=True)\n",
    "#             # x_np = x.numpy(force=True)\n",
    "            # try:\n",
    "            #     sq = calc_pesq(y_np, y_pred_np)\n",
    "            #     si = calc_stoi(y_np, y_pred_np)\n",
    "            # except:\n",
    "            #     continue\n",
    "            # res = {\n",
    "            #     \"pesq\": sq, \"stoi\": si, \"time\": perf_time\n",
    "            # }\n",
    "            # results.append(res)\n",
    "\n",
    "#     finally:\n",
    "#         return results\n",
    "\n",
    "def rnn_one_sec_test(model: RHRNet, dl: DataLoader, hp: dict, n_samples = None):\n",
    "    try:\n",
    "        results = []\n",
    "        if n_samples == None:\n",
    "            n_samples = len(dl)\n",
    "        model.eval()\n",
    "        sample: torch.Tensor\n",
    "        rnd = random.Random()\n",
    "        proc_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], 1)\n",
    "        clean_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], 1)\n",
    "        # noisy_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], 1)\n",
    "        i = 0\n",
    "        for sample in tqdm(dl):\n",
    "            if i >= n_samples:\n",
    "                break\n",
    "            i+=1\n",
    "            start = rnd.randint(0, sample[0].shape[-1]-SAMPLE_RATE)\n",
    "            slc = (start, start + SAMPLE_RATE)\n",
    "            _noisy, _clean = sample[0].squeeze()[slice(*slc)].clone().detach(), sample[1].squeeze()[slice(*slc)].clone().detach()\n",
    "            _,_,pad = calc_windowing(_noisy.shape[-1],hp[\"frame_size\"], hp[\"frame_shift\"])\n",
    "            noisy_pad, clean_pad = torch.nn.functional.pad(_noisy,(0,pad), value=0.0), torch.nn.functional.pad(_clean,(0,pad), value=0.0)\n",
    "            noisy, clean = get_all_frames(noisy_pad,hp[\"frame_size\"], hp[\"frame_shift\"]), get_all_frames(clean_pad,hp[\"frame_size\"], hp[\"frame_shift\"])\n",
    "            perf_time = time.perf_counter_ns()\n",
    "            for j in range(noisy.shape[1]):\n",
    "                batch = noisy.narrow(1, j, 1).squeeze(1), clean.narrow(1, j, 1).squeeze(1)\n",
    "                with torch.no_grad():\n",
    "                    x, y = batch[0].to(device=device), batch[1].to(device=device)\n",
    "                    y_pred: torch.Tensor = model(x)\n",
    "                    proc_frame_constructor.add_frame(y_pred)\n",
    "                    clean_frame_constructor.add_frame(y)\n",
    "                    # noisy_frame_constructor.add_frame(x)\n",
    "\n",
    "            perf_time = time.perf_counter_ns() - perf_time\n",
    "            y_pred = proc_frame_constructor.get_current_audio().squeeze()\n",
    "            y = clean_frame_constructor.get_current_audio().squeeze()\n",
    "            proc_frame_constructor.reset()\n",
    "            clean_frame_constructor.reset()\n",
    "            # display.display(Audio(y_pred, rate=SAMPLE_RATE))\n",
    "            # display.display(Audio(y, rate=SAMPLE_RATE))\n",
    "            # x = noisy_frame_constructor.get_current_audio()\n",
    "            y_pred_np = y_pred.numpy(force=True)\n",
    "            y_np = y.numpy(force=True)\n",
    "            # x_np = x.numpy(force=True)\n",
    "            try:\n",
    "                sq = calc_pesq(y_np, y_pred_np)\n",
    "                si = calc_stoi(y_np, y_pred_np)\n",
    "            except NoUtterancesError as e:\n",
    "                continue\n",
    "            res = {\n",
    "                \"pesq\": sq, \"stoi\": si, \"time\": perf_time\n",
    "            }\n",
    "            results.append(res)\n",
    "    finally:\n",
    "        print(traceback.print_exc())\n",
    "        return results\n",
    "\n",
    "def cnn_one_sec_test(model: TCNN, dl: DataLoader, hp: dict, n_samples = None):\n",
    "    try:\n",
    "        results = []\n",
    "        if n_samples == None:\n",
    "            n_samples = len(dl)\n",
    "        model.eval()\n",
    "        sample: torch.Tensor\n",
    "        rnd = random.Random()\n",
    "        proc_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], 1)\n",
    "        clean_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], 1)\n",
    "        # noisy_frame_constructor = FrameReconstructor(hp[\"frame_size\"], hp[\"frame_shift\"], 1)\n",
    "        i = 0\n",
    "        for sample in dl:\n",
    "            if i >= n_samples:\n",
    "                break\n",
    "            i+=1\n",
    "            start = rnd.randint(0, sample[0].shape[-1]-hp[\"frame_size\"])\n",
    "            slc = (start, start + hp[\"frame_size\"])\n",
    "            _noisy, _clean = sample[0][slice(*slc)].clone().detach(), sample[1][slice(*slc)].clone().detach()\n",
    "            _,_,pad = calc_windowing(_noisy.shape[-1],hp[\"frame_size\"], hp[\"frame_shift\"])\n",
    "            _noisy, _clean = torch.nn.functional.pad(_noisy,(0,pad), value=0.0), torch.nn.functional.pad(_clean,(0,pad), value=0.0)\n",
    "            noisy, clean = get_all_frames(_noisy,hp[\"frame_size\"], hp[\"frame_shift\"]).view(1,1,), get_all_frames(_clean,hp[\"frame_size\"], hp[\"frame_shift\"])\n",
    "            j = 0\n",
    "            j_end = noisy.shape[1] - hp[\"num_frames\"]\n",
    "            perf_time = time.perf_counter_ns()\n",
    "            while j < j_end:\n",
    "                batch = noisy.narrow(1,j,hp[\"num_frames\"]).unsqueeze(1), clean.narrow(1,j,hp[\"num_frames\"]).unsqueeze(1)\n",
    "                j += hp[\"num_frames\"]\n",
    "                with torch.no_grad():\n",
    "                    x, y = batch[0].to(device=device), batch[1].to(device=device)\n",
    "                    y_pred: torch.Tensor = model(x)\n",
    "                    for i in range(y_pred.shape[2]):\n",
    "                        proc_frame_constructor.add_frame(y_pred[:,:,i,:])\n",
    "                        clean_frame_constructor.add_frame(y[:,:,i,:])\n",
    "                        # noisy_frame_constructor.add_frame(x[:,:,i,:])\n",
    "\n",
    "\n",
    "            perf_time = time.perf_counter_ns() - perf_time\n",
    "            y_pred = proc_frame_constructor.get_current_audio()\n",
    "            y = clean_frame_constructor.get_current_audio()\n",
    "            proc_frame_constructor.reset()\n",
    "            clean_frame_constructor.reset()\n",
    "            # x = clean_frame_constructor.get_current_audio()\n",
    "            y_pred_np = y_pred.numpy(force=True)\n",
    "            y_np = y.numpy(force=True)\n",
    "            # x_np = x.numpy(force=True)\n",
    "            try:\n",
    "                sq = calc_pesq(y_np, y_pred_np)\n",
    "                si = calc_stoi(y_np, y_pred_np)\n",
    "            except:\n",
    "                continue\n",
    "            res = {\n",
    "                \"pesq\": sq, \"stoi\": si, \"time\": perf_time\n",
    "            }\n",
    "            results.append(res)\n",
    "    finally: \n",
    "        return results\n",
    "\n",
    "ds = SortedBatchDataset(get_sequential_wav_paths(\"data/mixed/test\"), get_sequential_wav_paths(\"data/speech_ordered/test\"),1)\n",
    "dl = DataLoader(ds)\n",
    "import yaml\n",
    "from models.rhrnetdir.Arg_Parser import Recursive_Parse\n",
    "_rnn_hp = Recursive_Parse(yaml.load(\n",
    "    open('models/rhrnetdir/rhrnet_hyperparameters.yaml', encoding='utf-8'),\n",
    "    Loader=yaml.Loader\n",
    "    ))  \n",
    "\n",
    "rnn = RHRNet(_rnn_hp).to(device=device)\n",
    "rnn.load_state_dict(torch.load(r\"D:\\fyp\\saved_models\\rnn_21-04-2025--01-00-43\\final.pt\"))\n",
    "res: dict[str, list[dict[str, float]]] = {}\n",
    "logging.disable(logging.DEBUG)\n",
    "fake_hp = {\"frame_size\": 320, \"frame_shift\":80}\n",
    "res[\"rnn\"] = rnn_one_sec_test(rnn, dl, fake_hp)\n",
    "with open(\"results/rnn_one_sec_test\",\"w\") as f:\n",
    "    json.dump(res, f)\n",
    "res\n",
    "\n",
    "\n",
    "\n",
    "### One test will be how fast can it do 1 second of audio\n",
    "### One test will be at max 10ms shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 1614.998 | Std: 32.195\n"
     ]
    }
   ],
   "source": [
    "for k, v in res.items():\n",
    "    t = [x[\"time\"] for x in v]\n",
    "    mn = np.mean(t)\n",
    "    std = np.std(t)\n",
    "    print(f\"Mean: {(mn/1e6):.3f} | Std: {(std/1e6):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_test(model: RHRNet):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeDataset(Dataset):\n",
    "    def __init__(self, l_waveforms: list, r_waveforms:list):\n",
    "        self.l_waveforms = l_waveforms\n",
    "        self.r_waveforms = r_waveforms\n",
    "        super().__init__()\n",
    "    def __len__(self):\n",
    "        return len(self.l_waveforms)\n",
    "    def __getitem__(self,idx):\n",
    "        # return self.l_waveforms[idx], self.r_waveforms[idx]\n",
    "        # print(torch.tensor(self.l_waveforms[idx]).unsqueeze_(0))\n",
    "        # print(torch.tensor(self.l_waveforms[idx]).unsqueeze_(0).shape,flush=True)\n",
    "\n",
    "        return torch.tensor(self.l_waveforms[idx]).unsqueeze_(0), torch.tensor(self.r_waveforms[idx]).unsqueeze_(0)\n",
    "\n",
    "def evaluate_e2e_one_sample(model_dict: dict, seed=None):\n",
    "    rnd = random.Random(seed)\n",
    "    chosen_sample = ntpath.basename(rnd.choice(glob.glob(\"data/speech_ordered/train/*.wav\")))\n",
    "    clean_sample,_ = torchaudio.load(\"data/speech_ordered/train/\" + chosen_sample)\n",
    "    mixed_sample,_ = torchaudio.load(\"data/mixed/train/\" + chosen_sample)\n",
    "    ds = FakeDataset([mixed_sample],[clean_sample])\n",
    "    dl = DataLoader(ds)\n",
    "    out = {}\n",
    "    for name in model_dict.keys():\n",
    "        out[name] = {}\n",
    "        out[name][\"model\"] = model_dict[name]\n",
    "        match name:\n",
    "            case \"cnn\":\n",
    "                out[name][\"loader\"] = FrameLoader(dl,CNN_FRAME_SIZE,CNN_FRAME_SHIFT, batch_size=1)\n",
    "                out[name][\"processed_constructor\"] = FrameReconstructor(CNN_OUT_FRAME_SIZE,CNN_FRAME_SHIFT, batch_size=1)\n",
    "                out[name][\"clean_constructor\"] = FrameReconstructor(CNN_OUT_FRAME_SIZE,CNN_FRAME_SHIFT, batch_size=1)\n",
    "            case \"rnn\":\n",
    "                out[name][\"loader\"] = FrameLoader(dl,RNN_FRAME_SIZE,RNN_FRAME_SHIFT, batch_size=1)\n",
    "                out[name][\"processed_constructor\"] = FrameReconstructor(RNN_FRAME_SIZE,RNN_FRAME_SHIFT, batch_size=1)\n",
    "                out[name][\"clean_constructor\"] = FrameReconstructor(RNN_FRAME_SIZE,RNN_FRAME_SHIFT, batch_size=1)\n",
    "            case \"crn\":\n",
    "                out[name][\"loader\"] = FrameLoader(dl,CRN_FRAME_SIZE,CRN_FRAME_SHIFT, batch_size=1, output_transform=lambda x: x.reshape(1,1,-1))\n",
    "                out[name][\"processed_constructor\"] = FrameReconstructor(CRN_FRAME_SIZE,CRN_FRAME_SHIFT, batch_size=1)\n",
    "                out[name][\"clean_constructor\"] = FrameReconstructor(CRN_FRAME_SIZE,CRN_FRAME_SHIFT, batch_size=1)\n",
    "            # case \"gan\":\n",
    "            #     out[name][\"loader\"] = FrameLoader(dl,GAN_FRAME_SIZE,GAN_FRAME_SHIFT)\n",
    "            case _:\n",
    "                pass\n",
    "        out[name][\"perf\"] = {\"e2e_time\":0, \"avg_forward\":0}\n",
    "    # print(\"shape__:\" + str(clean_sample.shape))\n",
    "    out[\"num_frames\"] = clean_sample.shape[1]\n",
    "    \n",
    "    for name in model_dict.keys():\n",
    "        # print(name)\n",
    "        # print(out[name],flush=True)\n",
    "        at_end = False\n",
    "        model = out[name][\"model\"]\n",
    "        data = iter(out[name][\"loader\"])\n",
    "        pf_eval_total = 0\n",
    "        n_loops = 0\n",
    "        pf_eval_e2e = time.perf_counter_ns()\n",
    "        while not at_end:\n",
    "            pf_eval_forward = time.perf_counter_ns()\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                x, y, at_end = next(data)\n",
    "                x = x.to(device=device)\n",
    "                y = y.to(device=device)\n",
    "                y_pred = model(x)\n",
    "                pf_eval_total += (time.perf_counter_ns() - pf_eval_forward)\n",
    "                n_loops += 1\n",
    "                try:\n",
    "                    out[name][\"processed_constructor\"].add_frame(y_pred)\n",
    "                    out[name][\"clean_constructor\"].add_frame(y)\n",
    "                except RuntimeError as e:\n",
    "                    print(out[name][\"processed_constructor\"].audio.shape)\n",
    "                    raise RuntimeError(e.args)\n",
    "                \n",
    "\n",
    "                if at_end:    #   Frame fully constructed\n",
    "                    y_pred_stitch = out[name][\"processed_constructor\"].get_current_audio()\n",
    "                    y_stitch = out[name][\"clean_constructor\"].get_current_audio()\n",
    "                    print(y_pred_stitch.shape)\n",
    "                    print(y_stitch.shape)\n",
    "                    display.display(Audio(y_pred_stitch[0][0],rate=SAMPLE_RATE))\n",
    "                    display.display(Audio(y_stitch[0][0],rate=SAMPLE_RATE))\n",
    "                    \n",
    "        \n",
    "        pf_eval_e2e = time.perf_counter_ns() - pf_eval_e2e\n",
    "        out[name][\"perf\"][\"e2e_time\"] = pf_eval_e2e\n",
    "        out[name][\"perf\"][\"avg_forward\"] = pf_eval_total / float(n_loops)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crn_model = ConvBSRU(frame_size=CRN_FRAME_SIZE, conv_channels=256, stride=48, num_layers=6, dropout=0.0).to(device=device)\n",
    "crn_model.load_state_dict(torch.load(\"saved_models/crn.pt\", weights_only=True))\n",
    "models = {  \"crn\": crn_model }#, \"rnn\": rnn_model}#, \"cnn\": cnn_model,}\n",
    "out = evaluate_e2e_one_sample(models)\n",
    "\n",
    "print(\"Duration of audio: \" + str(out[\"num_frames\"] / SAMPLE_RATE))\n",
    "for name in models.keys():\n",
    "    model_dict = out[name]\n",
    "    print(f\"{name.upper()} -- e2e:{ns_to_sec(model_dict[\"perf\"][\"e2e_time\"])}, average forward:{ns_to_sec(model_dict[\"perf\"][\"avg_forward\"])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tcnn import TCNN\n",
    "\n",
    "cnn_hp = {\n",
    "    \"frame_size\":320,\n",
    "    \"frame_shift\":160,\n",
    "    \"lr\":1.0e-4,\n",
    "    \"batch_size\":16,\n",
    "    \"epochs\":30,\n",
    "    \"save\":False,\n",
    "    \"load\":None,\n",
    "    \"model_type\":\"cnn\",\n",
    "}\n",
    "hp = cnn_hp\n",
    "\n",
    "_dataset = SortedBatchDataset(get_sequential_wav_paths(\"data/mixed/train\"),\n",
    "                                    get_sequential_wav_paths(\"data/speech_ordered/train\"), \n",
    "                                    batch_size=hp[\"batch_size\"])\n",
    "train_dataset, val_dataset = _dataset.split(0.2)\n",
    "del _dataset\n",
    "base_train_dataloader = DataLoader(train_dataset, shuffle=SHUFFLE)\n",
    "base_val_dataloader = DataLoader(val_dataset)\n",
    "\n",
    "dl = iter(base_train_dataloader)\n",
    "batch = next(dl)\n",
    "_x, _y = batch[0], batch[1]\n",
    "print(batch[0].shape[-1])\n",
    "\n",
    "mfi = MultiFrameLoader(base_train_dataloader, hp[\"frame_size\"], hp[\"frame_shift\"], hp[\"batch_size\"], num_frames=300, output_transform=lambda x: x.unsqueeze(1))\n",
    "for i in mfi:\n",
    "    print(i[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    torch.cuda.empty_cache()\n",
    "    try:\n",
    "        x = get_all_frames(_x,hp[\"frame_size\"],hp[\"frame_shift\"], lambda x: x.unsqueeze(1))\n",
    "        # x = x.narrow(2,0,500)\n",
    "        x = x.to(device=device)\n",
    "        print(f\"x shape = {x.shape}\")\n",
    "\n",
    "        model = TCNN().to(device=device)\n",
    "        y_pred = model(x)\n",
    "        print(f\"y shape = {y_pred.shape}\")\n",
    "    finally:\n",
    "        pass\n",
    "        \n",
    "\n",
    "test()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = TCNN()\n",
    "c = torch.optim.Adam(m.parameters(),0.01)\n",
    "print(str(c).split(\"(\")[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
